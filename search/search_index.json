{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Pipeliner \u00b6 An open-source, reproducible, and scalable solution for analyzing NGS data. Pipeliner provides access to the same best-practices pipelines developed and benchmarked by bioinformatics analysts at CCBR and NCBR . This repository is the main source of documentation for users and developers working with or contributing to Pipeliner . Our goal is to provide a mechanism or framework for researchers to employ robust, scalable, and reproducible scientific analysis. Over the years, Pipeliner has enabled users across the NIH to meet their research goals-- resulting in dozens of publications and over 16 million hours of compute! Questions or need help? \u00b6 Please check out our FAQ or contact page for different ways of getting in touch with the team.","title":"Home"},{"location":"#welcome-to-pipeliner","text":"An open-source, reproducible, and scalable solution for analyzing NGS data. Pipeliner provides access to the same best-practices pipelines developed and benchmarked by bioinformatics analysts at CCBR and NCBR . This repository is the main source of documentation for users and developers working with or contributing to Pipeliner . Our goal is to provide a mechanism or framework for researchers to employ robust, scalable, and reproducible scientific analysis. Over the years, Pipeliner has enabled users across the NIH to meet their research goals-- resulting in dozens of publications and over 16 million hours of compute!","title":"Welcome to Pipeliner"},{"location":"#questions-or-need-help","text":"Please check out our FAQ or contact page for different ways of getting in touch with the team.","title":"Questions or need help?"},{"location":"about/","text":"About \u00b6 Team \u00b6 CCBR and NCBR are umbrella organizations providing collaborative bioinformatics support to 300+ investigators across the Center for Cancer Research (CCR) and NIAID. Our development team includes members with a diversity of experiences and expertise, ranging from NGS analyses, statistics, population genetics, application development, and computational data science. Project \u00b6 In addition to providing bioinformatics support, we are actively engaged in technical development projects aimed at establishing best-practices for NGS data analysis. We extensively test and benchmark every tool that is added to our pipelines. Our comprehensive benchmarking of different tools and methods has accumulated in a set of best practices pipelines for the analysis of WGS/WES, RNA-seq, miR-seq, ChIP-Seq, ATAC-seq, Microarray, and Single-cell datasets. Pipeliner provides directly access to these pipelines.","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"about/#team","text":"CCBR and NCBR are umbrella organizations providing collaborative bioinformatics support to 300+ investigators across the Center for Cancer Research (CCR) and NIAID. Our development team includes members with a diversity of experiences and expertise, ranging from NGS analyses, statistics, population genetics, application development, and computational data science.","title":"Team"},{"location":"about/#project","text":"In addition to providing bioinformatics support, we are actively engaged in technical development projects aimed at establishing best-practices for NGS data analysis. We extensively test and benchmark every tool that is added to our pipelines. Our comprehensive benchmarking of different tools and methods has accumulated in a set of best practices pipelines for the analysis of WGS/WES, RNA-seq, miR-seq, ChIP-Seq, ATAC-seq, Microarray, and Single-cell datasets. Pipeliner provides directly access to these pipelines.","title":"Project"},{"location":"changelog/","text":"v4.0.2 \u00b6 Increasing picard memory allocation and num of threads for garbage collection ChIP-seq updates: estimated fragment length and more (#450) Merge pull request #449 from wong-nw/activeDev Bug Fix in integrateBatches.R URD call v4.0.1 \u00b6 removed AVIA Increasing resources for fusion inspector Switch to python script Python implementation of 'reformat_bed.pl' Adding memory for fusion inspector rules mm10 error Run only for 'hg19' or 'hg38' Remove ancient tag Fixing STAR fusion perl issue Explicitly load Perl scRNASeq changes Feb 2020 (#438) Changing git version: module git/2.15.1 is no longer available v4.0.0 \u00b6 Merging activeDev for v4.0.1 release (#444) v3.0.6 \u00b6 Setting activeDev branch to master Adding updated viral integrated genome hg38_30+HPV16 Archiving older viral integrated hg38_28+HPV16 references json Explicitly loading perl to aviod: 'Perl module GD::Graph::bars not installed, skipping charts' error Replacing hg19_KSHV with hg38_30_KSHV Adding \"References/\" as a cache for old reference files Updating targets file text, now changes based on reference genome Merge pull request #432 from mtandon09/activeDev Specify R version (3.5) because default (3.6) does not have 'magick' installed Merge pull request #431 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed gzipped VCF issue with germline calling Merge pull request #430 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev updated hg38 PON Updating rule pca: prevents race condition due to severe filesystem latency Updating rule pca: severe filesystem latency can create race condition when copying over files Updating pcacall usage to aviod filesystem latency issues RNA-seq Initial QC: Contrasts file not longer required ChIP-seq GUI: Adding \"contrasts\" button to the GUI Updating Initial QC RNA-seq Interface: only ask for group information Update dryrun file-checking for DEG pipelines only Updating DEG Reports for mm10_M21 Updating karyploter's usage to include mm10_M21 Adding \"mm10_M21\" to drop down reference genome Adding \"mm10_M21\" Reference Genome: Built using version M21 (Ensembl 96) annotation Adding pycache to gitignore Merge pull request #429 from kopardev/activeDev tidyverse added to genecounts.R along with writetogz function trim_se is now temp too tmp is actually temp tmp is actually temp make trim files temp not usin g deeptools anymore for bam2bw ... not doing any smoothing for bigwig files bringing back bw creation Merge remote-tracking branch 'upstream/activeDev' into activeDev Updating STAR from 2.5.2b to 2.7.0f for all RNA-seq references genomes changing PcaReport.Rmd genecounts.R rsemcounts.R to account for the scenario that we have only 1 group Adding compatibility for \"ref_vAnnotation\" formatted reference genomes Removing Strand-specific BigWigs as a target file tabs converted to 4 spaces bam2bw bc fix renaming bam2bw in rnaseq to bam2bw_rnaseq... and increasing its ram to 120g and cpus to 56 Adding hg38_30 to pipeliner's user interface Adding support for hg38_30 to karyoploter.R Updating DEG Reports for hg38_30 Updating PATH to KARYOPLOTER Updating the version of STAR from 2.5.2b to 2.7.0f Adding hg38_30 references using GENCODE version 30 annotation of the human genome (GRCh38) Merge pull request #428 from kopardev/activeDev added missing tail -n1 bam2bw rule Merge pull request #427 from kopardev/activeDev D1.0 type fixed to 1.0 in bam2bw rule Merge pull request #426 from jlac/activeDev updated STARfusion and FusionInspector, added merged final fusion outputs across 2 callers Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev updated STARfusion, fusioncatcher, and FusionInspector versions cluster.json ... partition fixed back to norm only Merge pull request #425 from kopardev/activeDev Deeptools rule now outputs bigwig files to bams folder Deeptools rule all wildcard fix Deeptools rule all indentation error fix rule all edited to add bam2bw outputs Merge pull request #424 from kopardev/activeDev rpsd fix forward-prob fix for rsem file2 defined for se rsem rule adding strand specificity to rsem counts command; adding rule to convert bams to forward and reverse bigwigs for easy visualization Merge pull request #423 from tovahmarkowitz/activeDev fixed bug in gem rule DiffBind,uropa,homer,manorm homer,uropa,manorm,diffbind,jaccard added BCFtools variant QC Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev homer,manorm,uropa,protcoding Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added new fusion rules removed target selection from polished germline WES variants; added BCFtools stats QC; substituted Agilent SS v7 target BED file for default targets update to mm9/mm10 json files... blacklist bwa index now includes chr_rDNA as well merging with main branch nggerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Changing effective genome size and adding differential binding analysis Added warning message to \"karyoploter.R\" Adding DEG Type prefix to output karyplot to prevent race conditions Adding last reference files for \"karoploter.R\" Adding gene expression karyoploter script Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Marked Qualimap Counts to be moved to DEG Updating GUI title Updating version to \"4.0\" for activeDev pipelines Updating \"activeDev\" Pipeliner branch version to 4.0 Merge pull request #422 from jlac/activeDev Adding \"karyotxt\" reference file to DESeq2, edgeR, limma calls Updating LimmaReport Rmarkdown Updating EdgerReport Rmarkdown Updating DESeq2 Rmarkdown Adding karyoploter reference file to organism json files Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev expanded MAF annotation to merged somatic variants Updating EBSeq.py Script Updating Ebseq rules Adding 'hg38_HPV16' to GUI Adding resources for hg38_HPV16: hg38_HPV16.json Merge pull request #421 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev reduced verbosity of VarDictt to decrease slurm log file size Adding hg19_KSHV reference files and updating GUI Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Updating QualiMap commands Merge pull request #420 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added multi-caller somatic variant detection to tumor-normal pipelines Adding QualiMap bamQC and QualiMap counts Updating path to RNA-seq MultiQC config file Adding adding qualimap sources to json files Adding support for edge-case: group CPM and MINSAMPLE filtering 0 0 (i.e. no filtering) completed multi-caller additions to tumor-only somatic pipeline Adding rule 'pca' to cluster.json fixed bugs in expanded WES tumor only pipeline; changed admixture outputs to all be printed in admixture_out; incorporated vardict somatic calling added Vardict tumor only somatic caller, added joint calling with 3 callers for tumor only calling improving HOMER/UROPA speeds Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #417 from tovahmarkowitz/activeDev adding spearman correlation heatmap to multiQC adding to the multiQC report removed mtDNA from germline genotyping Updating 'rule QCstats' to grab the fragment Length Updating to 'filterMetrics' to accept fragLen as an argument improving multiqc report, deeptools runtime, and other details Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed bug in admixture plot generation Resolves #416: use the project directory's 'cluster.json' file Merge pull request #408 from tovahmarkowitz/activeDev begin tracking R scripts for generating sample network and admixture PNGs Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added conversion of sample network to PNG and embedding it in multiQC report updates to gui by Vishal Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Resolves #415, added canFam3 and Mmul_8.0.1 to gui added summary figure generation and P-value annotation for FREEC CNVs Adding Macaca mulatta (Mmul_8.0.1) and Canis_lupus_familiaris (canFam3) reference files Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev adding vardict calling and multi-callier merging e for your changes. Lines starting rsemcount.R but fix... columns were getting duplicate names Updating STAR-p1 arguement: \"clip3pAdapterSeq\" to \"--clip3pAdapterSeq\" contrasts.tab now accepts 2, 3 or 4 columns, accepts numbers or fraction as column 4, fraction as to be >=0.5 and <1, numbers have to be integers; both numbers and fractions now denote number of samples or fraction of samples PER GROUP where GROUP is one of the groups in the contrast. Filtering of genes in DEG_ALL is changed from 0.5 CPM cutoff of atleast 2 samples out of all the samples to 0.5,0.5 setting ie., 50% of the samples PER GROUP should have atleast 0.5 CPM. more memory for ngsqc multiqc update and uropa update Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #406 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed bug in prep_mafs.pl script Updating ambiguous Subread genes output filename uropa fixes and cluster.json update filtersamples.R: changed .. 4 th column in contrasts.tab now denotes the number of samples PER GROUP that are required to meet the CPM threshold denoted in column 3 of the same file. If number in column 4 is greater than number of samples in the group, then MINCOUNT is reset to the number of samples in the group. Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Resolves #405, 'preseq lc_extrap' approximation uropa temporary workaround Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #404 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev improved somatic variant fitlering and maftools summaries merging branches adding uropa and other changes to chip-seq pipeline PhantomPeakQualTool: Bigwig Generation from Estimated Fragment Length, resolves #403 Updated Heatmap Height and PCA report generation (when > 100 samples) fixing issues caused by lack of input or PE sequencing data Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #401 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed bug in WES BED file generation where empty files are written when an incorrect path to target bed is given Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #400 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev moved sort out of STAR and into samtools rule to deal with memory bug PcaReport Rmarkdown Fix: Before Normalization/DESeq2 #399 reworked ChIPseq.snakefile with improvements Merge pull request #394 from tovahmarkowitz/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #398 from jlac/activeDev added memory limit to STAR 2-pass in rnaseqvarcalling Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed bug in 2 nd pass of freec Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #397 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed bug tracking FREEC 2 nd pass output gerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #396 from jlac/activeDev completed new CNV workflow for WES and WGS implementing 2-pass FREEC and Sequenza to WES and WGS pipelines Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev completed sequenza rule for WES and WGS, and completed second-pass rules for 2-pass freec added multipass freec CNV analysis to use ploidy and purity prior from sequenza tracking new files and scripts to run FREEC and sequenza added FREEC to tumor only pipeline, and sequenza and freec to tumor-normal pipeline updated Canvas germline to most recent version, and fixed bugs updated Canvas and fixed bugs in Canvas somatic CNV calling fixed error with ngsqc_plot rule adding ngsqc plot feature adding macs2 dedup functionality Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added full germline calling to wgs tumor-only pipeline added full germline genotyping to all somatic pipelines Merge pull request #389 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev updated GATK version to 3.8 in combine somatic GVCFs, and switched to filtering all MAF files with perl script rather than in maftools Merge pull request #388 from tovahmarkowitz/activeDev fixed fingerprint plot and multiQC Fix: WES Slurm Master Job Failure WGS/WES Reference Genome Selection Warning Message #377 Merge pull request #376 from tovahmarkowitz/activeDev Update cluster.json Initial ChIP-seq QC DAG SVG Generation, Updated Peaking Calling Rules, Generated MEMEchip Reference Files #375 fixed ppqt bak files removed; cutadapt updated to 1.18 on rnaseq fixing .gitignore Fixed ChIP-seq Python Package ImportError #374 Fixed ChIP-seq Python Package ImportError #374 Merge pull request #1 from vnkoparde/activeDev changing cutadapt in initial chipseq qc snakefile from 1.16 to 1.18 and adding a ppqt_pe rule actual purge and adding .DS_Store to the list adding .gitignore to ignore .* *.bak and *~ files standard-bin.json changed to change version of cutadapt from 1.16 to 1.18 Rolling back InitialChIP Seq snakefile to commit ac47e92a20af8de3fe1ddd9344c613dc38f9cf63 Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev In PE mode readlength based filters to be applied to any (not both) of the the reads Merge pull request #373 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added automated filtering to prep_mafs.pl script Python Package Import Incomaptiblity Fix: pysam chipseq:cutadapt to v 1.18, remove files ending in tilda, added .gitignore, added separate ppqt rules for se and pe Labels Testing: unbound variable fix updated genome fasta for rnaseqvarcalling for mm10 Labels file edge case: peak call pop-up box fix Copy peakcall.tab if labels.txt in rawdata directory merge with main pipeline gerge th otherbranch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev ltered somatic variant filtering to be based on alt and ref counts in tumor sample, instead of allele frequency Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Explicitly Loading Snakemake Module #371 Explicitly Loading Snakemake Module #371 fixed somatic directory creation bug due to snakemake version change Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed bug in loading VEP and vcf2maf for MAF generation rules Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev combining pipelines :gibincomninge enter a commit message to explain why this merge is necessary, separating fingerprint plots; merging inputnorm heatmaps Update README.md Update README.md readding geneinfo to chipseq fixing merge issue merging with CCBR/activeDev gerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Dynamically Resolve CCR BUY-IN NODES ISSUE #358 Dynamically Resolve BUY-IN NODE Issue #358 RSEM CPM filtering Issue #357 json merge issue merging json files Removed an include statement Updated GEM GEMONECHRS Merge pull request #356 from jlac/activeDev updated splitNcigar GATK version to 3.8 Re-validated cluster.json file fix error with read extension gerge with Justin's changes branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Changing Partition from 'ccr,norm' to 'norm' Merge pull request #355 from jlac/activeDev reduced wall times for rules that do not need max wall time changed default partition to norm renaming bws changing bw naming Update Deeptools PE Target Rule Resolving Deeptools Filenames Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added indexing rule to all WGS and WES pipelines playing with dependencies merge with other pipelines branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #351 from jlac/activeDev repaired wgs_tumor_only bug in maftools merging ChIP-seq with other pipelines gerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev CPM Filtering Fix Use Updated Sampletable for PCA Export RSTUDIO_PANDOC merging with Paul's function gerge branch 'activeDev' of https://github.com/tovahmarkowitz/Pipeliner into activeDev merging with Justin's changes gerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Inputnorm rule integration Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev increased master job wall time to 10 days Merge pull request #350 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev made theta2 outputs dynamic to allow pipeline to complete under conditions where the theta2 rule fails read extension for bigwigs and dynamic deeptools rules merge with Justin's changes branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #349 from jlac/activeDev added chr prefix to hg38 chromosome names in haplotype caller rules split by chromosome merging with contrasts.tab changes Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added filtering for MAF files, and added additional summary plot and analysis of MAF files Safe-guards to ensure referential integrity during differential expression analysis Updating rule pca adding heatmaps and profile plots merging changes with ChIP-seq and RNA-seq pipelinesMerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Pop-up box warning if 'groups.tab' or 'contrast.tab' are not in RNA-seq working directory before dry-running pcacall.R revert removed some pointers changed conditions for trim_pe and trim_se combining structural annotation information and chip-seq file pointers Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #348 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev split rnaseqvarcalling by chromosome Adjusting different rules in IniitialChIPseq.snakefile merge branch 'activeDev' of https://github.com/tovahmarkowitz/Pipeliner into activeDev changes made to both exome-seq and chip-seq portions of hg19.json Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #347 from jlac/activeDev fixed bug in location of fusion STAR libraries add peakcall.tab parsing and rule inputnorm (not implemented) new heatmap rule adding GENEINFO to ChIP-seq Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixing thread usage Merge pull request #345 from jlac/activeDev 'peakcall.tab' is copied over if it's in the data directory bug fixes with deeptools_QC Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev increased the number of jobs submitted at a time to 500 bug fixes adding fingerprint plot Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev changes to RNA-seq merged with changes to ChIP-seq: Merge branch 'kopardev-activeDev' into activeDev 344 pr updates 344 pr updates split haplotype caller by chromosome for all germline pipelines removed Delly from all pipelines Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added knwn ploidy config file to mm10.json for running Canvas Rename symlinked bams to .recal.bam Genome-seq/Exome-seq symlink update to work with labels.txt file fixed bug Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev GUI Changes: peakcall.tab now required for InitialChIPseqQC Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Symlink BAM and VCF files for Exome-seq/Genome-seq fixed rule connections fixed indentation error organized rules cleaning script for clarity consolidating rules updated MallDoneerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev repaired starfusion bug and hg38 exome somatic only bug cleaned up code Merge pull request #343 from jlac/activeDev updated versions for STARfusion and Canvas, and updated annotation resources for STARfusion to the most recent. Also, added multithreading to STARfusion fixed bug in all rule for wgs somatic tumor-only stepped back to v0.9.1 for cnvkit due to python bug RNA-seq DEG changes Syntax Error: removing extra parentheses Undo reading in files in binary mode Low Abundance Gene Thresholds option removed from the DEG gui frame ... this data is now entered in the contrasts.tab rRNA list fixed for mm9 Merge pull request #342 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev updated snpeff genome version for mouse Merge pull request #341 from jlac/activeDev changed hg38 filter ExAC VCF adding warnings for selecting the wrong genome ... for eg. GRCh38 will only work with scRNASeq pipeline ... pop up warning if it is selected for other pipeline adding decoy genomes for RNASeq/ChIPSeq pipelines ... updating annotations for other genomes new mouse RNASeq and ChIPSeq indexes included in json files Fixed indention inconsistency QCTable NReads Fix add sample info to initialrnaseqqc gui; added mincount column to groups.tab Merge pull request #339 from jlac/activeDev updated hatplotype caller steps to GATK 3.8-0, fixed jdk inflater bug, and added index BAMs step to Dragen entry point Adding peakcaller GEM ChIP-seq QC Table Merge pull request #338 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev updating updated Canvas version from 1.31 to 1.35 ChIP-seq Multiqc: Samtools Flagstat and Fastq Screen Delete PipelinerVer1.0_documentation.pdf Delete PipelinerVer1.0_documentation.docx Delete PipelinerVer1.0_documentation.pdf Delete PipelinerVer1.0_documentation.docx Filename bug fix Snakemake DAG generation fix filtersample scripts DEG_ALL folder ... extra column for contrasts.tab to have different cutoffs increased memory for qualimap rules Label Name Fix Merge pull request #332 from CCBR/revert-331-activeDev Revert \"test commit\" Merge pull request #331 from pajailwala/activeDev test commit Venn Diagram Additions deleting test Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Update README.md avia curl request fix test2 testing Venn Diagram showing overlap of DE genes Reformatted Limma, DESeq2, EdgeR Output: RNASeq v3.0.5 \u00b6 ChIP-seq bug fix and gui additions Merge pull request #322 from nikhilbg/centosOS7 minor bugfix for annotationdbi usage in scrnaseq cell cycle regression option in scrnaseq Nihkil changes for Single Cell v3.0.4 \u00b6 centOS7 ChIP-seq compatibility and requested GUI changes v3.0.3 \u00b6 WGS and WES changes for centos7 v3.0.2 \u00b6 Skylers changes for centos7 / RNASeq v3.0.1 \u00b6 bringing branch to the version on ccbrpipeliner (v3.0.2) bringing upto v3.0.2 v3.0.2 v3.0.0 \u00b6 multiqc is now not running in DEG part Merge pull request #316 from jlac/master updated versions for cnvkit and manta Merge pull request #315 from abdallahamr/master This is for the cpm filtering as it was not doing cpm twice, I only commented out one line per file Merge pull request #314 from jlac/master removed realign and recal from WES somatic and germline calling stages of WES pipelines Merge pull request #313 from CCBR/v3.0branch data/work folder is copy paste on gui... workflow error fix Merge pull request #312 from jlac/master Merge remote branch 'upstream/master' updates version of multiqc to v1.3 Merge pull request #311 from jlac/master fixed bugs in fusion expression cleanup Merge pull request #310 from jlac/master Merge remote branch 'upstream/master' changed path to Oncofuse jar file Merge pull request #309 from jlac/master removed subread components from gene expression rules for fusion pipeline Merge remote branch 'upstream/master' changed filtering criteria for MAF filtering fixed bug in processing tumor-only maftools rule Merge pull request #308 from jlac/master Merge remote branch 'upstream/master' added filtering to somatic mutation calls; fixed jsons to repair missing resources in fusion and rnaseqvar pipelines Merge pull request #307 from jlac/master fixed Canvas version module Merge pull request #306 from jlac/master repaired missing reference resources for fusion and ranseqvar pipelines fixed bug in counting sample for mutsigCV Merge pull request #305 from jlac/master Merge remote branch 'upstream/master' added population allele frequencies to MAF filtering, and set mutsig a threshold of 10 samples or tumor/normal pairs for mutsig to run Merge pull request #304 from jlac/master Merge remote branch 'upstream/master' fixed X11 graphics bug in qualimap Merge remote branch 'upstream/master' removed extraneous file","title":"Changelog"},{"location":"changelog/#v402","text":"Increasing picard memory allocation and num of threads for garbage collection ChIP-seq updates: estimated fragment length and more (#450) Merge pull request #449 from wong-nw/activeDev Bug Fix in integrateBatches.R URD call","title":"v4.0.2"},{"location":"changelog/#v401","text":"removed AVIA Increasing resources for fusion inspector Switch to python script Python implementation of 'reformat_bed.pl' Adding memory for fusion inspector rules mm10 error Run only for 'hg19' or 'hg38' Remove ancient tag Fixing STAR fusion perl issue Explicitly load Perl scRNASeq changes Feb 2020 (#438) Changing git version: module git/2.15.1 is no longer available","title":"v4.0.1"},{"location":"changelog/#v400","text":"Merging activeDev for v4.0.1 release (#444)","title":"v4.0.0"},{"location":"changelog/#v306","text":"Setting activeDev branch to master Adding updated viral integrated genome hg38_30+HPV16 Archiving older viral integrated hg38_28+HPV16 references json Explicitly loading perl to aviod: 'Perl module GD::Graph::bars not installed, skipping charts' error Replacing hg19_KSHV with hg38_30_KSHV Adding \"References/\" as a cache for old reference files Updating targets file text, now changes based on reference genome Merge pull request #432 from mtandon09/activeDev Specify R version (3.5) because default (3.6) does not have 'magick' installed Merge pull request #431 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed gzipped VCF issue with germline calling Merge pull request #430 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev updated hg38 PON Updating rule pca: prevents race condition due to severe filesystem latency Updating rule pca: severe filesystem latency can create race condition when copying over files Updating pcacall usage to aviod filesystem latency issues RNA-seq Initial QC: Contrasts file not longer required ChIP-seq GUI: Adding \"contrasts\" button to the GUI Updating Initial QC RNA-seq Interface: only ask for group information Update dryrun file-checking for DEG pipelines only Updating DEG Reports for mm10_M21 Updating karyploter's usage to include mm10_M21 Adding \"mm10_M21\" to drop down reference genome Adding \"mm10_M21\" Reference Genome: Built using version M21 (Ensembl 96) annotation Adding pycache to gitignore Merge pull request #429 from kopardev/activeDev tidyverse added to genecounts.R along with writetogz function trim_se is now temp too tmp is actually temp tmp is actually temp make trim files temp not usin g deeptools anymore for bam2bw ... not doing any smoothing for bigwig files bringing back bw creation Merge remote-tracking branch 'upstream/activeDev' into activeDev Updating STAR from 2.5.2b to 2.7.0f for all RNA-seq references genomes changing PcaReport.Rmd genecounts.R rsemcounts.R to account for the scenario that we have only 1 group Adding compatibility for \"ref_vAnnotation\" formatted reference genomes Removing Strand-specific BigWigs as a target file tabs converted to 4 spaces bam2bw bc fix renaming bam2bw in rnaseq to bam2bw_rnaseq... and increasing its ram to 120g and cpus to 56 Adding hg38_30 to pipeliner's user interface Adding support for hg38_30 to karyoploter.R Updating DEG Reports for hg38_30 Updating PATH to KARYOPLOTER Updating the version of STAR from 2.5.2b to 2.7.0f Adding hg38_30 references using GENCODE version 30 annotation of the human genome (GRCh38) Merge pull request #428 from kopardev/activeDev added missing tail -n1 bam2bw rule Merge pull request #427 from kopardev/activeDev D1.0 type fixed to 1.0 in bam2bw rule Merge pull request #426 from jlac/activeDev updated STARfusion and FusionInspector, added merged final fusion outputs across 2 callers Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev updated STARfusion, fusioncatcher, and FusionInspector versions cluster.json ... partition fixed back to norm only Merge pull request #425 from kopardev/activeDev Deeptools rule now outputs bigwig files to bams folder Deeptools rule all wildcard fix Deeptools rule all indentation error fix rule all edited to add bam2bw outputs Merge pull request #424 from kopardev/activeDev rpsd fix forward-prob fix for rsem file2 defined for se rsem rule adding strand specificity to rsem counts command; adding rule to convert bams to forward and reverse bigwigs for easy visualization Merge pull request #423 from tovahmarkowitz/activeDev fixed bug in gem rule DiffBind,uropa,homer,manorm homer,uropa,manorm,diffbind,jaccard added BCFtools variant QC Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev homer,manorm,uropa,protcoding Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added new fusion rules removed target selection from polished germline WES variants; added BCFtools stats QC; substituted Agilent SS v7 target BED file for default targets update to mm9/mm10 json files... blacklist bwa index now includes chr_rDNA as well merging with main branch nggerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Changing effective genome size and adding differential binding analysis Added warning message to \"karyoploter.R\" Adding DEG Type prefix to output karyplot to prevent race conditions Adding last reference files for \"karoploter.R\" Adding gene expression karyoploter script Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Marked Qualimap Counts to be moved to DEG Updating GUI title Updating version to \"4.0\" for activeDev pipelines Updating \"activeDev\" Pipeliner branch version to 4.0 Merge pull request #422 from jlac/activeDev Adding \"karyotxt\" reference file to DESeq2, edgeR, limma calls Updating LimmaReport Rmarkdown Updating EdgerReport Rmarkdown Updating DESeq2 Rmarkdown Adding karyoploter reference file to organism json files Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev expanded MAF annotation to merged somatic variants Updating EBSeq.py Script Updating Ebseq rules Adding 'hg38_HPV16' to GUI Adding resources for hg38_HPV16: hg38_HPV16.json Merge pull request #421 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev reduced verbosity of VarDictt to decrease slurm log file size Adding hg19_KSHV reference files and updating GUI Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Updating QualiMap commands Merge pull request #420 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added multi-caller somatic variant detection to tumor-normal pipelines Adding QualiMap bamQC and QualiMap counts Updating path to RNA-seq MultiQC config file Adding adding qualimap sources to json files Adding support for edge-case: group CPM and MINSAMPLE filtering 0 0 (i.e. no filtering) completed multi-caller additions to tumor-only somatic pipeline Adding rule 'pca' to cluster.json fixed bugs in expanded WES tumor only pipeline; changed admixture outputs to all be printed in admixture_out; incorporated vardict somatic calling added Vardict tumor only somatic caller, added joint calling with 3 callers for tumor only calling improving HOMER/UROPA speeds Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #417 from tovahmarkowitz/activeDev adding spearman correlation heatmap to multiQC adding to the multiQC report removed mtDNA from germline genotyping Updating 'rule QCstats' to grab the fragment Length Updating to 'filterMetrics' to accept fragLen as an argument improving multiqc report, deeptools runtime, and other details Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed bug in admixture plot generation Resolves #416: use the project directory's 'cluster.json' file Merge pull request #408 from tovahmarkowitz/activeDev begin tracking R scripts for generating sample network and admixture PNGs Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added conversion of sample network to PNG and embedding it in multiQC report updates to gui by Vishal Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Resolves #415, added canFam3 and Mmul_8.0.1 to gui added summary figure generation and P-value annotation for FREEC CNVs Adding Macaca mulatta (Mmul_8.0.1) and Canis_lupus_familiaris (canFam3) reference files Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev adding vardict calling and multi-callier merging e for your changes. Lines starting rsemcount.R but fix... columns were getting duplicate names Updating STAR-p1 arguement: \"clip3pAdapterSeq\" to \"--clip3pAdapterSeq\" contrasts.tab now accepts 2, 3 or 4 columns, accepts numbers or fraction as column 4, fraction as to be >=0.5 and <1, numbers have to be integers; both numbers and fractions now denote number of samples or fraction of samples PER GROUP where GROUP is one of the groups in the contrast. Filtering of genes in DEG_ALL is changed from 0.5 CPM cutoff of atleast 2 samples out of all the samples to 0.5,0.5 setting ie., 50% of the samples PER GROUP should have atleast 0.5 CPM. more memory for ngsqc multiqc update and uropa update Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #406 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed bug in prep_mafs.pl script Updating ambiguous Subread genes output filename uropa fixes and cluster.json update filtersamples.R: changed .. 4 th column in contrasts.tab now denotes the number of samples PER GROUP that are required to meet the CPM threshold denoted in column 3 of the same file. If number in column 4 is greater than number of samples in the group, then MINCOUNT is reset to the number of samples in the group. Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Resolves #405, 'preseq lc_extrap' approximation uropa temporary workaround Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #404 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev improved somatic variant fitlering and maftools summaries merging branches adding uropa and other changes to chip-seq pipeline PhantomPeakQualTool: Bigwig Generation from Estimated Fragment Length, resolves #403 Updated Heatmap Height and PCA report generation (when > 100 samples) fixing issues caused by lack of input or PE sequencing data Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #401 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed bug in WES BED file generation where empty files are written when an incorrect path to target bed is given Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #400 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev moved sort out of STAR and into samtools rule to deal with memory bug PcaReport Rmarkdown Fix: Before Normalization/DESeq2 #399 reworked ChIPseq.snakefile with improvements Merge pull request #394 from tovahmarkowitz/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #398 from jlac/activeDev added memory limit to STAR 2-pass in rnaseqvarcalling Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed bug in 2 nd pass of freec Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #397 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed bug tracking FREEC 2 nd pass output gerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #396 from jlac/activeDev completed new CNV workflow for WES and WGS implementing 2-pass FREEC and Sequenza to WES and WGS pipelines Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev completed sequenza rule for WES and WGS, and completed second-pass rules for 2-pass freec added multipass freec CNV analysis to use ploidy and purity prior from sequenza tracking new files and scripts to run FREEC and sequenza added FREEC to tumor only pipeline, and sequenza and freec to tumor-normal pipeline updated Canvas germline to most recent version, and fixed bugs updated Canvas and fixed bugs in Canvas somatic CNV calling fixed error with ngsqc_plot rule adding ngsqc plot feature adding macs2 dedup functionality Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added full germline calling to wgs tumor-only pipeline added full germline genotyping to all somatic pipelines Merge pull request #389 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev updated GATK version to 3.8 in combine somatic GVCFs, and switched to filtering all MAF files with perl script rather than in maftools Merge pull request #388 from tovahmarkowitz/activeDev fixed fingerprint plot and multiQC Fix: WES Slurm Master Job Failure WGS/WES Reference Genome Selection Warning Message #377 Merge pull request #376 from tovahmarkowitz/activeDev Update cluster.json Initial ChIP-seq QC DAG SVG Generation, Updated Peaking Calling Rules, Generated MEMEchip Reference Files #375 fixed ppqt bak files removed; cutadapt updated to 1.18 on rnaseq fixing .gitignore Fixed ChIP-seq Python Package ImportError #374 Fixed ChIP-seq Python Package ImportError #374 Merge pull request #1 from vnkoparde/activeDev changing cutadapt in initial chipseq qc snakefile from 1.16 to 1.18 and adding a ppqt_pe rule actual purge and adding .DS_Store to the list adding .gitignore to ignore .* *.bak and *~ files standard-bin.json changed to change version of cutadapt from 1.16 to 1.18 Rolling back InitialChIP Seq snakefile to commit ac47e92a20af8de3fe1ddd9344c613dc38f9cf63 Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev In PE mode readlength based filters to be applied to any (not both) of the the reads Merge pull request #373 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added automated filtering to prep_mafs.pl script Python Package Import Incomaptiblity Fix: pysam chipseq:cutadapt to v 1.18, remove files ending in tilda, added .gitignore, added separate ppqt rules for se and pe Labels Testing: unbound variable fix updated genome fasta for rnaseqvarcalling for mm10 Labels file edge case: peak call pop-up box fix Copy peakcall.tab if labels.txt in rawdata directory merge with main pipeline gerge th otherbranch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev ltered somatic variant filtering to be based on alt and ref counts in tumor sample, instead of allele frequency Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Explicitly Loading Snakemake Module #371 Explicitly Loading Snakemake Module #371 fixed somatic directory creation bug due to snakemake version change Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixed bug in loading VEP and vcf2maf for MAF generation rules Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev combining pipelines :gibincomninge enter a commit message to explain why this merge is necessary, separating fingerprint plots; merging inputnorm heatmaps Update README.md Update README.md readding geneinfo to chipseq fixing merge issue merging with CCBR/activeDev gerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Dynamically Resolve CCR BUY-IN NODES ISSUE #358 Dynamically Resolve BUY-IN NODE Issue #358 RSEM CPM filtering Issue #357 json merge issue merging json files Removed an include statement Updated GEM GEMONECHRS Merge pull request #356 from jlac/activeDev updated splitNcigar GATK version to 3.8 Re-validated cluster.json file fix error with read extension gerge with Justin's changes branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Changing Partition from 'ccr,norm' to 'norm' Merge pull request #355 from jlac/activeDev reduced wall times for rules that do not need max wall time changed default partition to norm renaming bws changing bw naming Update Deeptools PE Target Rule Resolving Deeptools Filenames Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added indexing rule to all WGS and WES pipelines playing with dependencies merge with other pipelines branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #351 from jlac/activeDev repaired wgs_tumor_only bug in maftools merging ChIP-seq with other pipelines gerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev CPM Filtering Fix Use Updated Sampletable for PCA Export RSTUDIO_PANDOC merging with Paul's function gerge branch 'activeDev' of https://github.com/tovahmarkowitz/Pipeliner into activeDev merging with Justin's changes gerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Inputnorm rule integration Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev increased master job wall time to 10 days Merge pull request #350 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev made theta2 outputs dynamic to allow pipeline to complete under conditions where the theta2 rule fails read extension for bigwigs and dynamic deeptools rules merge with Justin's changes branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #349 from jlac/activeDev added chr prefix to hg38 chromosome names in haplotype caller rules split by chromosome merging with contrasts.tab changes Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added filtering for MAF files, and added additional summary plot and analysis of MAF files Safe-guards to ensure referential integrity during differential expression analysis Updating rule pca adding heatmaps and profile plots merging changes with ChIP-seq and RNA-seq pipelinesMerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Pop-up box warning if 'groups.tab' or 'contrast.tab' are not in RNA-seq working directory before dry-running pcacall.R revert removed some pointers changed conditions for trim_pe and trim_se combining structural annotation information and chip-seq file pointers Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #348 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev split rnaseqvarcalling by chromosome Adjusting different rules in IniitialChIPseq.snakefile merge branch 'activeDev' of https://github.com/tovahmarkowitz/Pipeliner into activeDev changes made to both exome-seq and chip-seq portions of hg19.json Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Merge pull request #347 from jlac/activeDev fixed bug in location of fusion STAR libraries add peakcall.tab parsing and rule inputnorm (not implemented) new heatmap rule adding GENEINFO to ChIP-seq Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev fixing thread usage Merge pull request #345 from jlac/activeDev 'peakcall.tab' is copied over if it's in the data directory bug fixes with deeptools_QC Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev increased the number of jobs submitted at a time to 500 bug fixes adding fingerprint plot Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev changes to RNA-seq merged with changes to ChIP-seq: Merge branch 'kopardev-activeDev' into activeDev 344 pr updates 344 pr updates split haplotype caller by chromosome for all germline pipelines removed Delly from all pipelines Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev added knwn ploidy config file to mm10.json for running Canvas Rename symlinked bams to .recal.bam Genome-seq/Exome-seq symlink update to work with labels.txt file fixed bug Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev GUI Changes: peakcall.tab now required for InitialChIPseqQC Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Symlink BAM and VCF files for Exome-seq/Genome-seq fixed rule connections fixed indentation error organized rules cleaning script for clarity consolidating rules updated MallDoneerge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev repaired starfusion bug and hg38 exome somatic only bug cleaned up code Merge pull request #343 from jlac/activeDev updated versions for STARfusion and Canvas, and updated annotation resources for STARfusion to the most recent. Also, added multithreading to STARfusion fixed bug in all rule for wgs somatic tumor-only stepped back to v0.9.1 for cnvkit due to python bug RNA-seq DEG changes Syntax Error: removing extra parentheses Undo reading in files in binary mode Low Abundance Gene Thresholds option removed from the DEG gui frame ... this data is now entered in the contrasts.tab rRNA list fixed for mm9 Merge pull request #342 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev updated snpeff genome version for mouse Merge pull request #341 from jlac/activeDev changed hg38 filter ExAC VCF adding warnings for selecting the wrong genome ... for eg. GRCh38 will only work with scRNASeq pipeline ... pop up warning if it is selected for other pipeline adding decoy genomes for RNASeq/ChIPSeq pipelines ... updating annotations for other genomes new mouse RNASeq and ChIPSeq indexes included in json files Fixed indention inconsistency QCTable NReads Fix add sample info to initialrnaseqqc gui; added mincount column to groups.tab Merge pull request #339 from jlac/activeDev updated hatplotype caller steps to GATK 3.8-0, fixed jdk inflater bug, and added index BAMs step to Dragen entry point Adding peakcaller GEM ChIP-seq QC Table Merge pull request #338 from jlac/activeDev Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev updating updated Canvas version from 1.31 to 1.35 ChIP-seq Multiqc: Samtools Flagstat and Fastq Screen Delete PipelinerVer1.0_documentation.pdf Delete PipelinerVer1.0_documentation.docx Delete PipelinerVer1.0_documentation.pdf Delete PipelinerVer1.0_documentation.docx Filename bug fix Snakemake DAG generation fix filtersample scripts DEG_ALL folder ... extra column for contrasts.tab to have different cutoffs increased memory for qualimap rules Label Name Fix Merge pull request #332 from CCBR/revert-331-activeDev Revert \"test commit\" Merge pull request #331 from pajailwala/activeDev test commit Venn Diagram Additions deleting test Merge branch 'activeDev' of https://github.com/CCBR/Pipeliner into activeDev Update README.md avia curl request fix test2 testing Venn Diagram showing overlap of DE genes Reformatted Limma, DESeq2, EdgeR Output: RNASeq","title":"v3.0.6"},{"location":"changelog/#v305","text":"ChIP-seq bug fix and gui additions Merge pull request #322 from nikhilbg/centosOS7 minor bugfix for annotationdbi usage in scrnaseq cell cycle regression option in scrnaseq Nihkil changes for Single Cell","title":"v3.0.5"},{"location":"changelog/#v304","text":"centOS7 ChIP-seq compatibility and requested GUI changes","title":"v3.0.4"},{"location":"changelog/#v303","text":"WGS and WES changes for centos7","title":"v3.0.3"},{"location":"changelog/#v302","text":"Skylers changes for centos7 / RNASeq","title":"v3.0.2"},{"location":"changelog/#v301","text":"bringing branch to the version on ccbrpipeliner (v3.0.2) bringing upto v3.0.2 v3.0.2","title":"v3.0.1"},{"location":"changelog/#v300","text":"multiqc is now not running in DEG part Merge pull request #316 from jlac/master updated versions for cnvkit and manta Merge pull request #315 from abdallahamr/master This is for the cpm filtering as it was not doing cpm twice, I only commented out one line per file Merge pull request #314 from jlac/master removed realign and recal from WES somatic and germline calling stages of WES pipelines Merge pull request #313 from CCBR/v3.0branch data/work folder is copy paste on gui... workflow error fix Merge pull request #312 from jlac/master Merge remote branch 'upstream/master' updates version of multiqc to v1.3 Merge pull request #311 from jlac/master fixed bugs in fusion expression cleanup Merge pull request #310 from jlac/master Merge remote branch 'upstream/master' changed path to Oncofuse jar file Merge pull request #309 from jlac/master removed subread components from gene expression rules for fusion pipeline Merge remote branch 'upstream/master' changed filtering criteria for MAF filtering fixed bug in processing tumor-only maftools rule Merge pull request #308 from jlac/master Merge remote branch 'upstream/master' added filtering to somatic mutation calls; fixed jsons to repair missing resources in fusion and rnaseqvar pipelines Merge pull request #307 from jlac/master fixed Canvas version module Merge pull request #306 from jlac/master repaired missing reference resources for fusion and ranseqvar pipelines fixed bug in counting sample for mutsigCV Merge pull request #305 from jlac/master Merge remote branch 'upstream/master' added population allele frequencies to MAF filtering, and set mutsig a threshold of 10 samples or tumor/normal pairs for mutsig to run Merge pull request #304 from jlac/master Merge remote branch 'upstream/master' fixed X11 graphics bug in qualimap Merge remote branch 'upstream/master' removed extraneous file","title":"v3.0.0"},{"location":"community-and-contribution/","text":"Contribute \u00b6 Our team works closely with collaborators and staff scientists at the NIH to develop Pipeliner. We understand that to deliver the best pipelines, we must get the community involved. We would love to hear your feedback and your ideas. Our pipelines are built upon layers of open-source tools and other community-driven projects. We are constantly testing and benchmarking new tools. If you would like to collaborate with us, please reach out to our team and checkout our roadmap. Let's build together! Roadmap \u00b6 As an open-source project, transparency is very important to our team. That is why we try to share as much information as possible regarding current and future development. Please checkout Github Projects for insights into our development roadmap. If you would like to contribute to this project, feel free to email us. We welcome new contributions! Improve Pipeliner \u00b6 Feel free to open an issue on GitHub to make feature requests and report bugs. For all other general support or questions, feel free to contact us directly.","title":"Contribute"},{"location":"community-and-contribution/#contribute","text":"Our team works closely with collaborators and staff scientists at the NIH to develop Pipeliner. We understand that to deliver the best pipelines, we must get the community involved. We would love to hear your feedback and your ideas. Our pipelines are built upon layers of open-source tools and other community-driven projects. We are constantly testing and benchmarking new tools. If you would like to collaborate with us, please reach out to our team and checkout our roadmap. Let's build together!","title":"Contribute"},{"location":"community-and-contribution/#roadmap","text":"As an open-source project, transparency is very important to our team. That is why we try to share as much information as possible regarding current and future development. Please checkout Github Projects for insights into our development roadmap. If you would like to contribute to this project, feel free to email us. We welcome new contributions!","title":"Roadmap"},{"location":"community-and-contribution/#improve-pipeliner","text":"Feel free to open an issue on GitHub to make feature requests and report bugs. For all other general support or questions, feel free to contact us directly.","title":"Improve Pipeliner"},{"location":"contact-us/","text":"Contact Us \u00b6 Pipeliner is maintained by the development teams at CCBR and NCBR and is improved by feedback from external collaborators like you. We want to make it easy for users to connect with us to share ideas, solve problems, and to continuously deliver the best pipelines. Here are the best ways to get in contact with us. General questions \u00b6 For all general support and questions, please contact us through email . Please do not open an issue on Github for a general question. Feature requests and issues \u00b6 Please create a new issue on GitHub if you have a feature request, or if you are observing unexpected behavior when running Pipeliner.","title":"Contact"},{"location":"contact-us/#contact-us","text":"Pipeliner is maintained by the development teams at CCBR and NCBR and is improved by feedback from external collaborators like you. We want to make it easy for users to connect with us to share ideas, solve problems, and to continuously deliver the best pipelines. Here are the best ways to get in contact with us.","title":"Contact Us"},{"location":"contact-us/#general-questions","text":"For all general support and questions, please contact us through email . Please do not open an issue on Github for a general question.","title":"General questions"},{"location":"contact-us/#feature-requests-and-issues","text":"Please create a new issue on GitHub if you have a feature request, or if you are observing unexpected behavior when running Pipeliner.","title":"Feature requests and issues"},{"location":"license/","text":"MIT License \u00b6 Copyright \u00a9 2020 CCBR and NCBR Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#mit-license","text":"Copyright \u00a9 2020 CCBR and NCBR Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"troubleshooting/","text":"If you are experiencing an issue, please read through this list first before contacting our team. We have compiled this FAQ from the most common problems. If you are running into an issue that is not on this page, please feel free to reach out to our team . General questions \u00b6 Q. Why am I getting a message saying \"_tkinter.TclError: no display name and no $DISPLAY environment variable\" ? A. This may be due to logging into Biowulf without enabling X11 forwarding. X11 is needed to instantiate Pipeliner's tkinter-based graphical user interface. To enable X11 forwarding, please use the -Y flag when logging into Biowulf: # Enable X11 forwarding ssh -Y $USER @biowulf.nih.gov After re-logging into Biowulf with -Y , we can check if enabling X11 solved the problem. You can check this by running xeyes after logging into Biowulf. If everything is properly setup, you will be greeted by a set of cartoon eyes that follows position of your mouse. If you are still receiving error messages, this is an indication that you do not have X-windows software installed on your local machine. Here are instruction to install an X11 client. Install X11 client macOS XQuartz As of OS X 10.6 , X11 is no longer included with the mac's OS. The X11 server and client libraries for OS X are available from the XQuartz project . Please download the latest available version of XQuartz that is compatible with your operating system. Windows NoMachine (NX) Windows users can install the X-window client NoMachine (NX). Graphical applications can display within the NoMachine window, and terminal sessions can be saved and reconnected in a persistent manner. Please download the latest NX client. Here are some more details from HPC staff to help you getting started with NoMachine: # Configuration for Helix or Biowulf To set up a new connection: Click 'New' from the top menu. Protocol: Set the Protocol to SSH. Host: Set the Host to either helix.nih.gov or biowulf.nih.gov. The port must be 22. Authentication: Choose Use the system login. Authentication: Choose Password. Proxy: Choose Don't use a proxy. Save as: Any choice is a good choice. Once the connection is set, double click on the connection and enter your username and password. NOTE: Never check the \"Save Your Password\" button. Once the login is successful and a connection has been established, a session must be chosen or created. If this is the first time, or no previous sessions are available, click \"Create a new virtual desktop\". Save the setting in the connection file. Otherwise, choose the previous session to open. Please see NoMachine's documentation for more information. Job Status \u00b6 Q. How do I know if Pipeliner finished running successfully? A. There are several different ways of checking the status of each job submitted to the cluster. Here are a few suggestions: Check Job Status HPC Dashboard You can check the status of Biowulf jobs through the your user dashboard . Each job that Pipeliner submits to the cluster starts with the pl: prefix. Snakemake Log Snakemake generates the following file, Reports/snakemake.log , in each pipeline's working directory. This file contains information about each job submitted to the job scheduler. If there are no problems, snakemake will report 100% steps done in those last few lines of the file. You can take a peek of the end of the file by running the following command: tail -n30 Reports/snakemake.log Or more specifically, you can pull out the timestamps of the last few completed jobs like this: grep -A 1 done Reports/snakemake.log | tail Query Job Scheduler SLURM has built-in commands that allow a user to view the status of jobs submitted to the cluster. Method 1: To see what jobs you have running, run the following command: squeue -u $USER Method 2 You can also run this alternative command to check the status of your running jobs: sjobs Each job that Pipeliner submits to the cluster starts with the pl: prefix. Q. How do I identify failed jobs? A. If there are errors, you'll need to identify which jobs failed and check its corresponding SLURM output file. The SLURM output file may contain a clue as to why the job failed. Find Failed Jobs HPC Usage Table Pipeliner gathers runtime statistics for each job submitted to the cluster. This information is aggregated in a file called HPC_usage_table.txt . The fourth column of this tab-delimited file contains the job state. If the job successfully finished, it will be listed as COMPLETED . awk -F '\\t' '(NR==1) || ($4==\"COMPLETED\") {print}' HPC_usage_table.txt This file also contains information about memory usage and other resources allocated at submission. This file can be used to determine if the job needs to be re-submitted with higher memory or an increased walltime. SLURM output files Quick and dirty method to search for failed jobs by looking through each job's output file: grep -i 'fail' slurmfiles/slurm-*.out Snakemake Log Bash script identify the SLURM ID of the first failed job and check if the output file exists. Many failures are caused by filesystem or network issues on Biowulf, and in such cases, simply re-starting the Pipeline should resolve the issue. Snakemake will dynamically determine which steps have been completed, and which steps still need to be run. If you are still running into problems after re-running the pipeline, there may be another issue. If that is the case, please feel free to contact us . Q. How do I cancel ongoing Pipeliner jobs? A. Sometimes, you might need to manually stop a Pipeliner run prematurely, perhaps because the run was configured incorrectly or if a job is stalled. Although the walltime limits will eventually stop the workflow, this can take up to 5 or 10 days depending on the pipeline. To stop Pipeliner jobs that are currently running, you can follow these options. Cancel running jobs Manual Inspection You can use the sjobs tool provided by Biowulf to monitor ongoing jobs. Examine the NAME column of the sjobs output, one of them should match what you entered as the 'Project Id' in the Project Information section of the Pipeliner GUI. This is the \"primary\" job that coordinates secondary job submissions as steps are completed. Terminating this job will ensure that the pipeline is cancelled; however, you will likely need to unlock the working directory before re-running Pipeliner again. Please see our instructions below in Error: Directory cannot be locked for how to unlock a working directory. You can manually cancel the primary job using scancel . However, secondary jobs that are already running will continue to completion (or failure). To stop them immediately, you will need to run scancel individually for each secondary job. See the next tab for a bash script that tries to automate this process. Bash Script When there are lots of secondary jobs running, or if you have multiple Pipeliner runs ongoing simultaneously, it's not feasible to manually cancel jobs based on the sjobs output (see previous tab). We provide a script that will parse the snakemake log file and cancel all jobs listed within. ## Download the script (to the current directory) wget https://raw.githubusercontent.com/CCBR/Tools/master/Biowulf/cancel_snakemake_jobs.sh ## Run the script bash cancel_snakemake_jobs.sh /path/to/snakemake.log The script accepts one argument, which should be the path to the snakemake log file. This will work for any log output from Snakemake version 5.1.3 . This script will NOT cancel the primary job, which you will still have to identify and cancel manually, as described in the previous tab. Once you've ensured that all running jobs have been stopped, you need to unlock the working directory (see below ), and re-run Pipeliner to continue the workflow. Job Errors \u00b6 Q. Why am I getting sbatch: command not found error ? A. Are you running the ccbrpipeliner/4.0 on helix.nih.gov by mistake. Helix does not have a job scheduler. One may be able to fire up the ccbrpipeliner module, initial working directory and perform dry-run on helix . But to submit jobs (Run button), you need to log into biowulf using ssh -Y username@biowulf.nih.gov . Q. Why am I getting a message saying Error: Directory cannot be locked. ... when I do the dry-run? A. This is caused when a run is stopped prematurely, either accidentally or on purpose, or the pipeline is still running in your working directory. Snakemake will lock a working directory to prevent two concurrent pipelines from writing to the same location. This can be remedied easily by running snakemake --unlock , but the version of snakemake needs to match what Pipeliner uses (which is no longer the default on Biowulf). Please check to see if the pipeline is still running prior to running the commands below. If you would like to cancel a submitted or running pipeline, please reference the instructions above. # Navigate to working directory cd /path/to/working/dir # Load the right version of snakemake modue load snakemake/5.1.3 # Unlock the working directory snakemake --unlock Q. Why am I getting a message saying MissingInputException in line ... when I do the dry-run? A. This error usually occurs when snakemake is terminated ungracefully. Did you forcefully cancel a running pipeline? Or did one of your running pipelines abruptly end? Either way, the solution is straight-forward. Please go to your pipeline's output directory, and rename or delete the following hidden directory: .snakemake/ . This directory contains metadata pertaining any snakemake runs inside that working directory. Sometimes when a pipeline is pre-maturely or forcefully terminated, a few files related to tracking temp() files are not deleted and snakemake raises a MissingInputException. # Navigate to working directory cd /path/to/working/dir # Rename .snakemake directory to something else # And try re-dry running the pipeline mv .snakemake .old_snakemake","title":"Troubleshooting"},{"location":"troubleshooting/#general-questions","text":"Q. Why am I getting a message saying \"_tkinter.TclError: no display name and no $DISPLAY environment variable\" ? A. This may be due to logging into Biowulf without enabling X11 forwarding. X11 is needed to instantiate Pipeliner's tkinter-based graphical user interface. To enable X11 forwarding, please use the -Y flag when logging into Biowulf: # Enable X11 forwarding ssh -Y $USER @biowulf.nih.gov After re-logging into Biowulf with -Y , we can check if enabling X11 solved the problem. You can check this by running xeyes after logging into Biowulf. If everything is properly setup, you will be greeted by a set of cartoon eyes that follows position of your mouse. If you are still receiving error messages, this is an indication that you do not have X-windows software installed on your local machine. Here are instruction to install an X11 client. Install X11 client macOS XQuartz As of OS X 10.6 , X11 is no longer included with the mac's OS. The X11 server and client libraries for OS X are available from the XQuartz project . Please download the latest available version of XQuartz that is compatible with your operating system. Windows NoMachine (NX) Windows users can install the X-window client NoMachine (NX). Graphical applications can display within the NoMachine window, and terminal sessions can be saved and reconnected in a persistent manner. Please download the latest NX client. Here are some more details from HPC staff to help you getting started with NoMachine: # Configuration for Helix or Biowulf To set up a new connection: Click 'New' from the top menu. Protocol: Set the Protocol to SSH. Host: Set the Host to either helix.nih.gov or biowulf.nih.gov. The port must be 22. Authentication: Choose Use the system login. Authentication: Choose Password. Proxy: Choose Don't use a proxy. Save as: Any choice is a good choice. Once the connection is set, double click on the connection and enter your username and password. NOTE: Never check the \"Save Your Password\" button. Once the login is successful and a connection has been established, a session must be chosen or created. If this is the first time, or no previous sessions are available, click \"Create a new virtual desktop\". Save the setting in the connection file. Otherwise, choose the previous session to open. Please see NoMachine's documentation for more information.","title":"General questions"},{"location":"troubleshooting/#job-status","text":"Q. How do I know if Pipeliner finished running successfully? A. There are several different ways of checking the status of each job submitted to the cluster. Here are a few suggestions: Check Job Status HPC Dashboard You can check the status of Biowulf jobs through the your user dashboard . Each job that Pipeliner submits to the cluster starts with the pl: prefix. Snakemake Log Snakemake generates the following file, Reports/snakemake.log , in each pipeline's working directory. This file contains information about each job submitted to the job scheduler. If there are no problems, snakemake will report 100% steps done in those last few lines of the file. You can take a peek of the end of the file by running the following command: tail -n30 Reports/snakemake.log Or more specifically, you can pull out the timestamps of the last few completed jobs like this: grep -A 1 done Reports/snakemake.log | tail Query Job Scheduler SLURM has built-in commands that allow a user to view the status of jobs submitted to the cluster. Method 1: To see what jobs you have running, run the following command: squeue -u $USER Method 2 You can also run this alternative command to check the status of your running jobs: sjobs Each job that Pipeliner submits to the cluster starts with the pl: prefix. Q. How do I identify failed jobs? A. If there are errors, you'll need to identify which jobs failed and check its corresponding SLURM output file. The SLURM output file may contain a clue as to why the job failed. Find Failed Jobs HPC Usage Table Pipeliner gathers runtime statistics for each job submitted to the cluster. This information is aggregated in a file called HPC_usage_table.txt . The fourth column of this tab-delimited file contains the job state. If the job successfully finished, it will be listed as COMPLETED . awk -F '\\t' '(NR==1) || ($4==\"COMPLETED\") {print}' HPC_usage_table.txt This file also contains information about memory usage and other resources allocated at submission. This file can be used to determine if the job needs to be re-submitted with higher memory or an increased walltime. SLURM output files Quick and dirty method to search for failed jobs by looking through each job's output file: grep -i 'fail' slurmfiles/slurm-*.out Snakemake Log Bash script identify the SLURM ID of the first failed job and check if the output file exists. Many failures are caused by filesystem or network issues on Biowulf, and in such cases, simply re-starting the Pipeline should resolve the issue. Snakemake will dynamically determine which steps have been completed, and which steps still need to be run. If you are still running into problems after re-running the pipeline, there may be another issue. If that is the case, please feel free to contact us . Q. How do I cancel ongoing Pipeliner jobs? A. Sometimes, you might need to manually stop a Pipeliner run prematurely, perhaps because the run was configured incorrectly or if a job is stalled. Although the walltime limits will eventually stop the workflow, this can take up to 5 or 10 days depending on the pipeline. To stop Pipeliner jobs that are currently running, you can follow these options. Cancel running jobs Manual Inspection You can use the sjobs tool provided by Biowulf to monitor ongoing jobs. Examine the NAME column of the sjobs output, one of them should match what you entered as the 'Project Id' in the Project Information section of the Pipeliner GUI. This is the \"primary\" job that coordinates secondary job submissions as steps are completed. Terminating this job will ensure that the pipeline is cancelled; however, you will likely need to unlock the working directory before re-running Pipeliner again. Please see our instructions below in Error: Directory cannot be locked for how to unlock a working directory. You can manually cancel the primary job using scancel . However, secondary jobs that are already running will continue to completion (or failure). To stop them immediately, you will need to run scancel individually for each secondary job. See the next tab for a bash script that tries to automate this process. Bash Script When there are lots of secondary jobs running, or if you have multiple Pipeliner runs ongoing simultaneously, it's not feasible to manually cancel jobs based on the sjobs output (see previous tab). We provide a script that will parse the snakemake log file and cancel all jobs listed within. ## Download the script (to the current directory) wget https://raw.githubusercontent.com/CCBR/Tools/master/Biowulf/cancel_snakemake_jobs.sh ## Run the script bash cancel_snakemake_jobs.sh /path/to/snakemake.log The script accepts one argument, which should be the path to the snakemake log file. This will work for any log output from Snakemake version 5.1.3 . This script will NOT cancel the primary job, which you will still have to identify and cancel manually, as described in the previous tab. Once you've ensured that all running jobs have been stopped, you need to unlock the working directory (see below ), and re-run Pipeliner to continue the workflow.","title":"Job Status"},{"location":"troubleshooting/#job-errors","text":"Q. Why am I getting sbatch: command not found error ? A. Are you running the ccbrpipeliner/4.0 on helix.nih.gov by mistake. Helix does not have a job scheduler. One may be able to fire up the ccbrpipeliner module, initial working directory and perform dry-run on helix . But to submit jobs (Run button), you need to log into biowulf using ssh -Y username@biowulf.nih.gov . Q. Why am I getting a message saying Error: Directory cannot be locked. ... when I do the dry-run? A. This is caused when a run is stopped prematurely, either accidentally or on purpose, or the pipeline is still running in your working directory. Snakemake will lock a working directory to prevent two concurrent pipelines from writing to the same location. This can be remedied easily by running snakemake --unlock , but the version of snakemake needs to match what Pipeliner uses (which is no longer the default on Biowulf). Please check to see if the pipeline is still running prior to running the commands below. If you would like to cancel a submitted or running pipeline, please reference the instructions above. # Navigate to working directory cd /path/to/working/dir # Load the right version of snakemake modue load snakemake/5.1.3 # Unlock the working directory snakemake --unlock Q. Why am I getting a message saying MissingInputException in line ... when I do the dry-run? A. This error usually occurs when snakemake is terminated ungracefully. Did you forcefully cancel a running pipeline? Or did one of your running pipelines abruptly end? Either way, the solution is straight-forward. Please go to your pipeline's output directory, and rename or delete the following hidden directory: .snakemake/ . This directory contains metadata pertaining any snakemake runs inside that working directory. Sometimes when a pipeline is pre-maturely or forcefully terminated, a few files related to tracking temp() files are not deleted and snakemake raises a MissingInputException. # Navigate to working directory cd /path/to/working/dir # Rename .snakemake directory to something else # And try re-dry running the pipeline mv .snakemake .old_snakemake","title":"Job Errors"},{"location":"ChIP-seq/ChIP-seq-output-files/","text":"Phase 1 of the ChIP-seq pipeline \u00b6 Successful completion of Phase 1 of the ChIPseq tutorial demo data will create the following file/folder structure: Rawdata files \u00b6 Symlinks to the raw fastq files: <working_dir> \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.fastq.gz -> /data/CCBR_Pipeliner/testdata/chipseq//SRR3081748_1.fastq.gz \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2.R1.fastq.gz -> /data/CCBR_Pipeliner/testdata/chipseq//SRR3081749_1.fastq.gz \u251c\u2500\u2500 ... \u251c\u2500\u2500 ... Sequencing quality and contamination assessments: \u00b6 FastQC \u00b6 rawfastqc and fastqc folders contains sequencing quality assessment results using fastqc for raw and preprocess fastq files. Each file has a .zip archive and a .html report. These results are also summarized across samples in the multiqc_report.html file. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 rawfastQC \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1_fastqc.html \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1_fastqc.zip \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 fastQC \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_fastqc.html \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_fastqc.zip \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... FastQScreen \u00b6 1 million reads from each sample are screened against the following database using Fastqscreen : Human Mouse Bacteria Fungi Viruses UniVec Ribosomal sequences The results are saved in the FQscreen and FQscreen2 folders. You can expect 6 files per sample as shown the example below: <working_dir> \u2502 \u2502 \u251c\u2500\u2500 FQscreen \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_screen.html \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_screen.png \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_screen.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 FQscreen2 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_screen.html \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_screen.png \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_screen.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... Kraken/Krona \u00b6 Kraken provides a k-mer based approach which assigns each read to a bacterial reference in an \"all known bacterial species\" database. These are reported in the *.taxa.txt files per sample. These assignments can then be interactively visualized in a html file using Krona . <working_dir> \u2502 \u2502 \u251c\u2500\u2500 kraken \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.trim.fastq.kraken_bacteria.krona.html \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.trim.fastq.kraken_bacteria.taxa.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... ChIP quality and replicate concordance assessments \u00b6 Deeptools outputs \u00b6 deeptools` folder has the following set of files for each group (a group includes all replicates for that group including input samples): fingerprint plot related files: fingerprint.metrics.Q5DD.tsv : fingerprint plot stats fingerprint.Q5DD.pdf : fingerprint plot with Q5DD data fingerprint.sorted.pdf : fingerprint plot with unfiltered data heatmap and profile plots focused on various genomic loci: metagene : all genes in the genome normalized by gene length prot.metagene : same as above but focused on protein-coding genes only TSS : around transcription start sites of all genes prot.TSS : same as above but focused on protein-coding genes only <working_dir> \u2502 \u2502 \u251c\u2500\u2500 deeptools \u2502 \u251c\u2500\u2500 Macrophage_p20.fingerprint.metrics.Q5DD.tsv \u2502 \u251c\u2500\u2500 Macrophage_p20.fingerprint.Q5DD.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.fingerprint.sorted.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.metagene_heatmap.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.metagene_heatmap.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.metagene_profile.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.metagene_profile.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.metagene_heatmap.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.metagene_heatmap.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.metagene_profile.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.metagene_profile.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.TSS_heatmap.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.TSS_heatmap.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.TSS_profile.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.TSS_profile.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.TSS_heatmap.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.TSS_heatmap.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.TSS_profile.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.TSS_profile.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... deeptools folder sorted_fingerprint subfolder with fingerprint stats for unfiltered bam files. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 deeptools \u2502 \u251c\u2500\u2500 sorted_fingerprint \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p20.fingerprint.metrics.sorted.tsv \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3.fingerprint.metrics.sorted.tsv \u2502 \u2502 \u2514\u2500\u2500 MEF_p20.fingerprint.metrics.sorted.tsv deeptools folder contains principle component analysis plots with all samples. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 deeptools \u2502 \u251c\u2500\u2500 pca.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 pca.sorted.RPGC.pdf deeptools folder also contain spearman correlation plots (heatmaps and scatterplots) with all samples <working_dir> \u2502 \u2502 \u251c\u2500\u2500 deeptools \u2502 \u251c\u2500\u2500 spearman_heatmap.Q5DD.RPGC_mqc.png \u2502 \u251c\u2500\u2500 spearman_heatmap.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 spearman_heatmap.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 spearman_scatterplot.Q5DD.RPGC.pdf \u2502 \u2514\u2500\u2500 spearman_scatterplot.sorted.RPGC.pdf ChIP-seq relevant QC \u00b6 QC folder contains more ChIP-seq relevant qc metrics. For eg. Preseq is used to assess library complexity. NGSQC is used to compare ChIP quality between replicates/samples. These results are also summarized per group. QCTable.txt neatly aggregrates all the QC metrics into a single tab-delimited file which can be easily read into Microsoft Excel. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 QC \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.ccurve \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.preseq.dat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.preseq.log \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.NGSQC_report.txt \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.NGSQC.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 Macrophage_p20.NGSQC.Q5DD.png \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u2502 \u2514\u2500\u2500 QCTable.txt Multiqc report \u00b6 Along with some other housekeeping files the Reports folder contains the multiqc_report.html which graphically aggregates all QC assestments into one report. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 Reports \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 multiqc_data \u2502 \u2502 \u251c\u2500\u2500 multiqc_bcbio_metrics.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_chip-specific_qc_metrics.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_data.json \u2502 \u2502 \u251c\u2500\u2500 multiqc_fastqc.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_fastq_screen.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_general_stats.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc.log \u2502 \u2502 \u251c\u2500\u2500 multiqc_samtools_flagstat.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_samtools_idxstats.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_sources.txt \u2502 \u2502 \u251c\u2500\u2500 seqbuster_isomirs.txt \u2502 \u2502 \u2514\u2500\u2500 seqbuster_mirs.txt \u2502 \u251c\u2500\u2500 multiqc_report.html \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... Alignment and Visualization files: \u00b6 Bams \u00b6 bam folder has following files for each sample: .bam : binary version of the alignment file. There are 3 versions of alignment files: sorted.bam : all alignments sorted by coordinates Q5.bam : sorted alignments filtered to exclude alignments with MAPQ<5 Q5DD.bam : deduplicated version of the Q5.bam file Each of the .bam files may also have the following secondary files: .bai : index for the .bam file .flagstat : file containing the alignment statistics .idxstat : file containing number of reads aligning per chromosome .ppqt : cross-correlation statistics .pdf : cross-correlation plots .tagAlign.gz : alignments in bed format for downstream peak calling by MACS2 <working_dir> \u2502 \u2502 \u251c\u2500\u2500 bam \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5.bam.bai \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5.bam.flagstat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5.bam.idxstat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.bam \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.bam.bai \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.bam.flagstat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.bam.idxstat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.pdf \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.ppqt \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.tagAlign.gz \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.bam \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.bam.bai \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.bam.flagstat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.bam.idxstat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.pdf \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.ppqt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... Bigwigs \u00b6 .bigwig folder contains alignments in bigwig format which is smaller than bam format and easy for quick visualizations using genome browsers like IGV . Each sample has 3 bigwig files: .sorted.RPGC.bw : created by normalizing the corresponding .sorted.bam file to 1X genome coverage .Q5DD.RPGC.bw : created by normalizing the corresponding .Q5DD.bam file to 1X genome coverage .Q5DD.RPGC.inputnorm.bw : created by subtracting the normalized input bigwig file from the normalized ChIP bigwig <working_dir> \u2502 \u2502 \u251c\u2500\u2500 bigwig \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.RPGC.bw \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.RPGC.inputnorm.bw \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.RPGC.bw \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... Other important files \u00b6 Some of the other important files in the working_dir are: cluster.json : outlines the resources requested for each Snakemake rule Snakefile : contains all the Snakemake rules HPC_usage_table.txt : tabular report of how each Snakemake rule utilized the HPC cluster with details run.json : json file saving all GUI selections peakcall.tab : tab-delimited file defining which samples are ChIP and what are their corresponding input samples <working_dir> \u2502 \u2502 \u251c\u2500\u2500 cluster.json \u251c\u2500\u2500 Snakefile \u251c\u2500\u2500 HPC_usage_table.txt \u251c\u2500\u2500 run.json \u251c\u2500\u2500 peakcall.tab \u251c\u2500\u2500 ... \u251c\u2500\u2500 ... All other folder and files in the working_dir are for housekeeping and are required for successful execution of the CCBR_Pipeliner. Phase 2 of the ChIP-seq pipeline \u00b6 Successful completion of Phase 2 of the ChIPseq tutorial demo data will create the following file/folder structure in addition to the files created in Phase 1: Peak calls: \u00b6 GEM \u00b6 gem folder has a subfolder for each sample, which should contain the files ending with GEM_events.narrowPeak which represent the peak calls from GEM in narrowPeak format. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 gem \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.GEM_events.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.GEM_events.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.GPS_events.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.GPS_events.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_outputs \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... MACS2 for broad peaks \u00b6 macs2Broad folder has a subfolder for each sample, which should contain the files ending with .broadPeak which represent the peak calls from macs2 in broadPeak format. The peaks are also available in Excel format. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 macsBroad \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_peaks.broadPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_peaks.gappedPeak \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_1_peaks.xls \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_peaks.broadPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_peaks.gappedPeak \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_2_peaks.xls \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_peaks.broadPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_peaks.gappedPeak \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_1_peaks.xls \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_peaks.broadPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_peaks.gappedPeak \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_2_peaks.xls \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_peaks.broadPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_peaks.gappedPeak \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_1_peaks.xls \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_2 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_2_peaks.broadPeak \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_2_peaks.gappedPeak \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_2_peaks.xls MACS2 for narrow peaks \u00b6 macs2Narrow folder has a subfolder for each sample, which should contain the files ending with .narrowPeak which represent the peak calls from macs2 in narrowPeak format. The peaks are also available in Excel format, along with peak summits in bed format. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 macsNarrow \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_peaks.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_peaks.xls \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_1_summits.bed \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_peaks.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_peaks.xls \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_2_summits.bed \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_peaks.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_peaks.xls \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_1_summits.bed \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_peaks.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_peaks.xls \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_2_summits.bed \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_peaks.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_peaks.xls \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_1_summits.bed \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_2 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_2_peaks.narrowPeak \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_2_peaks.xls \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_2_summits.bed Sicer \u00b6 sicer folder has a subfolder for each sample which contains the peakcalls from sicer in bed , broadPeak and tabular formats. \u251c\u2500\u2500 sicer \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_broadpeaks.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_broadpeaks.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_1_sicer.broadPeak \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_broadpeaks.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_broadpeaks.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_2_sicer.broadPeak \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_broadpeaks.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_broadpeaks.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_1_sicer.broadPeak \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_broadpeaks.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_broadpeaks.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_2_sicer.broadPeak \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_broadpeaks.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_broadpeaks.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_1_sicer.broadPeak \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_2 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_2_broadpeaks.bed \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_2_broadpeaks.txt \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_2_sicer.broadPeak Peaks-based QC \u00b6 FRiP/Jaccard \u00b6 FRiP and jaccard barplots/scatterplots/table are saved in the PeakQC folder for each of the peak callers: gem macs broad narrow sicer <working_dir> \u2502 \u2502 \u251c\u2500\u2500 PeakQC \u2502 \u251c\u2500\u2500 gem.FRiP_barplot.png \u2502 \u251c\u2500\u2500 gem.FRiP_scatterplot.png \u2502 \u251c\u2500\u2500 gem.FRiP_table.txt \u2502 \u251c\u2500\u2500 gem.jaccard_heatmap.pdf \u2502 \u251c\u2500\u2500 gem.jaccard_PCA.pdf \u2502 \u251c\u2500\u2500 gem_jaccard.txt \u2502 \u251c\u2500\u2500 macsBroad.FRiP_barplot.png \u2502 \u251c\u2500\u2500 macsBroad.FRiP_scatterplot.png \u2502 \u251c\u2500\u2500 macsBroad.FRiP_table.txt \u2502 \u251c\u2500\u2500 macsBroad.jaccard_heatmap.pdf \u2502 \u251c\u2500\u2500 macsBroad.jaccard_PCA.pdf \u2502 \u251c\u2500\u2500 macsBroad_jaccard.txt \u2502 \u251c\u2500\u2500 macsNarrow.FRiP_barplot.png \u2502 \u251c\u2500\u2500 macsNarrow.FRiP_scatterplot.png \u2502 \u251c\u2500\u2500 macsNarrow.FRiP_table.txt \u2502 \u251c\u2500\u2500 macsNarrow.jaccard_heatmap.pdf \u2502 \u251c\u2500\u2500 macsNarrow.jaccard_PCA.pdf \u2502 \u251c\u2500\u2500 macsNarrow_jaccard.txt \u2502 \u251c\u2500\u2500 sicer.FRiP_barplot.png \u2502 \u251c\u2500\u2500 sicer.FRiP_scatterplot.png \u2502 \u251c\u2500\u2500 sicer.FRiP_table.txt \u2502 \u251c\u2500\u2500 sicer.jaccard_heatmap.pdf \u2502 \u251c\u2500\u2500 sicer.jaccard_PCA.pdf \u2502 \u2514\u2500\u2500 sicer_jaccard.txt The above files allow you to make inter-sample comparison for a peak caller at a time. If you want to compare accross peak caller then you can you the following files in PeakQC folder. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 PeakQC \u2502 \u251c\u2500\u2500 jaccard_heatmap.pdf \u2502 \u251c\u2500\u2500 jaccard_PCA.pdf \u2502 \u2514\u2500\u2500 jaccard.txt Replicate concordance with IDR \u00b6 IDR folder contains the outputs generated by comparing replicates peaks using idr for the following peak callers: sicer macs2 broad narrow Please note that IDR is not run for GEM. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 IDR \u2502 \u251c\u2500\u2500 macsBroad \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p20 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_vs_CTCF_ChIP_macrophage_p20_2.idrValue.txt \u2502 \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_1_vs_CTCF_ChIP_macrophage_p20_2.idrValue.txt.png \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_vs_CTCF_ChIP_macrophage_p3_2.idrValue.txt \u2502 \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_1_vs_CTCF_ChIP_macrophage_p3_2.idrValue.txt.png \u2502 \u2502 \u2514\u2500\u2500 MEF_p20 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_vs_CTCF_ChIP_MEF_p20_2.idrValue.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_1_vs_CTCF_ChIP_MEF_p20_2.idrValue.txt.png \u2502 \u251c\u2500\u2500 macsNarrow \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p20 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_vs_CTCF_ChIP_macrophage_p20_2.idrValue.txt \u2502 \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_1_vs_CTCF_ChIP_macrophage_p20_2.idrValue.txt.png \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_vs_CTCF_ChIP_macrophage_p3_2.idrValue.txt \u2502 \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_1_vs_CTCF_ChIP_macrophage_p3_2.idrValue.txt.png \u2502 \u2502 \u2514\u2500\u2500 MEF_p20 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_vs_CTCF_ChIP_MEF_p20_2.idrValue.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_1_vs_CTCF_ChIP_MEF_p20_2.idrValue.txt.png \u2502 \u2514\u2500\u2500 sicer \u2502 \u251c\u2500\u2500 Macrophage_p20 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_vs_CTCF_ChIP_macrophage_p20_2.idrValue.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_1_vs_CTCF_ChIP_macrophage_p20_2.idrValue.txt.png \u2502 \u251c\u2500\u2500 Macrophage_p3 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_vs_CTCF_ChIP_macrophage_p3_2.idrValue.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_1_vs_CTCF_ChIP_macrophage_p3_2.idrValue.txt.png \u2502 \u2514\u2500\u2500 MEF_p20 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_vs_CTCF_ChIP_MEF_p20_2.idrValue.txt \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_1_vs_CTCF_ChIP_MEF_p20_2.idrValue.txt.png Peak annotations with UROPA \u00b6 UROPA annotations are provided while prioritizing the following genomic features: all genes protein-coding genes transcription start sites of all genes transcription start sites of protein-coding genes Files are saved for all four peak callers (gem/macs2Narrow/macs2Broad/sicer) in individual subfolders for all called peaks. Similarly the DiffBind results are also annotated with UROPA in the DiffBind folder if any contrasts are provided at the time of running phase2 of the pipeline. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 UROPA_annotations \u2502 \u251c\u2500\u2500 gem \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.gem.genes.json \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.gem.prot.json \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.gem.TSSgenes.json \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.gem.TSSprot.json \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_genes_allhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_genes_finalhits.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_genes_finalhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_genes_summary.pdf \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_prot_allhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_prot_finalhits.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_prot_finalhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_prot_summary.pdf \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSgenes_allhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSgenes_finalhits.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSgenes_finalhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSgenes_summary.pdf \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSprot_allhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSprot_finalhits.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSprot_finalhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSprot_summary.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 macsNarrow \u2502 \u251c\u2500\u2500 macsBroad \u2502 \u251c\u2500\u2500 sicer \u2502 \u251c\u2500\u2500 DiffBind Motif analysis with HOMER \u00b6 de novo and known motif enrichment is performed using HOMER with the entire genome as background. The HOMER_motifs folder contains a subfolder for all four peak callers (gem/macsBroad/macsNarrow/sicer). Each of these subfolders further contain a subfolder per sample peak call as shown below: <working_dir> \u2502 \u2502 \u251c\u2500\u2500 HOMER_motifs \u2502 \u251c\u2500\u2500 macsBroad \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_macsBroad_GW \u2502 \u2502 \u2502 \u251c\u2500\u2500 homerMotifs.all.motifs \u2502 \u2502 \u2502 \u251c\u2500\u2500 homerMotifs.motifs10 \u2502 \u2502 \u2502 \u251c\u2500\u2500 homerMotifs.motifs12 \u2502 \u2502 \u2502 \u251c\u2500\u2500 homerMotifs.motifs8 \u2502 \u2502 \u2502 \u251c\u2500\u2500 homerResults \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2502 \u251c\u2500\u2500 homerResults.html \u2502 \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_macsBroad_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_macsBroad_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_macsBroad_GW \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 macsNarrow \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_macsNarrow_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_macsNarrow_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_macsNarrow_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_macsNarrow_GW \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 sicer \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_sicer_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_sicer_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_sicer_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_sicer_GW \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... DiffBind results (Optional) \u00b6 DiffBind is run for all contrast provided in the contrast.tab file using: DESeq2 EdgeR Each contrasts' results are saved in a separate subfolder along with a combined html report as shown below: <working_dir> \u2502 \u2502 \u251c\u2500\u2500 DiffBind \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem \u2502 \u2502 \u251c\u2500\u2500 DiffBind_pipeliner.Rmd \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem_Diffbind_Deseq2.bed \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem_Diffbind_Deseq2.txt \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem_Diffbind_EdgeR.bed \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem_Diffbind_EdgeR.txt \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem_Diffbind.html \u2502 \u2502 \u2514\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem_Diffbind_prep.csv \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-macsNarrow \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-macsBroad \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-sicer \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... Other important files \u00b6 Some of the other important files in the working_dir are: contrast.tab : if contrasts are supplied for running DiffBind , then they are saved in this tab-delimited file HPC_usage_table.txt : tabular report of how each Snakemake rule utilized the HPC cluster with details. The older version of this file from the phase1 execution is also retained by renaming it. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 ... \u251c\u2500\u2500 contrast.tab \u251c\u2500\u2500 HPC_usage_table.txt \u251c\u2500\u2500 HPC_usage_table.txt.2020_06_22_05_14_24 \u251c\u2500\u2500 ... \u251c\u2500\u2500 ... All other folder and files in the working_dir are for housekeeping and are required for successful execution of the CCBR_Pipeliner.","title":"Output Files"},{"location":"ChIP-seq/ChIP-seq-output-files/#phase-1-of-the-chip-seq-pipeline","text":"Successful completion of Phase 1 of the ChIPseq tutorial demo data will create the following file/folder structure:","title":"Phase 1 of the ChIP-seq pipeline"},{"location":"ChIP-seq/ChIP-seq-output-files/#rawdata-files","text":"Symlinks to the raw fastq files: <working_dir> \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.fastq.gz -> /data/CCBR_Pipeliner/testdata/chipseq//SRR3081748_1.fastq.gz \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2.R1.fastq.gz -> /data/CCBR_Pipeliner/testdata/chipseq//SRR3081749_1.fastq.gz \u251c\u2500\u2500 ... \u251c\u2500\u2500 ...","title":"Rawdata files"},{"location":"ChIP-seq/ChIP-seq-output-files/#sequencing-quality-and-contamination-assessments","text":"","title":"Sequencing quality and contamination assessments:"},{"location":"ChIP-seq/ChIP-seq-output-files/#fastqc","text":"rawfastqc and fastqc folders contains sequencing quality assessment results using fastqc for raw and preprocess fastq files. Each file has a .zip archive and a .html report. These results are also summarized across samples in the multiqc_report.html file. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 rawfastQC \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1_fastqc.html \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1_fastqc.zip \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 fastQC \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_fastqc.html \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_fastqc.zip \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ...","title":"FastQC"},{"location":"ChIP-seq/ChIP-seq-output-files/#fastqscreen","text":"1 million reads from each sample are screened against the following database using Fastqscreen : Human Mouse Bacteria Fungi Viruses UniVec Ribosomal sequences The results are saved in the FQscreen and FQscreen2 folders. You can expect 6 files per sample as shown the example below: <working_dir> \u2502 \u2502 \u251c\u2500\u2500 FQscreen \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_screen.html \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_screen.png \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_screen.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 FQscreen2 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_screen.html \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_screen.png \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.R1.trim_screen.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ...","title":"FastQScreen"},{"location":"ChIP-seq/ChIP-seq-output-files/#krakenkrona","text":"Kraken provides a k-mer based approach which assigns each read to a bacterial reference in an \"all known bacterial species\" database. These are reported in the *.taxa.txt files per sample. These assignments can then be interactively visualized in a html file using Krona . <working_dir> \u2502 \u2502 \u251c\u2500\u2500 kraken \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.trim.fastq.kraken_bacteria.krona.html \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.trim.fastq.kraken_bacteria.taxa.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ...","title":"Kraken/Krona"},{"location":"ChIP-seq/ChIP-seq-output-files/#chip-quality-and-replicate-concordance-assessments","text":"","title":"ChIP quality and replicate concordance assessments"},{"location":"ChIP-seq/ChIP-seq-output-files/#deeptools-outputs","text":"deeptools` folder has the following set of files for each group (a group includes all replicates for that group including input samples): fingerprint plot related files: fingerprint.metrics.Q5DD.tsv : fingerprint plot stats fingerprint.Q5DD.pdf : fingerprint plot with Q5DD data fingerprint.sorted.pdf : fingerprint plot with unfiltered data heatmap and profile plots focused on various genomic loci: metagene : all genes in the genome normalized by gene length prot.metagene : same as above but focused on protein-coding genes only TSS : around transcription start sites of all genes prot.TSS : same as above but focused on protein-coding genes only <working_dir> \u2502 \u2502 \u251c\u2500\u2500 deeptools \u2502 \u251c\u2500\u2500 Macrophage_p20.fingerprint.metrics.Q5DD.tsv \u2502 \u251c\u2500\u2500 Macrophage_p20.fingerprint.Q5DD.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.fingerprint.sorted.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.metagene_heatmap.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.metagene_heatmap.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.metagene_profile.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.metagene_profile.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.metagene_heatmap.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.metagene_heatmap.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.metagene_profile.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.metagene_profile.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.TSS_heatmap.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.TSS_heatmap.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.TSS_profile.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.prot.TSS_profile.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.TSS_heatmap.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.TSS_heatmap.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.TSS_profile.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 Macrophage_p20.TSS_profile.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... deeptools folder sorted_fingerprint subfolder with fingerprint stats for unfiltered bam files. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 deeptools \u2502 \u251c\u2500\u2500 sorted_fingerprint \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p20.fingerprint.metrics.sorted.tsv \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3.fingerprint.metrics.sorted.tsv \u2502 \u2502 \u2514\u2500\u2500 MEF_p20.fingerprint.metrics.sorted.tsv deeptools folder contains principle component analysis plots with all samples. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 deeptools \u2502 \u251c\u2500\u2500 pca.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 pca.sorted.RPGC.pdf deeptools folder also contain spearman correlation plots (heatmaps and scatterplots) with all samples <working_dir> \u2502 \u2502 \u251c\u2500\u2500 deeptools \u2502 \u251c\u2500\u2500 spearman_heatmap.Q5DD.RPGC_mqc.png \u2502 \u251c\u2500\u2500 spearman_heatmap.Q5DD.RPGC.pdf \u2502 \u251c\u2500\u2500 spearman_heatmap.sorted.RPGC.pdf \u2502 \u251c\u2500\u2500 spearman_scatterplot.Q5DD.RPGC.pdf \u2502 \u2514\u2500\u2500 spearman_scatterplot.sorted.RPGC.pdf","title":"Deeptools outputs"},{"location":"ChIP-seq/ChIP-seq-output-files/#chip-seq-relevant-qc","text":"QC folder contains more ChIP-seq relevant qc metrics. For eg. Preseq is used to assess library complexity. NGSQC is used to compare ChIP quality between replicates/samples. These results are also summarized per group. QCTable.txt neatly aggregrates all the QC metrics into a single tab-delimited file which can be easily read into Microsoft Excel. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 QC \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.ccurve \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.preseq.dat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.preseq.log \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.NGSQC_report.txt \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.NGSQC.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 Macrophage_p20.NGSQC.Q5DD.png \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u2502 \u2514\u2500\u2500 QCTable.txt","title":"ChIP-seq relevant QC"},{"location":"ChIP-seq/ChIP-seq-output-files/#multiqc-report","text":"Along with some other housekeeping files the Reports folder contains the multiqc_report.html which graphically aggregates all QC assestments into one report. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 Reports \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 multiqc_data \u2502 \u2502 \u251c\u2500\u2500 multiqc_bcbio_metrics.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_chip-specific_qc_metrics.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_data.json \u2502 \u2502 \u251c\u2500\u2500 multiqc_fastqc.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_fastq_screen.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_general_stats.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc.log \u2502 \u2502 \u251c\u2500\u2500 multiqc_samtools_flagstat.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_samtools_idxstats.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_sources.txt \u2502 \u2502 \u251c\u2500\u2500 seqbuster_isomirs.txt \u2502 \u2502 \u2514\u2500\u2500 seqbuster_mirs.txt \u2502 \u251c\u2500\u2500 multiqc_report.html \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ...","title":"Multiqc report"},{"location":"ChIP-seq/ChIP-seq-output-files/#alignment-and-visualization-files","text":"","title":"Alignment and Visualization files:"},{"location":"ChIP-seq/ChIP-seq-output-files/#bams","text":"bam folder has following files for each sample: .bam : binary version of the alignment file. There are 3 versions of alignment files: sorted.bam : all alignments sorted by coordinates Q5.bam : sorted alignments filtered to exclude alignments with MAPQ<5 Q5DD.bam : deduplicated version of the Q5.bam file Each of the .bam files may also have the following secondary files: .bai : index for the .bam file .flagstat : file containing the alignment statistics .idxstat : file containing number of reads aligning per chromosome .ppqt : cross-correlation statistics .pdf : cross-correlation plots .tagAlign.gz : alignments in bed format for downstream peak calling by MACS2 <working_dir> \u2502 \u2502 \u251c\u2500\u2500 bam \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5.bam.bai \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5.bam.flagstat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5.bam.idxstat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.bam \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.bam.bai \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.bam.flagstat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.bam.idxstat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.pdf \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.ppqt \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.tagAlign.gz \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.bam \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.bam.bai \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.bam.flagstat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.bam.idxstat \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.pdf \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.ppqt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ...","title":"Bams"},{"location":"ChIP-seq/ChIP-seq-output-files/#bigwigs","text":".bigwig folder contains alignments in bigwig format which is smaller than bam format and easy for quick visualizations using genome browsers like IGV . Each sample has 3 bigwig files: .sorted.RPGC.bw : created by normalizing the corresponding .sorted.bam file to 1X genome coverage .Q5DD.RPGC.bw : created by normalizing the corresponding .Q5DD.bam file to 1X genome coverage .Q5DD.RPGC.inputnorm.bw : created by subtracting the normalized input bigwig file from the normalized ChIP bigwig <working_dir> \u2502 \u2502 \u251c\u2500\u2500 bigwig \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.RPGC.bw \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.Q5DD.RPGC.inputnorm.bw \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.sorted.RPGC.bw \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ...","title":"Bigwigs"},{"location":"ChIP-seq/ChIP-seq-output-files/#other-important-files","text":"Some of the other important files in the working_dir are: cluster.json : outlines the resources requested for each Snakemake rule Snakefile : contains all the Snakemake rules HPC_usage_table.txt : tabular report of how each Snakemake rule utilized the HPC cluster with details run.json : json file saving all GUI selections peakcall.tab : tab-delimited file defining which samples are ChIP and what are their corresponding input samples <working_dir> \u2502 \u2502 \u251c\u2500\u2500 cluster.json \u251c\u2500\u2500 Snakefile \u251c\u2500\u2500 HPC_usage_table.txt \u251c\u2500\u2500 run.json \u251c\u2500\u2500 peakcall.tab \u251c\u2500\u2500 ... \u251c\u2500\u2500 ... All other folder and files in the working_dir are for housekeeping and are required for successful execution of the CCBR_Pipeliner.","title":"Other important files"},{"location":"ChIP-seq/ChIP-seq-output-files/#phase-2-of-the-chip-seq-pipeline","text":"Successful completion of Phase 2 of the ChIPseq tutorial demo data will create the following file/folder structure in addition to the files created in Phase 1:","title":"Phase 2 of the ChIP-seq pipeline"},{"location":"ChIP-seq/ChIP-seq-output-files/#peak-calls","text":"","title":"Peak calls:"},{"location":"ChIP-seq/ChIP-seq-output-files/#gem","text":"gem folder has a subfolder for each sample, which should contain the files ending with GEM_events.narrowPeak which represent the peak calls from GEM in narrowPeak format. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 gem \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.GEM_events.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.GEM_events.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.GPS_events.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.GPS_events.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_outputs \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ...","title":"GEM"},{"location":"ChIP-seq/ChIP-seq-output-files/#macs2-for-broad-peaks","text":"macs2Broad folder has a subfolder for each sample, which should contain the files ending with .broadPeak which represent the peak calls from macs2 in broadPeak format. The peaks are also available in Excel format. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 macsBroad \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_peaks.broadPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_peaks.gappedPeak \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_1_peaks.xls \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_peaks.broadPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_peaks.gappedPeak \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_2_peaks.xls \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_peaks.broadPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_peaks.gappedPeak \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_1_peaks.xls \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_peaks.broadPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_peaks.gappedPeak \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_2_peaks.xls \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_peaks.broadPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_peaks.gappedPeak \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_1_peaks.xls \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_2 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_2_peaks.broadPeak \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_2_peaks.gappedPeak \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_2_peaks.xls","title":"MACS2 for broad peaks"},{"location":"ChIP-seq/ChIP-seq-output-files/#macs2-for-narrow-peaks","text":"macs2Narrow folder has a subfolder for each sample, which should contain the files ending with .narrowPeak which represent the peak calls from macs2 in narrowPeak format. The peaks are also available in Excel format, along with peak summits in bed format. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 macsNarrow \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_peaks.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_peaks.xls \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_1_summits.bed \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_peaks.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_peaks.xls \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_2_summits.bed \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_peaks.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_peaks.xls \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_1_summits.bed \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_peaks.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_peaks.xls \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_2_summits.bed \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_peaks.narrowPeak \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_peaks.xls \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_1_summits.bed \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_2 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_2_peaks.narrowPeak \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_2_peaks.xls \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_2_summits.bed","title":"MACS2 for narrow peaks"},{"location":"ChIP-seq/ChIP-seq-output-files/#sicer","text":"sicer folder has a subfolder for each sample which contains the peakcalls from sicer in bed , broadPeak and tabular formats. \u251c\u2500\u2500 sicer \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_broadpeaks.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_broadpeaks.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_1_sicer.broadPeak \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_broadpeaks.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_broadpeaks.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_2_sicer.broadPeak \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_broadpeaks.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_broadpeaks.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_1_sicer.broadPeak \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_broadpeaks.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_broadpeaks.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_2_sicer.broadPeak \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_broadpeaks.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_broadpeaks.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_1_sicer.broadPeak \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_2 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_2_broadpeaks.bed \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_2_broadpeaks.txt \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_2_sicer.broadPeak","title":"Sicer"},{"location":"ChIP-seq/ChIP-seq-output-files/#peaks-based-qc","text":"","title":"Peaks-based QC"},{"location":"ChIP-seq/ChIP-seq-output-files/#fripjaccard","text":"FRiP and jaccard barplots/scatterplots/table are saved in the PeakQC folder for each of the peak callers: gem macs broad narrow sicer <working_dir> \u2502 \u2502 \u251c\u2500\u2500 PeakQC \u2502 \u251c\u2500\u2500 gem.FRiP_barplot.png \u2502 \u251c\u2500\u2500 gem.FRiP_scatterplot.png \u2502 \u251c\u2500\u2500 gem.FRiP_table.txt \u2502 \u251c\u2500\u2500 gem.jaccard_heatmap.pdf \u2502 \u251c\u2500\u2500 gem.jaccard_PCA.pdf \u2502 \u251c\u2500\u2500 gem_jaccard.txt \u2502 \u251c\u2500\u2500 macsBroad.FRiP_barplot.png \u2502 \u251c\u2500\u2500 macsBroad.FRiP_scatterplot.png \u2502 \u251c\u2500\u2500 macsBroad.FRiP_table.txt \u2502 \u251c\u2500\u2500 macsBroad.jaccard_heatmap.pdf \u2502 \u251c\u2500\u2500 macsBroad.jaccard_PCA.pdf \u2502 \u251c\u2500\u2500 macsBroad_jaccard.txt \u2502 \u251c\u2500\u2500 macsNarrow.FRiP_barplot.png \u2502 \u251c\u2500\u2500 macsNarrow.FRiP_scatterplot.png \u2502 \u251c\u2500\u2500 macsNarrow.FRiP_table.txt \u2502 \u251c\u2500\u2500 macsNarrow.jaccard_heatmap.pdf \u2502 \u251c\u2500\u2500 macsNarrow.jaccard_PCA.pdf \u2502 \u251c\u2500\u2500 macsNarrow_jaccard.txt \u2502 \u251c\u2500\u2500 sicer.FRiP_barplot.png \u2502 \u251c\u2500\u2500 sicer.FRiP_scatterplot.png \u2502 \u251c\u2500\u2500 sicer.FRiP_table.txt \u2502 \u251c\u2500\u2500 sicer.jaccard_heatmap.pdf \u2502 \u251c\u2500\u2500 sicer.jaccard_PCA.pdf \u2502 \u2514\u2500\u2500 sicer_jaccard.txt The above files allow you to make inter-sample comparison for a peak caller at a time. If you want to compare accross peak caller then you can you the following files in PeakQC folder. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 PeakQC \u2502 \u251c\u2500\u2500 jaccard_heatmap.pdf \u2502 \u251c\u2500\u2500 jaccard_PCA.pdf \u2502 \u2514\u2500\u2500 jaccard.txt","title":"FRiP/Jaccard"},{"location":"ChIP-seq/ChIP-seq-output-files/#replicate-concordance-with-idr","text":"IDR folder contains the outputs generated by comparing replicates peaks using idr for the following peak callers: sicer macs2 broad narrow Please note that IDR is not run for GEM. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 IDR \u2502 \u251c\u2500\u2500 macsBroad \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p20 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_vs_CTCF_ChIP_macrophage_p20_2.idrValue.txt \u2502 \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_1_vs_CTCF_ChIP_macrophage_p20_2.idrValue.txt.png \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_vs_CTCF_ChIP_macrophage_p3_2.idrValue.txt \u2502 \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_1_vs_CTCF_ChIP_macrophage_p3_2.idrValue.txt.png \u2502 \u2502 \u2514\u2500\u2500 MEF_p20 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_vs_CTCF_ChIP_MEF_p20_2.idrValue.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_1_vs_CTCF_ChIP_MEF_p20_2.idrValue.txt.png \u2502 \u251c\u2500\u2500 macsNarrow \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p20 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_vs_CTCF_ChIP_macrophage_p20_2.idrValue.txt \u2502 \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_1_vs_CTCF_ChIP_macrophage_p20_2.idrValue.txt.png \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_vs_CTCF_ChIP_macrophage_p3_2.idrValue.txt \u2502 \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_1_vs_CTCF_ChIP_macrophage_p3_2.idrValue.txt.png \u2502 \u2502 \u2514\u2500\u2500 MEF_p20 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_vs_CTCF_ChIP_MEF_p20_2.idrValue.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_1_vs_CTCF_ChIP_MEF_p20_2.idrValue.txt.png \u2502 \u2514\u2500\u2500 sicer \u2502 \u251c\u2500\u2500 Macrophage_p20 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_vs_CTCF_ChIP_macrophage_p20_2.idrValue.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p20_1_vs_CTCF_ChIP_macrophage_p20_2.idrValue.txt.png \u2502 \u251c\u2500\u2500 Macrophage_p3 \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_vs_CTCF_ChIP_macrophage_p3_2.idrValue.txt \u2502 \u2502 \u2514\u2500\u2500 CTCF_ChIP_macrophage_p3_1_vs_CTCF_ChIP_macrophage_p3_2.idrValue.txt.png \u2502 \u2514\u2500\u2500 MEF_p20 \u2502 \u251c\u2500\u2500 CTCF_ChIP_MEF_p20_1_vs_CTCF_ChIP_MEF_p20_2.idrValue.txt \u2502 \u2514\u2500\u2500 CTCF_ChIP_MEF_p20_1_vs_CTCF_ChIP_MEF_p20_2.idrValue.txt.png","title":"Replicate concordance with IDR"},{"location":"ChIP-seq/ChIP-seq-output-files/#peak-annotations-with-uropa","text":"UROPA annotations are provided while prioritizing the following genomic features: all genes protein-coding genes transcription start sites of all genes transcription start sites of protein-coding genes Files are saved for all four peak callers (gem/macs2Narrow/macs2Broad/sicer) in individual subfolders for all called peaks. Similarly the DiffBind results are also annotated with UROPA in the DiffBind folder if any contrasts are provided at the time of running phase2 of the pipeline. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 UROPA_annotations \u2502 \u251c\u2500\u2500 gem \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.gem.genes.json \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.gem.prot.json \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.gem.TSSgenes.json \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1.gem.TSSprot.json \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_genes_allhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_genes_finalhits.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_genes_finalhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_genes_summary.pdf \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_prot_allhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_prot_finalhits.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_prot_finalhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_prot_summary.pdf \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSgenes_allhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSgenes_finalhits.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSgenes_finalhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSgenes_summary.pdf \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSprot_allhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSprot_finalhits.bed \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSprot_finalhits.txt \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_gem_uropa_TSSprot_summary.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 macsNarrow \u2502 \u251c\u2500\u2500 macsBroad \u2502 \u251c\u2500\u2500 sicer \u2502 \u251c\u2500\u2500 DiffBind","title":"Peak annotations with UROPA"},{"location":"ChIP-seq/ChIP-seq-output-files/#motif-analysis-with-homer","text":"de novo and known motif enrichment is performed using HOMER with the entire genome as background. The HOMER_motifs folder contains a subfolder for all four peak callers (gem/macsBroad/macsNarrow/sicer). Each of these subfolders further contain a subfolder per sample peak call as shown below: <working_dir> \u2502 \u2502 \u251c\u2500\u2500 HOMER_motifs \u2502 \u251c\u2500\u2500 macsBroad \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_macsBroad_GW \u2502 \u2502 \u2502 \u251c\u2500\u2500 homerMotifs.all.motifs \u2502 \u2502 \u2502 \u251c\u2500\u2500 homerMotifs.motifs10 \u2502 \u2502 \u2502 \u251c\u2500\u2500 homerMotifs.motifs12 \u2502 \u2502 \u2502 \u251c\u2500\u2500 homerMotifs.motifs8 \u2502 \u2502 \u2502 \u251c\u2500\u2500 homerResults \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2502 \u251c\u2500\u2500 homerResults.html \u2502 \u2502 \u2502 \u251c\u2500\u2500 knownResults \u2502 \u2502 \u2502 \u251c\u2500\u2500 knownResults.html \u2502 \u2502 \u2502 \u251c\u2500\u2500 knownResults.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_macsBroad_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_macsBroad_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_macsBroad_GW \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 macsNarrow \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_macsNarrow_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_macsNarrow_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_macsNarrow_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_macsNarrow_GW \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 sicer \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_1_sicer_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p20_2_sicer_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_1_sicer_GW \u2502 \u2502 \u251c\u2500\u2500 CTCF_ChIP_macrophage_p3_2_sicer_GW \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ...","title":"Motif analysis with HOMER"},{"location":"ChIP-seq/ChIP-seq-output-files/#diffbind-results-optional","text":"DiffBind is run for all contrast provided in the contrast.tab file using: DESeq2 EdgeR Each contrasts' results are saved in a separate subfolder along with a combined html report as shown below: <working_dir> \u2502 \u2502 \u251c\u2500\u2500 DiffBind \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem \u2502 \u2502 \u251c\u2500\u2500 DiffBind_pipeliner.Rmd \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem_Diffbind_Deseq2.bed \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem_Diffbind_Deseq2.txt \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem_Diffbind_EdgeR.bed \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem_Diffbind_EdgeR.txt \u2502 \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem_Diffbind.html \u2502 \u2502 \u2514\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-gem_Diffbind_prep.csv \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-macsNarrow \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-macsBroad \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 Macrophage_p3_vs_Macrophage_p20-sicer \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ...","title":"DiffBind results (Optional)"},{"location":"ChIP-seq/ChIP-seq-output-files/#other-important-files_1","text":"Some of the other important files in the working_dir are: contrast.tab : if contrasts are supplied for running DiffBind , then they are saved in this tab-delimited file HPC_usage_table.txt : tabular report of how each Snakemake rule utilized the HPC cluster with details. The older version of this file from the phase1 execution is also retained by renaming it. <working_dir> \u2502 \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 ... \u251c\u2500\u2500 contrast.tab \u251c\u2500\u2500 HPC_usage_table.txt \u251c\u2500\u2500 HPC_usage_table.txt.2020_06_22_05_14_24 \u251c\u2500\u2500 ... \u251c\u2500\u2500 ... All other folder and files in the working_dir are for housekeeping and are required for successful execution of the CCBR_Pipeliner.","title":"Other important files"},{"location":"ChIP-seq/ChIP-seq-tools/","text":"Quality-control pipeline \u00b6 QC assessment tools \u00b6 Tool Version Notes FastQC 1 0.11.5 Assess sequencing quality, run before and after adapter trimming Kraken 2 1.1 Assess microbial taxonomic composition KronaTools 3 2.7 Visualize kraken output FastQ Screen 4 0.9.3 Assess contamination; additional dependencies: bowtie2/2.3.4, perl/5.24.3 Preseq 5 2.0.3 Estimate library complexity NGSQC 6 Infers a set of global QC indicators to asses data quality MultiQC 7 1.7 Aggregate sample statistics and quality-control information across all samples Data processing tools \u00b6 Tool Version Notes Cutadapt 8 1.18 Remove adapter sequences and perform quality trimming BWA 9 mem 0.7.17 Read alignment, first to identify reads aligning to blacklisted regions and later for the remainder of the genome Picard 10 2.17.11 Run SamToFastq (for blacklist read removal) and MarkDuplicates (to remove PCR duplicates in PE data) SAMtools 11 1.6 Remove reads with mapQ less than 6. Also run flagstat and idxstats to calculate alignment statistics. MACS 12 2.1.1 Run filterdup on SE data ( --keep-dup=\u201dauto\u201d ) to remove PCR duplicates Bedtools 13 2.27.1 Run intersect and bedtobam to convert .tag.Align.gz to .bam for use with Deeptools (specific to SE data) ppqt 14 2.0 Also known as phantompeakqualtools, used to calculate estimated fragment length (used for bigwig and peak calling for SE data). Also produces QC metrics: NSC and RSC. deepTools 15 3.0.1 Used for bigwig creation and multiple QC metrics. Use bamcoverage to create RPGC-normalized data: --binSize 25 --smoothLength 75 --normalizeUsing RPGC . For PE data, add --centerReads . For Control SE, add -e 200 . For ChIP SE, add -e [estimated fragment length] . For control subtraction (inputnorm), use bigwigCompare: --binSize 25 --operation \u2018subtract\u2019 . Run multiBigWigSummary, plotCorrelation, plotPCA, plotFingerprint, computeMatrix, plotHeatmap, and plotProfile for QC plots. Peak calling and differential binding pipeline \u00b6 Peak calling and differential peak calling tools \u00b6 Tool Version Notes MACS 16 2.1.1 Sicer 17 1.1 GEM 18 3.0 MANorm 19 1.1.4 DiffBind 20,21 2.10.0 Annotations, motifs, and QC assesment tools \u00b6 Tool Version Notes Uropa 22 4.0.2 Homer 23 4.10.1 IDR 24 2.0.3 Jaccard FRiP References \u00b6 1. FastQC: Andrews, S. (2010). FastQC: a quality control tool for high throughput sequence data. https://www.bioinformatics.babraham.ac.uk/projects/fastqc/ 2. Kraken: Wood, D. E. and S. L. Salzberg (2014). \"Kraken: ultrafast metagenomic sequence classification using exact alignments.\" Genome Biol 15(3): R46. http://ccb.jhu.edu/software/kraken/ 3. Krona: Ondov, B. D., et al. (2011). \"Interactive metagenomic visualization in a Web browser.\" BMC Bioinformatics 12(1): 385. https://github.com/marbl/Krona/wiki 4. FastQ Screen: Wingett, S. and S. Andrews (2018). \"FastQ Screen: A tool for multi-genome mapping and quality control.\" F1000Research 7(2): 1338. https://www.bioinformatics.babraham.ac.uk/projects/fastq_screen/ 5. Preseq: Daley, T. and A.D. Smith (2013). Predicting the molecular complexity of sequencing libraries. Nat Methods 10(4): 325-7. http://smithlabresearch.org/software/preseq/ 6. NGSQC: Mendoza-Parra M., et al. (2013). A quality control system for profiles obtained by ChIP sequencing. Nucleic Acids Research 41(21,): e196. 7. MultiQC: Ewels, P., et al. (2016). \"MultiQC: summarize analysis results for multiple tools and samples in a single report.\" Bioinformatics 32(19): 3047-3048. https://multiqc.info/docs/ 8. Cutadapt: Martin, M. (2011). \"Cutadapt removes adapter sequences from high-throughput sequencing reads.\" EMBnet 17(1): 10-12. https://cutadapt.readthedocs.io/en/stable/ 9. BWA: Li H. and Durbin R. (2009) Fast and accurate short read alignment with Burrows-Wheeler Transform. Bioinformatics 25: 1754-60. http://bio-bwa.sourceforge.net/bwa.shtml 10. Picard: The Picard toolkit. https://broadinstitute.github.io/picard/ 11. SAMtools: Li, H., et al. (2009). \"The Sequence Alignment/Map format and SAMtools.\" Bioinformatics 25(16): 2078-2079. http://www.htslib.org/doc/samtools.html 12. MACS: Zhang, Y., et al. (2008). Model-based Analysis of ChIP-Seq (MACS). Genome Biol 9: R137. https://github.com/macs3-project/MACS 13. Bedtools: Quinlan, A.R. (2014). BEDTools: The Swiss\u2010Army Tool for Genome Feature Analysis. Current Protocols in Bioinformatics, 47: 11.12.1-11.12.34. https://bedtools.readthedocs.io/en/latest/index.html 14. ppqt: Landt S.G., et al. (2012). ChIP-seq guidelines and practices of the ENCODE and modENCODE consortia. Genome Res 22(9): 1813-31. https://github.com/kundajelab/phantompeakqualtools 15. deepTools: Ram\u00edrez, F., et al. (2016). deepTools2: A next Generation Web Server for Deep-Sequencing Data Analysis , Nucleic Acids Research, 44(W1), W160-W165. 16. MACS: Zhang Y., et al. (2008). Model-based Analysis of ChIP-Seq (MACS). Genome Biol 9(9): R137 17. Sicer: Xu S., et al. (2014). Spatial Clustering for Identification of ChIP-Enriched Regions (SICER) to Map Regions of Histone Methylation Patterns in Embryonic Stem Cells. Methods Mol Biol 1150: 97\u2013111. 18. GEM: Guo Y., Mahony S., and D. K. Gifford. (2012). High Resolution Genome Wide Binding Event Finding and Motif Discovery Reveals Transcription Factor Spatial Binding Constraints. PLoS Comput Biol 8(8): e1002638. 19. MANorm: Shao, Z., et al. (2012). MAnorm: a robust model for quantitative comparison of ChIP-Seq data sets. Genome Biology 13: R16. https://manorm.readthedocs.io/en/latest/index.html 20. DiffBind: Ross-Innes C.S., et al. (2012). Differential oestrogen receptor binding is associated with clinical outcome in breast cancer. Nature 481: 389\u2013393. 21. DiffBind: Stark R. and G. Brown. (2011). DiffBind: differential binding analysis of ChIP-Seq peak data. http://bioconductor.org/packages/release/bioc/vignettes/DiffBind/inst/doc/DiffBind.pdf . 22. Uropa: Kondili M., et al. (2017). UROPA: a tool for Universal RObust Peak Annotation. Scientific Reports 7: 2593. 23. Homer: Heinz S., et al. (2010). Simple combinations of lineage-determining transcription factors prime cis-regulatory elements required for macrophage and B cell identities. Mol Cell 38(4): 576\u2013589. 24. IDR: Li Q., et al. (2011). Measuring reproducibility of high-throughput experiments. Ann Appl Stat 5(3): 1752-1779.","title":"Resources"},{"location":"ChIP-seq/ChIP-seq-tools/#quality-control-pipeline","text":"","title":"Quality-control pipeline"},{"location":"ChIP-seq/ChIP-seq-tools/#qc-assessment-tools","text":"Tool Version Notes FastQC 1 0.11.5 Assess sequencing quality, run before and after adapter trimming Kraken 2 1.1 Assess microbial taxonomic composition KronaTools 3 2.7 Visualize kraken output FastQ Screen 4 0.9.3 Assess contamination; additional dependencies: bowtie2/2.3.4, perl/5.24.3 Preseq 5 2.0.3 Estimate library complexity NGSQC 6 Infers a set of global QC indicators to asses data quality MultiQC 7 1.7 Aggregate sample statistics and quality-control information across all samples","title":"QC assessment tools"},{"location":"ChIP-seq/ChIP-seq-tools/#data-processing-tools","text":"Tool Version Notes Cutadapt 8 1.18 Remove adapter sequences and perform quality trimming BWA 9 mem 0.7.17 Read alignment, first to identify reads aligning to blacklisted regions and later for the remainder of the genome Picard 10 2.17.11 Run SamToFastq (for blacklist read removal) and MarkDuplicates (to remove PCR duplicates in PE data) SAMtools 11 1.6 Remove reads with mapQ less than 6. Also run flagstat and idxstats to calculate alignment statistics. MACS 12 2.1.1 Run filterdup on SE data ( --keep-dup=\u201dauto\u201d ) to remove PCR duplicates Bedtools 13 2.27.1 Run intersect and bedtobam to convert .tag.Align.gz to .bam for use with Deeptools (specific to SE data) ppqt 14 2.0 Also known as phantompeakqualtools, used to calculate estimated fragment length (used for bigwig and peak calling for SE data). Also produces QC metrics: NSC and RSC. deepTools 15 3.0.1 Used for bigwig creation and multiple QC metrics. Use bamcoverage to create RPGC-normalized data: --binSize 25 --smoothLength 75 --normalizeUsing RPGC . For PE data, add --centerReads . For Control SE, add -e 200 . For ChIP SE, add -e [estimated fragment length] . For control subtraction (inputnorm), use bigwigCompare: --binSize 25 --operation \u2018subtract\u2019 . Run multiBigWigSummary, plotCorrelation, plotPCA, plotFingerprint, computeMatrix, plotHeatmap, and plotProfile for QC plots.","title":"Data processing tools"},{"location":"ChIP-seq/ChIP-seq-tools/#peak-calling-and-differential-binding-pipeline","text":"","title":"Peak calling and differential binding pipeline"},{"location":"ChIP-seq/ChIP-seq-tools/#peak-calling-and-differential-peak-calling-tools","text":"Tool Version Notes MACS 16 2.1.1 Sicer 17 1.1 GEM 18 3.0 MANorm 19 1.1.4 DiffBind 20,21 2.10.0","title":"Peak calling and differential peak calling tools"},{"location":"ChIP-seq/ChIP-seq-tools/#annotations-motifs-and-qc-assesment-tools","text":"Tool Version Notes Uropa 22 4.0.2 Homer 23 4.10.1 IDR 24 2.0.3 Jaccard FRiP","title":"Annotations, motifs, and QC assesment tools"},{"location":"ChIP-seq/ChIP-seq-tools/#references","text":"1. FastQC: Andrews, S. (2010). FastQC: a quality control tool for high throughput sequence data. https://www.bioinformatics.babraham.ac.uk/projects/fastqc/ 2. Kraken: Wood, D. E. and S. L. Salzberg (2014). \"Kraken: ultrafast metagenomic sequence classification using exact alignments.\" Genome Biol 15(3): R46. http://ccb.jhu.edu/software/kraken/ 3. Krona: Ondov, B. D., et al. (2011). \"Interactive metagenomic visualization in a Web browser.\" BMC Bioinformatics 12(1): 385. https://github.com/marbl/Krona/wiki 4. FastQ Screen: Wingett, S. and S. Andrews (2018). \"FastQ Screen: A tool for multi-genome mapping and quality control.\" F1000Research 7(2): 1338. https://www.bioinformatics.babraham.ac.uk/projects/fastq_screen/ 5. Preseq: Daley, T. and A.D. Smith (2013). Predicting the molecular complexity of sequencing libraries. Nat Methods 10(4): 325-7. http://smithlabresearch.org/software/preseq/ 6. NGSQC: Mendoza-Parra M., et al. (2013). A quality control system for profiles obtained by ChIP sequencing. Nucleic Acids Research 41(21,): e196. 7. MultiQC: Ewels, P., et al. (2016). \"MultiQC: summarize analysis results for multiple tools and samples in a single report.\" Bioinformatics 32(19): 3047-3048. https://multiqc.info/docs/ 8. Cutadapt: Martin, M. (2011). \"Cutadapt removes adapter sequences from high-throughput sequencing reads.\" EMBnet 17(1): 10-12. https://cutadapt.readthedocs.io/en/stable/ 9. BWA: Li H. and Durbin R. (2009) Fast and accurate short read alignment with Burrows-Wheeler Transform. Bioinformatics 25: 1754-60. http://bio-bwa.sourceforge.net/bwa.shtml 10. Picard: The Picard toolkit. https://broadinstitute.github.io/picard/ 11. SAMtools: Li, H., et al. (2009). \"The Sequence Alignment/Map format and SAMtools.\" Bioinformatics 25(16): 2078-2079. http://www.htslib.org/doc/samtools.html 12. MACS: Zhang, Y., et al. (2008). Model-based Analysis of ChIP-Seq (MACS). Genome Biol 9: R137. https://github.com/macs3-project/MACS 13. Bedtools: Quinlan, A.R. (2014). BEDTools: The Swiss\u2010Army Tool for Genome Feature Analysis. Current Protocols in Bioinformatics, 47: 11.12.1-11.12.34. https://bedtools.readthedocs.io/en/latest/index.html 14. ppqt: Landt S.G., et al. (2012). ChIP-seq guidelines and practices of the ENCODE and modENCODE consortia. Genome Res 22(9): 1813-31. https://github.com/kundajelab/phantompeakqualtools 15. deepTools: Ram\u00edrez, F., et al. (2016). deepTools2: A next Generation Web Server for Deep-Sequencing Data Analysis , Nucleic Acids Research, 44(W1), W160-W165. 16. MACS: Zhang Y., et al. (2008). Model-based Analysis of ChIP-Seq (MACS). Genome Biol 9(9): R137 17. Sicer: Xu S., et al. (2014). Spatial Clustering for Identification of ChIP-Enriched Regions (SICER) to Map Regions of Histone Methylation Patterns in Embryonic Stem Cells. Methods Mol Biol 1150: 97\u2013111. 18. GEM: Guo Y., Mahony S., and D. K. Gifford. (2012). High Resolution Genome Wide Binding Event Finding and Motif Discovery Reveals Transcription Factor Spatial Binding Constraints. PLoS Comput Biol 8(8): e1002638. 19. MANorm: Shao, Z., et al. (2012). MAnorm: a robust model for quantitative comparison of ChIP-Seq data sets. Genome Biology 13: R16. https://manorm.readthedocs.io/en/latest/index.html 20. DiffBind: Ross-Innes C.S., et al. (2012). Differential oestrogen receptor binding is associated with clinical outcome in breast cancer. Nature 481: 389\u2013393. 21. DiffBind: Stark R. and G. Brown. (2011). DiffBind: differential binding analysis of ChIP-Seq peak data. http://bioconductor.org/packages/release/bioc/vignettes/DiffBind/inst/doc/DiffBind.pdf . 22. Uropa: Kondili M., et al. (2017). UROPA: a tool for Universal RObust Peak Annotation. Scientific Reports 7: 2593. 23. Homer: Heinz S., et al. (2010). Simple combinations of lineage-determining transcription factors prime cis-regulatory elements required for macrophage and B cell identities. Mol Cell 38(4): 576\u2013589. 24. IDR: Li Q., et al. (2011). Measuring reproducibility of high-throughput experiments. Ann Appl Stat 5(3): 1752-1779.","title":"References"},{"location":"ChIP-seq/ChIP-seq/","text":"This page is the main source of documentation for users that are getting started with the ChIP-seq pipeline. Please check out our pipeline resources page for a comprehensive listing of supported reference genomes and different tools the (with version information) pipeline employs. If you are a new user , we recommend following our Tutorial with the provided test data set on Biowulf. If you are a new user and you would like to skip our guided tutorial, please see our quick start section . Getting started with the Quality-control pipeline \u00b6 This section provides step-by-step instructions for setting up the first pipeline (Quality-control pipeline) and a brief description of the pipeline's output files and directories. We assume that you have already successfully launched the GUI. If not, please see Launch Pipeliner . Also, in order to use CCBR_Pipeliner on biowulf , you will need an active biowulf account which can be requested here . About the Demo Dataset \u00b6 For the purposes of this demo we have chosen a subset of a publicly available dataset from GEO ( GSE76478 ). The origin datasets contains CTCF and H3K27ac ChIP-seq experimental data at early and late stages in iPS cells. Here we will focus on the following samples: GSM number SRR number Sample Cell type GSM2026234 SRR3081748 CTCF_ChIP_macrophage_p20_1 macrophage derived induced pluripotent stem cells after 20 passages GSM2026235 SRR3081749 CTCF_ChIP_macrophage_p20_2 macrophage derived induced pluripotent stem cells after 20 passages GSM2026236 SRR3081750 CTCF_ChIP_macrophage_p3_1 macrophage derived induced pluripotent stem cells after 3 passages GSM2026237 SRR3081751 CTCF_ChIP_macrophage_p3_2 macrophage derived induced pluripotent stem cells after 3 passages GSM2026238 SRR3081752 CTCF_ChIP_MEF_p20_1 mouse embryonic fibroblasts derived induced pluripotent stem cells after 20 passages GSM2026239 SRR3081753 CTCF_ChIP_MEF_p20_2 mouse embryonic fibroblasts derived induced pluripotent stem cells after 20 passages GSM2026258 SRR3081772 WCE_p3 whole cell extract after 3 passages GSM2026259 SRR3081773 WCE_p20 whole cell extract after 20 passages The raw fastq files were downloaded from SRA using the sra toolkit > ls /data/CCBR_Pipeliner/testdata/chipseq/*fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081749_1.fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081750_1.fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081751_1.fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081752_1.fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081753_1.fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081772_1.fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081773_1.fastq.gz This is single-ended sequencing dataset, hence we have one fastq file per sample. Single-ended (SE) sequencing is the preferred sequencing choice for ChIP-seq data, but CCBR_Pipeliner does accept paired-end (PE) data. In case of PE data, each sample will have two fastq files of raw data, namely, a Read1 and a Read2 , generally denoted by R1 and R2 . Please note that, R1 and R2 in the context of PE data, do not represent two different replicates as this is the most common source of confusion for most novice NGS data analysts. The SRA filenames do not comply with our file naming convention . There are three possible ways to fix this: Rename the files with CCBR_Pipeliner compliant names Create symbolic links at a different location and rename the symbolic links with CCBR_Pipeliner compliant filenames Add a tab-delimited file called labels.txt in the same folder as the raw data. This file has 2 columns: First column denotes the current name of the file, and Second column is the what the corresponding CCBR_Pipeliner compliant name should be. Here, we are going to use option 3. The labels.txt file looks something like this: SRR3081748_1.fastq.gz CTCF_ChIP_macrophage_p20_1.R1.fastq.gz SRR3081749_1.fastq.gz CTCF_ChIP_macrophage_p20_2.R1.fastq.gz SRR3081750_1.fastq.gz CTCF_ChIP_macrophage_p3_1.R1.fastq.gz SRR3081751_1.fastq.gz CTCF_ChIP_macrophage_p3_2.R1.fastq.gz SRR3081752_1.fastq.gz CTCF_ChIP_MEF_p20_1.R1.fastq.gz SRR3081753_1.fastq.gz CTCF_ChIP_MEF_p20_2.R1.fastq.gz SRR3081772_1.fastq.gz WCE_p3_input.R1.fastq.gz SRR3081773_1.fastq.gz WCE_p20_input.R1.fastq.gz Phase 1: Initial QC \u00b6 Before you can run the QC portion of the ChIP-seq pipeline, there are a few key pieces of information that must be provided. Step 0. Fill out the Project Information section \u00b6 This section contains three fields: Project Id , Email address , Flow Cell ID . For this demo, you can set Project Id to project . This will be the name of the pipeline's master job. Please enter your email address in the Email address field. You may leave Flow cell ID blank for now. Step 1. Setting Pipeline \u00b6 Under the Pipeline Family select ChIPSeq . Once ChIPSeq pipeline is selected a new tab should appear next to Project Description . Step 2. Select Genome \u00b6 Next select the genome to choose mm10 as this is Mus musculus data. Although many genome options show up in the Genome drop down only the following four are supported by the ChIP-seq pipeline. Genome Organism (assembly) hg19 Human (GRCh37) hg38 Human (GRCh38) mm9 Mouse (GRCm37) mm10 Mouse (GRCm38) If any other genome is selected from the drop-down, then a pop-up will give a warning and will prevent you from proceeding with your analysis. Please Note: If you select a reference genome that is not supported by the pipeline, a pop-up box will notify you. Step 3. Select your Data Directory \u00b6 If you are following along with this tutorial, you can use the included demo dataset. Please select the Open Directory button and navigate to the following path on biowulf's filesystem in the pop-up box: /data/CCBR_Pipeliner/testdata/chipseq/ Please Note: Input files will be read from and output files will be written to the biowulf filesystem. If your rawdata does not exist on biowulf, then you may need to upload it there first. Output files can be downloaded from biowulf to your local computer for downstream analysis. Once you have pointed to or navigated to the directory above, select OK . You should receive a message that 8 single end files were found: Click OK. Step 4. Select your Working Directory \u00b6 You are now ready to select your working directory on biowulf's filesystem. This is where all of the pipeline's output files will be created. In this tutorial, I set the working directory to /scratch/demo/chipseq by clicking the Open Directory button in front of Working Directory and then navigating the my directory of choice. But, you could set it to another location like /scratch/<yourUserName>/chipseq_demo . The only pre-requisites are that this directory should not exist. this directory should not be a sub-directory of CCBR pipeliner working dir from a previous run. The process very similar to the previous step except, you will point to a directory that does not exist on the biowulf filesystem by typing in the directory name, as it will be created in the next step. Please Note: Input files will be read from and output files will be written to the biowulf filesystem. If you rawdata does not exist on biowulf, then you may need to upload it there first. Output files can be downloaded from biowulf to your local computer for downstream analysis. Step 5. Initialize your Working Directory \u00b6 In this step, we will initialize or create the Working Directory defined in the step above. Please select the Initialize Directory button. During this step, the required resources to run the pipeline are copied into the working directory. After a few moments, you should receive a notification stating the directory was successfully initialized: Click Ok. If the directory already exists or you do not have write permissions, then you will get a warning like this: Step 6. Set Peak information \u00b6 Under Options , InitialChIPseqQC is selected by default. Click the Set Peak Information button, to pop-up another window, where you can specify which samples are ChIP samples and which samples should be used as their corresponding Input samples: Select all the ChIP samples in the ChIP Names column. For each ChIP sample, select the matching control sample (Input, IgG control, mock, no tag control, or WCE) in the Input Names column. Inputs can be paired to more than one ChIP sample. Leave as N/A if there is no control match for a ChIP sample. Type a Group Name for each ChIP sample or select from the pull-down list in the rightmost column. Each ChIP sample must have a Group Name. Replicates should be given the same Group Name. Group names should only contain alphanumeric characters (No spaces, hyphens, dashes, etc.), but underscores are okay. Click Save button once done and close the popup. This will save this information as peakcall.tab file in the work directory . Here we created three groups, namely mac_p20 , map_p3 and mef_p20 . Each of these groups have 2 replicates each denoted by the _1 and _2 in the file basenames. You can also save the three columns, ie, ChIP Names , Input Names and Group Names as a tab-delimited file in the work directory , name it peakcall.tab and load the predefined file using the Load button. Step 7. Perform Dry Run \u00b6 Click on the Dry Run button to check if the initial QC phase tasks and the pipeline is configured properly. A successful dry run will display all tasks to be run and will have a job counts table at the top and bottom of the popup. This step take about 10-20 seconds to run, so please be patient until another window pops up with DAG information: If there is no error in the Dry Run , then you are ready to proceed. Step 8. Run \u00b6 Close the Dry Run popup and click the Run button. In a few seconds, you will see another popup: Once you click OK button on the popup, the job is submitted to the slurm queue on biowulf. Check progress \u00b6 You can check status of the jobs submitted using the HPC dashboard . If you are comfortable using the command line, you can use squeue or sjobs command to monitor jobs submitted to slurm . Please refer slurm documentation for details. Confirm successful completion of Phase 1. \u00b6 In the work directory , look for a file name HPC_usage_table.txt , which lists details about all submitted jobs. This file doesn't appear until the job is finished. Here are columns in this tab-delimited file: 1 JobName 2 Jobid 3 Partition 4 State 5 Nodes 6 CPUs 7 Walltime 8 Runtime 9 MemReq 10 MemUsed 11 Nodelist 12 MaxCPUUsed 13 Queuetime 14 CPUHours 15 Account 16 Username This file can be open in Microsoft Excel for easy viewing. Examine the values under the column Status . The values can be COMPLETED . or FAILED . If no FAILED values are found and all values are COMPLETED , then Phase 1 has finished running successfully and you are ready to move to phase 2. Phase 2: Peak calling, differential peak calling, annotations, and motif searches \u00b6 Phase 1 will take a few hours to run. It is important to know that the second phase of the ChIP-seq Pipeliner can only be run after successful completion of initialQC phase. This workflow is to be executed in the same working directory (e.g. /scratch/<yourUserName>/chipseq_demo ) as that specified in the InitialQC phase, so that the pipeline can identify the output files from the InitialQC run, that are being used as input files to the differential expression workflow. Step 1. Initial Setup \u00b6 Repeat steps 0 through 3 from Phase 1. Also enter the work directory to the same folder selected in Step 4 of Phase 1, the only difference is that the work directory should already exist with Phase 1 results in it. Step 2. Select Pipeline Options \u00b6 From Options select ChIPseq Pipeline from the dropdown. Step 3. Set contrasts (Optional) \u00b6 If you wish to compare peaks between groups after peakcalling, then you can specify the contrasts that need to be performed here. Click Set Groups to compare peaks This will popup another window where you can select the groups to compare. Here, each row denoted a different comparison, ie, an independent instance of differential peak analysis using DiffBind . Clicking Save button creates a contrast.tab file in the work directory . If you are familiar with creating and editing file at the command line, then you can also create a tab-delimited file with the name contrast.tab in the work directory in order to set the contrasts without using the GUI interface. The contrast.tab looks like this: Macrophage_p3 Macrophage_p20 MEF_p20 Macrophage_p20 Here, we have specified two contrasts trying to compare the peaks in the groups Macrophage_p3 and MEF_p20 with respect to the peaks in group Macrophage_p20 . Step 4. Perform Dry Run \u00b6 Close the previous popup and then, click on the Dry Run button to check if the phase2 tasks and the pipeline is configured properly. A successful dry run will display all tasks to be run and will have a job counts table at the top and bottom of the popup. This step take about 10-20 seconds to run, so please be patient until another window pops up with DAG information: If there is no error in the Dry Run , as seen in the truncated snapshot above, then you are ready to proceed. Step 5. Run \u00b6 Close the Dry Run popup and click the Run button on the main GUI. In a few seconds, you will see another popup: Once you click OK button on the popup, the job is submitted to the slurm queue on biowulf. Check progress \u00b6 You can check status of the jobs submitted using the HPC dashboard . If you are comfortable using the command line, you can use squeue or sjobs command to monitor jobs submitted to slurm . Please refer slurm documentation for details. You can also use the HPC_usage_table.txt as we did in Phase 1.","title":"User Tutorial"},{"location":"ChIP-seq/ChIP-seq/#getting-started-with-the-quality-control-pipeline","text":"This section provides step-by-step instructions for setting up the first pipeline (Quality-control pipeline) and a brief description of the pipeline's output files and directories. We assume that you have already successfully launched the GUI. If not, please see Launch Pipeliner . Also, in order to use CCBR_Pipeliner on biowulf , you will need an active biowulf account which can be requested here .","title":"Getting started with the Quality-control pipeline"},{"location":"ChIP-seq/ChIP-seq/#about-the-demo-dataset","text":"For the purposes of this demo we have chosen a subset of a publicly available dataset from GEO ( GSE76478 ). The origin datasets contains CTCF and H3K27ac ChIP-seq experimental data at early and late stages in iPS cells. Here we will focus on the following samples: GSM number SRR number Sample Cell type GSM2026234 SRR3081748 CTCF_ChIP_macrophage_p20_1 macrophage derived induced pluripotent stem cells after 20 passages GSM2026235 SRR3081749 CTCF_ChIP_macrophage_p20_2 macrophage derived induced pluripotent stem cells after 20 passages GSM2026236 SRR3081750 CTCF_ChIP_macrophage_p3_1 macrophage derived induced pluripotent stem cells after 3 passages GSM2026237 SRR3081751 CTCF_ChIP_macrophage_p3_2 macrophage derived induced pluripotent stem cells after 3 passages GSM2026238 SRR3081752 CTCF_ChIP_MEF_p20_1 mouse embryonic fibroblasts derived induced pluripotent stem cells after 20 passages GSM2026239 SRR3081753 CTCF_ChIP_MEF_p20_2 mouse embryonic fibroblasts derived induced pluripotent stem cells after 20 passages GSM2026258 SRR3081772 WCE_p3 whole cell extract after 3 passages GSM2026259 SRR3081773 WCE_p20 whole cell extract after 20 passages The raw fastq files were downloaded from SRA using the sra toolkit > ls /data/CCBR_Pipeliner/testdata/chipseq/*fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081749_1.fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081750_1.fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081751_1.fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081752_1.fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081753_1.fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081772_1.fastq.gz /data/CCBR_Pipeliner/testdata/chipseq/SRR3081773_1.fastq.gz This is single-ended sequencing dataset, hence we have one fastq file per sample. Single-ended (SE) sequencing is the preferred sequencing choice for ChIP-seq data, but CCBR_Pipeliner does accept paired-end (PE) data. In case of PE data, each sample will have two fastq files of raw data, namely, a Read1 and a Read2 , generally denoted by R1 and R2 . Please note that, R1 and R2 in the context of PE data, do not represent two different replicates as this is the most common source of confusion for most novice NGS data analysts. The SRA filenames do not comply with our file naming convention . There are three possible ways to fix this: Rename the files with CCBR_Pipeliner compliant names Create symbolic links at a different location and rename the symbolic links with CCBR_Pipeliner compliant filenames Add a tab-delimited file called labels.txt in the same folder as the raw data. This file has 2 columns: First column denotes the current name of the file, and Second column is the what the corresponding CCBR_Pipeliner compliant name should be. Here, we are going to use option 3. The labels.txt file looks something like this: SRR3081748_1.fastq.gz CTCF_ChIP_macrophage_p20_1.R1.fastq.gz SRR3081749_1.fastq.gz CTCF_ChIP_macrophage_p20_2.R1.fastq.gz SRR3081750_1.fastq.gz CTCF_ChIP_macrophage_p3_1.R1.fastq.gz SRR3081751_1.fastq.gz CTCF_ChIP_macrophage_p3_2.R1.fastq.gz SRR3081752_1.fastq.gz CTCF_ChIP_MEF_p20_1.R1.fastq.gz SRR3081753_1.fastq.gz CTCF_ChIP_MEF_p20_2.R1.fastq.gz SRR3081772_1.fastq.gz WCE_p3_input.R1.fastq.gz SRR3081773_1.fastq.gz WCE_p20_input.R1.fastq.gz","title":"About the Demo Dataset"},{"location":"ChIP-seq/ChIP-seq/#phase-1-initial-qc","text":"Before you can run the QC portion of the ChIP-seq pipeline, there are a few key pieces of information that must be provided.","title":"Phase 1: Initial QC"},{"location":"ChIP-seq/ChIP-seq/#step-0-fill-out-the-project-information-section","text":"This section contains three fields: Project Id , Email address , Flow Cell ID . For this demo, you can set Project Id to project . This will be the name of the pipeline's master job. Please enter your email address in the Email address field. You may leave Flow cell ID blank for now.","title":"Step 0. Fill out the Project Information section"},{"location":"ChIP-seq/ChIP-seq/#step-1-setting-pipeline","text":"Under the Pipeline Family select ChIPSeq . Once ChIPSeq pipeline is selected a new tab should appear next to Project Description .","title":"Step 1. Setting Pipeline"},{"location":"ChIP-seq/ChIP-seq/#step-2-select-genome","text":"Next select the genome to choose mm10 as this is Mus musculus data. Although many genome options show up in the Genome drop down only the following four are supported by the ChIP-seq pipeline. Genome Organism (assembly) hg19 Human (GRCh37) hg38 Human (GRCh38) mm9 Mouse (GRCm37) mm10 Mouse (GRCm38) If any other genome is selected from the drop-down, then a pop-up will give a warning and will prevent you from proceeding with your analysis. Please Note: If you select a reference genome that is not supported by the pipeline, a pop-up box will notify you.","title":"Step 2. Select Genome"},{"location":"ChIP-seq/ChIP-seq/#step-3-select-your-data-directory","text":"If you are following along with this tutorial, you can use the included demo dataset. Please select the Open Directory button and navigate to the following path on biowulf's filesystem in the pop-up box: /data/CCBR_Pipeliner/testdata/chipseq/ Please Note: Input files will be read from and output files will be written to the biowulf filesystem. If your rawdata does not exist on biowulf, then you may need to upload it there first. Output files can be downloaded from biowulf to your local computer for downstream analysis. Once you have pointed to or navigated to the directory above, select OK . You should receive a message that 8 single end files were found: Click OK.","title":"Step 3. Select your Data Directory"},{"location":"ChIP-seq/ChIP-seq/#step-4-select-your-working-directory","text":"You are now ready to select your working directory on biowulf's filesystem. This is where all of the pipeline's output files will be created. In this tutorial, I set the working directory to /scratch/demo/chipseq by clicking the Open Directory button in front of Working Directory and then navigating the my directory of choice. But, you could set it to another location like /scratch/<yourUserName>/chipseq_demo . The only pre-requisites are that this directory should not exist. this directory should not be a sub-directory of CCBR pipeliner working dir from a previous run. The process very similar to the previous step except, you will point to a directory that does not exist on the biowulf filesystem by typing in the directory name, as it will be created in the next step. Please Note: Input files will be read from and output files will be written to the biowulf filesystem. If you rawdata does not exist on biowulf, then you may need to upload it there first. Output files can be downloaded from biowulf to your local computer for downstream analysis.","title":"Step 4. Select your Working Directory"},{"location":"ChIP-seq/ChIP-seq/#step-5-initialize-your-working-directory","text":"In this step, we will initialize or create the Working Directory defined in the step above. Please select the Initialize Directory button. During this step, the required resources to run the pipeline are copied into the working directory. After a few moments, you should receive a notification stating the directory was successfully initialized: Click Ok. If the directory already exists or you do not have write permissions, then you will get a warning like this:","title":"Step 5. Initialize your Working Directory"},{"location":"ChIP-seq/ChIP-seq/#step-6-set-peak-information","text":"Under Options , InitialChIPseqQC is selected by default. Click the Set Peak Information button, to pop-up another window, where you can specify which samples are ChIP samples and which samples should be used as their corresponding Input samples: Select all the ChIP samples in the ChIP Names column. For each ChIP sample, select the matching control sample (Input, IgG control, mock, no tag control, or WCE) in the Input Names column. Inputs can be paired to more than one ChIP sample. Leave as N/A if there is no control match for a ChIP sample. Type a Group Name for each ChIP sample or select from the pull-down list in the rightmost column. Each ChIP sample must have a Group Name. Replicates should be given the same Group Name. Group names should only contain alphanumeric characters (No spaces, hyphens, dashes, etc.), but underscores are okay. Click Save button once done and close the popup. This will save this information as peakcall.tab file in the work directory . Here we created three groups, namely mac_p20 , map_p3 and mef_p20 . Each of these groups have 2 replicates each denoted by the _1 and _2 in the file basenames. You can also save the three columns, ie, ChIP Names , Input Names and Group Names as a tab-delimited file in the work directory , name it peakcall.tab and load the predefined file using the Load button.","title":"Step 6. Set Peak information"},{"location":"ChIP-seq/ChIP-seq/#step-7-perform-dry-run","text":"Click on the Dry Run button to check if the initial QC phase tasks and the pipeline is configured properly. A successful dry run will display all tasks to be run and will have a job counts table at the top and bottom of the popup. This step take about 10-20 seconds to run, so please be patient until another window pops up with DAG information: If there is no error in the Dry Run , then you are ready to proceed.","title":"Step 7. Perform Dry Run"},{"location":"ChIP-seq/ChIP-seq/#step-8-run","text":"Close the Dry Run popup and click the Run button. In a few seconds, you will see another popup: Once you click OK button on the popup, the job is submitted to the slurm queue on biowulf.","title":"Step 8. Run"},{"location":"ChIP-seq/ChIP-seq/#check-progress","text":"You can check status of the jobs submitted using the HPC dashboard . If you are comfortable using the command line, you can use squeue or sjobs command to monitor jobs submitted to slurm . Please refer slurm documentation for details.","title":"Check progress"},{"location":"ChIP-seq/ChIP-seq/#confirm-successful-completion-of-phase-1","text":"In the work directory , look for a file name HPC_usage_table.txt , which lists details about all submitted jobs. This file doesn't appear until the job is finished. Here are columns in this tab-delimited file: 1 JobName 2 Jobid 3 Partition 4 State 5 Nodes 6 CPUs 7 Walltime 8 Runtime 9 MemReq 10 MemUsed 11 Nodelist 12 MaxCPUUsed 13 Queuetime 14 CPUHours 15 Account 16 Username This file can be open in Microsoft Excel for easy viewing. Examine the values under the column Status . The values can be COMPLETED . or FAILED . If no FAILED values are found and all values are COMPLETED , then Phase 1 has finished running successfully and you are ready to move to phase 2.","title":"Confirm successful completion of Phase 1."},{"location":"ChIP-seq/ChIP-seq/#phase-2-peak-calling-differential-peak-calling-annotations-and-motif-searches","text":"Phase 1 will take a few hours to run. It is important to know that the second phase of the ChIP-seq Pipeliner can only be run after successful completion of initialQC phase. This workflow is to be executed in the same working directory (e.g. /scratch/<yourUserName>/chipseq_demo ) as that specified in the InitialQC phase, so that the pipeline can identify the output files from the InitialQC run, that are being used as input files to the differential expression workflow.","title":"Phase 2: Peak calling, differential peak calling, annotations, and motif searches"},{"location":"ChIP-seq/ChIP-seq/#step-1-initial-setup","text":"Repeat steps 0 through 3 from Phase 1. Also enter the work directory to the same folder selected in Step 4 of Phase 1, the only difference is that the work directory should already exist with Phase 1 results in it.","title":"Step 1. Initial Setup"},{"location":"ChIP-seq/ChIP-seq/#step-2-select-pipeline-options","text":"From Options select ChIPseq Pipeline from the dropdown.","title":"Step 2. Select Pipeline Options"},{"location":"ChIP-seq/ChIP-seq/#step-3-set-contrasts-optional","text":"If you wish to compare peaks between groups after peakcalling, then you can specify the contrasts that need to be performed here. Click Set Groups to compare peaks This will popup another window where you can select the groups to compare. Here, each row denoted a different comparison, ie, an independent instance of differential peak analysis using DiffBind . Clicking Save button creates a contrast.tab file in the work directory . If you are familiar with creating and editing file at the command line, then you can also create a tab-delimited file with the name contrast.tab in the work directory in order to set the contrasts without using the GUI interface. The contrast.tab looks like this: Macrophage_p3 Macrophage_p20 MEF_p20 Macrophage_p20 Here, we have specified two contrasts trying to compare the peaks in the groups Macrophage_p3 and MEF_p20 with respect to the peaks in group Macrophage_p20 .","title":"Step 3. Set contrasts (Optional)"},{"location":"ChIP-seq/ChIP-seq/#step-4-perform-dry-run","text":"Close the previous popup and then, click on the Dry Run button to check if the phase2 tasks and the pipeline is configured properly. A successful dry run will display all tasks to be run and will have a job counts table at the top and bottom of the popup. This step take about 10-20 seconds to run, so please be patient until another window pops up with DAG information: If there is no error in the Dry Run , as seen in the truncated snapshot above, then you are ready to proceed.","title":"Step 4. Perform Dry Run"},{"location":"ChIP-seq/ChIP-seq/#step-5-run","text":"Close the Dry Run popup and click the Run button on the main GUI. In a few seconds, you will see another popup: Once you click OK button on the popup, the job is submitted to the slurm queue on biowulf.","title":"Step 5. Run"},{"location":"ChIP-seq/ChIP-seq/#check-progress_1","text":"You can check status of the jobs submitted using the HPC dashboard . If you are comfortable using the command line, you can use squeue or sjobs command to monitor jobs submitted to slurm . Please refer slurm documentation for details. You can also use the HPC_usage_table.txt as we did in Phase 1.","title":"Check progress"},{"location":"RNA-seq/Differential-expression-pipeline-tools-and-versions/","text":"Reference genomes \u00b6 Warning: This section contains FTP links for downloading each reference file. The quality-control and differential expression pipeline support the following genomes: GenomeName Species Annotation Version Comments hg19 Homo sapiens (human) Gencode Release 19 GRCh37 , Release date: 07/2013 hg38 Homo sapiens (human) Gencode Release 28 GRCh38 , Annotation Release date: 11/2017 hg38_30 Homo sapiens (human) Gencode Release 30 GRCh38 , Annotation Release date: 11/2018 hs37d5 Homo sapiens (human) Gencode Release 19 hg19 + decoy sequences hs38d1 Homo sapiens (human) Gencode Release 28 hg38 + decoy sequences hg38_30_KSHV Homo sapiens + KSHV Gencode Release 30 (hg38) + 06/2019 (KSHV) hg38 + NC_009333.1 . Annotation Release dates: 11/2018(human) + 06/2019(KSHV) hg38_HPV16 Homo sapiens + HPV16 Gencode Release 28 (hg38) + 03/2019 (HPV16 custom annotation from Zheng lab) hg38 + HPV16 custom sequence based off of KU298885.1 with custom annotation mm9 Mus musculus (house mouse) M1 NCBIM37 , Annotation Release date: 12/2011 mm10 Mus musculus (house mouse) M18 GRCm38 , Annotation Release date: 07/2018 mm10_M21 Mus musculus (house mouse) M21 GRCm38 , Annotation Release date: 04/2019 canFam3 Canis lupus familiaris (dog) Ensembl Release 94 CanFam3.1 Mmul_8.0.1 Macaca mulatta (Rhesus monkey or macaque) Ensembl Release 97 Mmul_8.0.1 (rheMac8) Please note : If you are looking for a reference genome and/or annotation that is currently not available , it can be generated using Pipeliner Index Maker (PIM) . Given the reference's FASTA file ref.fa and a GTF file genes.gtf , PIM will create all of the required reference files to run RNA-seq pipeline on Biowulf. Tools and versions \u00b6 Quality-control pipeline \u00b6 Raw data > Adapter Trimming > Alignment > Quantification (genes and isoforms) Tool Version Notes FastQC 2 0.11.5 Quality-control step to assess sequencing quality, run before and after adapter trimming Cutadapt 3 1.18 Data processing step to remove adapter sequences and perform quality trimming Kraken 18 1.1 Quality-control step to assess microbial taxonomic composition KronaTools 19 2.7 Quality-control step to visualize kraken output FastQ Screen 21 0.9.3 Quality-control step to assess contamination; additional dependencies: bowtie2/2.3.4 , perl/5.24.3 STAR 4 2.7.0f Data processing step to align reads against reference genome (using its two-pass mode) QualiMap 20 2.2.1 Quality-control step to assess various alignment metrics, also calculates insert_size Picard 12 2.17.11 Quality-control step to run MarkDuplicates , CollectRnaSeqMetrics and AddOrReplaceReadGroups Preseq 1 2.0.3 Quality-control step to estimate library complexity SAMtools 17 1.6 Quality-control step to run flagstat to calculate alignment statistics bam2strandedbw custom Summarization step to convert STAR aligned PE bam file into forward and reverse strand bigwigs suitable for a genomic track viewer like IGV RSeQC 11 2.6.4 Quality-control step to infer stranded-ness and read distributions over specific genomic features RSEM 5 1.3.0 Data processing step to quantify gene and isoform counts Subread 14 1.5.2 Data processing step to run featureCounts , an alternative quantification method to RSEM PCA Report 16 custom Summarization step to identify outliers prior to DE, contains pre- and post- normalization plots MultiQC 15 1.4 Reporting step to aggregate sample statistics and quality-control information across all sample Differential expression pipeline \u00b6 Raw counts matrix > Normalization > Differential Expression Analysis > Fuctional Impact Tool Version Notes filtersamples 16 custom Data processing step to remove low CPM genes prior to differential expression analysis PCAReport 16 custom Summarization step to identify outliers prior to DE, contains pre- and post- normalization plots EBSeq 22 1.2.0 Data processing step to find differentially expressed isoforms, additional dependencies: rsem/1.3.0 edgeR 23 3.24.3 Data processing step to find differentially expressed genes. Counts are modeled using a negative binomial distribution with mean equal to the multiplication of library size and relative abundance while a quasi-likelihood F-test is used for testing gene differential expression DESeq2 13 1.22.2 Data processing step to find differentially expressed genes. Counts are modeled using a negative binomial distribution similar to edgeR while a wald-test is implemented to test for differential expression limma 7,8 3.38.3 Data processing step to find differentially expressed genes. Log-transformed counts are modeled using a method analogous to a t-distribution while a moderated t-statistics is used to test for differential expression l2p 16 custom Summarization step for gene set enrichment analysis References \u00b6 1. Daley, T. and A.D. Smith, Predicting the molecular complexity of sequencing libraries. Nat Methods, 2013. 10(4): p. 325-7. 2. Andrews, S. (2010). FastQC: a quality control tool for high throughput sequence data. 3. Martin, M. (2011). \"Cutadapt removes adapter sequences from high-throughput sequencing reads.\" EMBnet 17(1): 10-12. 4. Dobin, A., et al., STAR: ultrafast universal RNA-seq aligner. Bioinformatics, 2013. 29(1): p. 15-21. 5. Li, B. and C.N. Dewey, RSEM: accurate transcript quantification from RNA-Seq data with or without a reference genome. BMC Bioinformatics, 2011. 12: p. 323. 6. Harrow, J., et al., GENCODE: the reference human genome annotation for The ENCODE Project. Genome Res, 2012. 22(9): p. 1760-74. 7. Law, C.W., et al., voom: Precision weights unlock linear model analysis tools for RNA-seq read counts. Genome Biol, 2014. 15(2): p. R29. 8. Smyth, G.K., Linear models and empirical bayes methods for assessing differential expression in microarray experiments. Stat Appl Genet Mol Biol, 2004. 3: p. Article3. 9. Fabregat, A., et al., The Reactome Pathway Knowledgebase. Nucleic Acids Res, 2018. 46(D1): p. D649-D655. 10. Liberzon, A., et al., Molecular signatures database (MSigDB) 3.0. Bioinformatics, 2011. 27(12): p. 1739-40. 11. Wang, L., et al. (2012). \"RSeQC: quality control of RNA-seq experiments.\" Bioinformatics 28(16): 2184-2185. 12. The Picard toolkit. https://broadinstitute.github.io/picard/ . 13. Love, M. I., et al. (2014). \"Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2.\" Genome Biol 15(12): 550. 14. Liao, Y., et al. (2013). \"The Subread aligner: fast, accurate and scalable read mapping by seed-and-vote.\" Nucleic Acids Research 41(10): e108-e108. 15. Ewels, P., et al. (2016). \"MultiQC: summarize analysis results for multiple tools and samples in a single report.\" Bioinformatics 32(19): 3047-3048. 16. R Core Team (2018). R: A Language and Environment for Statistical Computing. Vienna, Austria, R Foundation for Statistical Computing. 17. Li, H., et al. (2009). \"The Sequence Alignment/Map format and SAMtools.\" Bioinformatics 25(16): 2078-2079. 18. Wood, D. E. and S. L. Salzberg (2014). \"Kraken: ultrafast metagenomic sequence classification using exact alignments.\" Genome Biol 15(3): R46. 19. Ondov, B. D., et al. (2011). \"Interactive metagenomic visualization in a Web browser.\" BMC Bioinformatics 12(1): 385. 20. Okonechnikov, K., et al. (2015). \"Qualimap 2: advanced multi-sample quality control for high-throughput sequencing data.\" Bioinformatics 32(2): 292-294. 21. Wingett, S. and S. Andrews (2018). \"FastQ Screen: A tool for multi-genome mapping and quality control.\" F1000Research 7(2): 1338. 22. Leng, N., et al. (2013). \"EBSeq: an empirical Bayes hierarchical model for inference in RNA-seq experiments.\" Bioinformatics 29(8): 1035-1043. 23. Robinson, M. D., et al. (2009). \"edgeR: a Bioconductor package for differential expression analysis of digital gene expression data.\" Bioinformatics 26(1): 139-140.","title":"Resources"},{"location":"RNA-seq/Differential-expression-pipeline-tools-and-versions/#reference-genomes","text":"Warning: This section contains FTP links for downloading each reference file. The quality-control and differential expression pipeline support the following genomes: GenomeName Species Annotation Version Comments hg19 Homo sapiens (human) Gencode Release 19 GRCh37 , Release date: 07/2013 hg38 Homo sapiens (human) Gencode Release 28 GRCh38 , Annotation Release date: 11/2017 hg38_30 Homo sapiens (human) Gencode Release 30 GRCh38 , Annotation Release date: 11/2018 hs37d5 Homo sapiens (human) Gencode Release 19 hg19 + decoy sequences hs38d1 Homo sapiens (human) Gencode Release 28 hg38 + decoy sequences hg38_30_KSHV Homo sapiens + KSHV Gencode Release 30 (hg38) + 06/2019 (KSHV) hg38 + NC_009333.1 . Annotation Release dates: 11/2018(human) + 06/2019(KSHV) hg38_HPV16 Homo sapiens + HPV16 Gencode Release 28 (hg38) + 03/2019 (HPV16 custom annotation from Zheng lab) hg38 + HPV16 custom sequence based off of KU298885.1 with custom annotation mm9 Mus musculus (house mouse) M1 NCBIM37 , Annotation Release date: 12/2011 mm10 Mus musculus (house mouse) M18 GRCm38 , Annotation Release date: 07/2018 mm10_M21 Mus musculus (house mouse) M21 GRCm38 , Annotation Release date: 04/2019 canFam3 Canis lupus familiaris (dog) Ensembl Release 94 CanFam3.1 Mmul_8.0.1 Macaca mulatta (Rhesus monkey or macaque) Ensembl Release 97 Mmul_8.0.1 (rheMac8) Please note : If you are looking for a reference genome and/or annotation that is currently not available , it can be generated using Pipeliner Index Maker (PIM) . Given the reference's FASTA file ref.fa and a GTF file genes.gtf , PIM will create all of the required reference files to run RNA-seq pipeline on Biowulf.","title":"Reference genomes"},{"location":"RNA-seq/Differential-expression-pipeline-tools-and-versions/#tools-and-versions","text":"","title":"Tools and versions"},{"location":"RNA-seq/Differential-expression-pipeline-tools-and-versions/#quality-control-pipeline","text":"Raw data > Adapter Trimming > Alignment > Quantification (genes and isoforms) Tool Version Notes FastQC 2 0.11.5 Quality-control step to assess sequencing quality, run before and after adapter trimming Cutadapt 3 1.18 Data processing step to remove adapter sequences and perform quality trimming Kraken 18 1.1 Quality-control step to assess microbial taxonomic composition KronaTools 19 2.7 Quality-control step to visualize kraken output FastQ Screen 21 0.9.3 Quality-control step to assess contamination; additional dependencies: bowtie2/2.3.4 , perl/5.24.3 STAR 4 2.7.0f Data processing step to align reads against reference genome (using its two-pass mode) QualiMap 20 2.2.1 Quality-control step to assess various alignment metrics, also calculates insert_size Picard 12 2.17.11 Quality-control step to run MarkDuplicates , CollectRnaSeqMetrics and AddOrReplaceReadGroups Preseq 1 2.0.3 Quality-control step to estimate library complexity SAMtools 17 1.6 Quality-control step to run flagstat to calculate alignment statistics bam2strandedbw custom Summarization step to convert STAR aligned PE bam file into forward and reverse strand bigwigs suitable for a genomic track viewer like IGV RSeQC 11 2.6.4 Quality-control step to infer stranded-ness and read distributions over specific genomic features RSEM 5 1.3.0 Data processing step to quantify gene and isoform counts Subread 14 1.5.2 Data processing step to run featureCounts , an alternative quantification method to RSEM PCA Report 16 custom Summarization step to identify outliers prior to DE, contains pre- and post- normalization plots MultiQC 15 1.4 Reporting step to aggregate sample statistics and quality-control information across all sample","title":"Quality-control pipeline"},{"location":"RNA-seq/Differential-expression-pipeline-tools-and-versions/#differential-expression-pipeline","text":"Raw counts matrix > Normalization > Differential Expression Analysis > Fuctional Impact Tool Version Notes filtersamples 16 custom Data processing step to remove low CPM genes prior to differential expression analysis PCAReport 16 custom Summarization step to identify outliers prior to DE, contains pre- and post- normalization plots EBSeq 22 1.2.0 Data processing step to find differentially expressed isoforms, additional dependencies: rsem/1.3.0 edgeR 23 3.24.3 Data processing step to find differentially expressed genes. Counts are modeled using a negative binomial distribution with mean equal to the multiplication of library size and relative abundance while a quasi-likelihood F-test is used for testing gene differential expression DESeq2 13 1.22.2 Data processing step to find differentially expressed genes. Counts are modeled using a negative binomial distribution similar to edgeR while a wald-test is implemented to test for differential expression limma 7,8 3.38.3 Data processing step to find differentially expressed genes. Log-transformed counts are modeled using a method analogous to a t-distribution while a moderated t-statistics is used to test for differential expression l2p 16 custom Summarization step for gene set enrichment analysis","title":"Differential expression pipeline"},{"location":"RNA-seq/Differential-expression-pipeline-tools-and-versions/#references","text":"1. Daley, T. and A.D. Smith, Predicting the molecular complexity of sequencing libraries. Nat Methods, 2013. 10(4): p. 325-7. 2. Andrews, S. (2010). FastQC: a quality control tool for high throughput sequence data. 3. Martin, M. (2011). \"Cutadapt removes adapter sequences from high-throughput sequencing reads.\" EMBnet 17(1): 10-12. 4. Dobin, A., et al., STAR: ultrafast universal RNA-seq aligner. Bioinformatics, 2013. 29(1): p. 15-21. 5. Li, B. and C.N. Dewey, RSEM: accurate transcript quantification from RNA-Seq data with or without a reference genome. BMC Bioinformatics, 2011. 12: p. 323. 6. Harrow, J., et al., GENCODE: the reference human genome annotation for The ENCODE Project. Genome Res, 2012. 22(9): p. 1760-74. 7. Law, C.W., et al., voom: Precision weights unlock linear model analysis tools for RNA-seq read counts. Genome Biol, 2014. 15(2): p. R29. 8. Smyth, G.K., Linear models and empirical bayes methods for assessing differential expression in microarray experiments. Stat Appl Genet Mol Biol, 2004. 3: p. Article3. 9. Fabregat, A., et al., The Reactome Pathway Knowledgebase. Nucleic Acids Res, 2018. 46(D1): p. D649-D655. 10. Liberzon, A., et al., Molecular signatures database (MSigDB) 3.0. Bioinformatics, 2011. 27(12): p. 1739-40. 11. Wang, L., et al. (2012). \"RSeQC: quality control of RNA-seq experiments.\" Bioinformatics 28(16): 2184-2185. 12. The Picard toolkit. https://broadinstitute.github.io/picard/ . 13. Love, M. I., et al. (2014). \"Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2.\" Genome Biol 15(12): 550. 14. Liao, Y., et al. (2013). \"The Subread aligner: fast, accurate and scalable read mapping by seed-and-vote.\" Nucleic Acids Research 41(10): e108-e108. 15. Ewels, P., et al. (2016). \"MultiQC: summarize analysis results for multiple tools and samples in a single report.\" Bioinformatics 32(19): 3047-3048. 16. R Core Team (2018). R: A Language and Environment for Statistical Computing. Vienna, Austria, R Foundation for Statistical Computing. 17. Li, H., et al. (2009). \"The Sequence Alignment/Map format and SAMtools.\" Bioinformatics 25(16): 2078-2079. 18. Wood, D. E. and S. L. Salzberg (2014). \"Kraken: ultrafast metagenomic sequence classification using exact alignments.\" Genome Biol 15(3): R46. 19. Ondov, B. D., et al. (2011). \"Interactive metagenomic visualization in a Web browser.\" BMC Bioinformatics 12(1): 385. 20. Okonechnikov, K., et al. (2015). \"Qualimap 2: advanced multi-sample quality control for high-throughput sequencing data.\" Bioinformatics 32(2): 292-294. 21. Wingett, S. and S. Andrews (2018). \"FastQ Screen: A tool for multi-genome mapping and quality control.\" F1000Research 7(2): 1338. 22. Leng, N., et al. (2013). \"EBSeq: an empirical Bayes hierarchical model for inference in RNA-seq experiments.\" Bioinformatics 29(8): 1035-1043. 23. Robinson, M. D., et al. (2009). \"edgeR: a Bioconductor package for differential expression analysis of digital gene expression data.\" Bioinformatics 26(1): 139-140.","title":"References"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/","text":"User Tutorial \u00b6 Estimated completion time: 15 mins This section offers a guided tutorial that you can follow along on Biowulf. We have provided a test data set so you can learn how to set-up and run this pipeline. Please note: To follow along with this tutorial, you must have a Biowulf account . Quantification and quality-control pipeline \u00b6 This section provides step-by-step instructions for setting up the first pipeline (Quantification and Quality-control pipeline) and a brief description of the pipeline's output files and directories. We assume that you have already successfully launched the GUI. If not, please see Launch Pipeliner . About the Demo Dataset \u00b6 We have provided a test dataset that you can use to follow along with this tutorial. The raw data for this demo resides in /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/ . This demo dataset consists of 24 paired-end FastQ files for 12 samples, originating from a human cell-line. Libraries were constructed with a poly-A selection library preparation kit. There are three groups each with 4 replicates: Cntrl , TgA , and TgB . The Cntrl samples represent a baseline biological state while TgA and TgB samples represent the same cell-line after the treatment of two drugs: A and B . Here is a listing of all the samples in the demo dataset: $ ls /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/*.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S62.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S62.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S63.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S63.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S64.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S64.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S65.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S65.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S66.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S66.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S67.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S67.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S68.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S68.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S69.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S69.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S70.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S70.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S71.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S71.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S72.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S72.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S73.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S73.R2.fastq.gz Please Note: that \"R1\" and \"R2\" do not represent the replicate number. They denote forward and reverse reads, respectively. Pipeliner expects input files to follow a specific naming convention: <sampleName>.R1.fastq.gz , <sampleName>.R2.fastq.gz . FastQ files should end with the following extensions: .R1.fastq.gz and .R2.fastq.gz . Within <sampleName> , there are additional conventions you must follow. Please carefully read through all the rules for creating filenames. Before you can run the expression pipeline, there are a few key pieces of information that must be provided. Step 0. Fill out the Project Information section \u00b6 This section contains three fields: Project Id , Email address , Flow Cell ID . For this demo, you can set Project Id to project . This will be the name of the pipeline's master job. Please enter your email address in the Email address field. Step 1. Select the correct Pipeline Family \u00b6 Please select rnaseq from the pipeline family drop-down menu. Please note: The scrnaseq option is for single-cell data. This tutorial and pipeline are for bulk RNA-seq. To run the single-cell RNA-seq pipeline, please see its documentation. Step 2. Select the Reference Genome \u00b6 As mentioned above, these samples originate from a human cell-line. Please select hg38 from the Genome drop-down menu. Please Note: If you select a reference genome that is not supported by the pipeline, a pop-up box will notify you. Step 3. Select your Data Directory \u00b6 If you are following along with this tutorial, you can use the included demo dataset. Please select the Open Directory button and navigate to the following path in the pop-up box: /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/ Once you have pointed-to or navigated to the directory above, select OK . You should receive a message that 24 files were found. Click OK . Step 4. Select your Working Directory \u00b6 You are now ready to select your working directory. This is where all of the pipeline's output files will be created. In this tutorial, I set the working directory to /scratch/demo/rnaseq , but you could set it to another location like /scratch/demo/yourUserName/ . The only pre-requisite is that this directory should not exist. The process very similar to the step above except, you will point to a directory that does not exist on the filesystem. Please Note: Input and output files will be read from and written to the Biowulf's filesystem. If your raw data does not exist on Biowulf, you will need to upload it there first. Output files can be downloaded from Biowulf to your local computer for downstream analysis. Step 5. Initialize your Working Directory \u00b6 In this step, we will initialize or create the Working Directory defined in the step above. Please select the Initialize Directory button. During this step, the required resources to run the pipeline are copied into the working directory. After a few moments, you should receive a notification stating the directory was successfully initialized: Step 6. Select the Pipeline \u00b6 You are now ready to select the Quantification and Quality-control Pipeline. In the options section, please select Quality Control Analysis from the Pipeline field. Step 7. Load Group Information \u00b6 In the options, you will need to provide group information for each sample. Select Set Groups from the Sample Information section. Paste the group information below into the pop-up box and click save . Example groups.tab file Cntrl_S62 Cntrl Cntrl_1 Cntrl_S63 Cntrl Cntrl_2 Cntrl_S64 Cntrl Cntrl_3 Cntrl_S65 Cntrl Cntrl_4 TreatmentA_S66 TgA TgA_1 TreatmentA_S67 TgA TgA_2 TreatmentA_S68 TgA TgA_3 TreatmentA_S69 TgA TgA_4 TreatmentB_S70 TgB TgB_1 TreatmentB_S71 TgB TgB_2 TreatmentB_S72 TgB TgB_3 TreatmentB_S73 TgB TgB_4 Step 8. Dry-run the pipeline \u00b6 Please select the Dry-run button. This will generate the pipeline's Snakefile , run.json , and it will dry run the pipeline. This step take about 10-20 seconds to run, so please be patient until another window pops up with DAG information: If there is no error in the Dry Run , please close the dry-run popup box and proceed to the next step. Step 9. Run the pipeline \u00b6 You are now ready to run the Quantification and Quality-control pipeline! Please select the Run button. In a few moments, a pop-up box will appear stating that the job is starting. Please select OK . Once OK is selected from this popup box, the job will be submitted to the SLURM queue on Biowulf. That's it! You will receive an automated email when the pipeline starts and ends. You can now close out of the GUI. It should be noted that this pipeline takes around 3-4 hours to run. Check Progress \u00b6 If you are curious to see what jobs are running, you can run sjobs (or squeue -u $USER ). All of Pipeliner's jobs begin with the prefix pl: . Before running the second pipeline, it is important to ensure the pipeline has run to completion. There are a lot of factors that can cause a job to fail, some of which are out of our hands. To see if all the jobs have finished successfully, navigate to the Reports directory within your working directory, and examine the last few lines of the snakemake.log file. This file tracks the progress of all the jobs that get submitted to the cluster. If the pipeline has run to completion, it will look like this: If the pipeline reports that it's (100%) done , you are ready to run the Differential Expression Pipeline. You can also verify that all your jobs have completed by checking out the following file in your pipeline's working directory: HPC_usage_table.txt . This file doesn't appear until all jobs are finished. It contains information about each job submitted to the cluster. Here are columns in this tab-delimited file: 1 JobName 2 Jobid 3 Partition 4 State 5 Nodes 6 CPUs 7 Walltime 8 Runtime 9 MemReq 10 MemUsed 11 Nodelist 12 MaxCPUUsed 13 Queuetime 14 CPUHours 15 Account 16 Username This file can be opened in Microsoft Excel for easy viewing, or it can be viewed from the command-line. Please examine the values under the column State . The values can be COMPLETED , RUNNING , or FAILED . If there are no FAILED jobs and all jobs are COMPLETED , then the Quantification and Quality-control pipeline has finished running successfully. You are now ready to run to the Differential Expression pipeline.","title":"User Tutorial"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#user-tutorial","text":"Estimated completion time: 15 mins This section offers a guided tutorial that you can follow along on Biowulf. We have provided a test data set so you can learn how to set-up and run this pipeline. Please note: To follow along with this tutorial, you must have a Biowulf account .","title":"User Tutorial"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#quantification-and-quality-control-pipeline","text":"This section provides step-by-step instructions for setting up the first pipeline (Quantification and Quality-control pipeline) and a brief description of the pipeline's output files and directories. We assume that you have already successfully launched the GUI. If not, please see Launch Pipeliner .","title":"Quantification and quality-control pipeline"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#about-the-demo-dataset","text":"We have provided a test dataset that you can use to follow along with this tutorial. The raw data for this demo resides in /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/ . This demo dataset consists of 24 paired-end FastQ files for 12 samples, originating from a human cell-line. Libraries were constructed with a poly-A selection library preparation kit. There are three groups each with 4 replicates: Cntrl , TgA , and TgB . The Cntrl samples represent a baseline biological state while TgA and TgB samples represent the same cell-line after the treatment of two drugs: A and B . Here is a listing of all the samples in the demo dataset: $ ls /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/*.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S62.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S62.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S63.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S63.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S64.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S64.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S65.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/Cntrl_S65.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S66.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S66.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S67.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S67.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S68.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S68.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S69.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentA_S69.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S70.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S70.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S71.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S71.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S72.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S72.R2.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S73.R1.fastq.gz /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/TreatmentB_S73.R2.fastq.gz Please Note: that \"R1\" and \"R2\" do not represent the replicate number. They denote forward and reverse reads, respectively. Pipeliner expects input files to follow a specific naming convention: <sampleName>.R1.fastq.gz , <sampleName>.R2.fastq.gz . FastQ files should end with the following extensions: .R1.fastq.gz and .R2.fastq.gz . Within <sampleName> , there are additional conventions you must follow. Please carefully read through all the rules for creating filenames. Before you can run the expression pipeline, there are a few key pieces of information that must be provided.","title":"About the Demo Dataset"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#step-0-fill-out-the-project-information-section","text":"This section contains three fields: Project Id , Email address , Flow Cell ID . For this demo, you can set Project Id to project . This will be the name of the pipeline's master job. Please enter your email address in the Email address field.","title":"Step 0. Fill out the Project Information section"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#step-1-select-the-correct-pipeline-family","text":"Please select rnaseq from the pipeline family drop-down menu. Please note: The scrnaseq option is for single-cell data. This tutorial and pipeline are for bulk RNA-seq. To run the single-cell RNA-seq pipeline, please see its documentation.","title":"Step 1. Select the correct Pipeline Family"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#step-2-select-the-reference-genome","text":"As mentioned above, these samples originate from a human cell-line. Please select hg38 from the Genome drop-down menu. Please Note: If you select a reference genome that is not supported by the pipeline, a pop-up box will notify you.","title":"Step 2. Select the Reference Genome"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#step-3-select-your-data-directory","text":"If you are following along with this tutorial, you can use the included demo dataset. Please select the Open Directory button and navigate to the following path in the pop-up box: /data/CCBR_Pipeliner/testdata/rnaseq/expression_demo/ Once you have pointed-to or navigated to the directory above, select OK . You should receive a message that 24 files were found. Click OK .","title":"Step 3. Select your Data Directory"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#step-4-select-your-working-directory","text":"You are now ready to select your working directory. This is where all of the pipeline's output files will be created. In this tutorial, I set the working directory to /scratch/demo/rnaseq , but you could set it to another location like /scratch/demo/yourUserName/ . The only pre-requisite is that this directory should not exist. The process very similar to the step above except, you will point to a directory that does not exist on the filesystem. Please Note: Input and output files will be read from and written to the Biowulf's filesystem. If your raw data does not exist on Biowulf, you will need to upload it there first. Output files can be downloaded from Biowulf to your local computer for downstream analysis.","title":"Step 4. Select your Working Directory"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#step-5-initialize-your-working-directory","text":"In this step, we will initialize or create the Working Directory defined in the step above. Please select the Initialize Directory button. During this step, the required resources to run the pipeline are copied into the working directory. After a few moments, you should receive a notification stating the directory was successfully initialized:","title":"Step 5. Initialize your Working Directory"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#step-6-select-the-pipeline","text":"You are now ready to select the Quantification and Quality-control Pipeline. In the options section, please select Quality Control Analysis from the Pipeline field.","title":"Step 6. Select the Pipeline"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#step-7-load-group-information","text":"In the options, you will need to provide group information for each sample. Select Set Groups from the Sample Information section. Paste the group information below into the pop-up box and click save . Example groups.tab file Cntrl_S62 Cntrl Cntrl_1 Cntrl_S63 Cntrl Cntrl_2 Cntrl_S64 Cntrl Cntrl_3 Cntrl_S65 Cntrl Cntrl_4 TreatmentA_S66 TgA TgA_1 TreatmentA_S67 TgA TgA_2 TreatmentA_S68 TgA TgA_3 TreatmentA_S69 TgA TgA_4 TreatmentB_S70 TgB TgB_1 TreatmentB_S71 TgB TgB_2 TreatmentB_S72 TgB TgB_3 TreatmentB_S73 TgB TgB_4","title":"Step 7. Load Group Information"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#step-8-dry-run-the-pipeline","text":"Please select the Dry-run button. This will generate the pipeline's Snakefile , run.json , and it will dry run the pipeline. This step take about 10-20 seconds to run, so please be patient until another window pops up with DAG information: If there is no error in the Dry Run , please close the dry-run popup box and proceed to the next step.","title":"Step 8. Dry-run the pipeline"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#step-9-run-the-pipeline","text":"You are now ready to run the Quantification and Quality-control pipeline! Please select the Run button. In a few moments, a pop-up box will appear stating that the job is starting. Please select OK . Once OK is selected from this popup box, the job will be submitted to the SLURM queue on Biowulf. That's it! You will receive an automated email when the pipeline starts and ends. You can now close out of the GUI. It should be noted that this pipeline takes around 3-4 hours to run.","title":"Step 9. Run the pipeline"},{"location":"RNA-seq/Gene-and-isoform-expression-guided-tutorial/#check-progress","text":"If you are curious to see what jobs are running, you can run sjobs (or squeue -u $USER ). All of Pipeliner's jobs begin with the prefix pl: . Before running the second pipeline, it is important to ensure the pipeline has run to completion. There are a lot of factors that can cause a job to fail, some of which are out of our hands. To see if all the jobs have finished successfully, navigate to the Reports directory within your working directory, and examine the last few lines of the snakemake.log file. This file tracks the progress of all the jobs that get submitted to the cluster. If the pipeline has run to completion, it will look like this: If the pipeline reports that it's (100%) done , you are ready to run the Differential Expression Pipeline. You can also verify that all your jobs have completed by checking out the following file in your pipeline's working directory: HPC_usage_table.txt . This file doesn't appear until all jobs are finished. It contains information about each job submitted to the cluster. Here are columns in this tab-delimited file: 1 JobName 2 Jobid 3 Partition 4 State 5 Nodes 6 CPUs 7 Walltime 8 Runtime 9 MemReq 10 MemUsed 11 Nodelist 12 MaxCPUUsed 13 Queuetime 14 CPUHours 15 Account 16 Username This file can be opened in Microsoft Excel for easy viewing, or it can be viewed from the command-line. Please examine the values under the column State . The values can be COMPLETED , RUNNING , or FAILED . If there are no FAILED jobs and all jobs are COMPLETED , then the Quantification and Quality-control pipeline has finished running successfully. You are now ready to run to the Differential Expression pipeline.","title":"Check Progress"},{"location":"RNA-seq/Gene-and-isoform-expression-overview/","text":"Gene and isoform expression pipelines \u00b6 Overview \u00b6 This page is the main source of documentation for users that are getting started with the RNA-seq expression pipeline. If you are not familiar with RNA-seq, please checkout our theory and practical guide . That section provides a conceptual overview to RNA-seq analysis and as well as a set of generalized guidelines for different quality-control metrics. Our resources page contains more information about the pipeline's supported reference genomes along with every tool the pipeline employs. If you are a new user , we recommend following our guided tutorial with the provided test data set on Biowulf. If you are a new user and you would like to skip our guided tutorial, please see our quick start section . The RNA-seq expression workflow is composed of two phases (or pipelines). In the first pipeline, gene and isoform expression are quantified and pre- and post- alignment QC is performed. In the second pipeline, differential expression analysis is performed. In both pipelines, a series of interactive reports are generated to allow a user to explore their results. Both pipelines support the following reference genomes: Human hg19 hg38 hg38_30 hs37d5 hs38d1 hg38_30 Human + Integrated Virus hg38_30_KSHV hg38_HPV16 Mouse mm10 mm9 mm10_M21 Canine canFam3 Rhesus macaque Mmul_8.0.1 Quantification and quality-control pipeline \u00b6 In the first pipeline, the sequencing quality of each sample is independently assessed using FastQC, Preseq, Picard tools, RSeQC, SAMtools, and QualiMap. FastQ Screen and Kraken + Krona are used to screen for various sources of contamination. Adapter sequences are removed using Cutadapt prior to mapping to the user-selected reference genome. STAR is run in a two-pass mode where splice-junctions are collected and aggregated across all samples and provided to the second-pass of STAR. Gene and isoform expression levels are quantified using RSEM and subread. The expected counts from RSEM are merged across samples to create a two counts matrices for genes and isoforms. Fig 1. An Overview of the Quantification and Quality-control Pipeline. Gene and isoform counts are quantified and a series of QC-checks are performed to assess the quality of the data. This pipeline stops at the generation of a raw counts matrix, which is input to the next sub-workflow. To run the pipeline, a user must select their raw data directory (i.e. the location to their FastQ files), a reference genome, and output directory (i.e. the location where the pipeline performs the analysis). Quality-control information is summarized across all samples in the MultiQC report. Differential Expression pipeline \u00b6 In the second step, the count matrices from RSEM are filtered to remove low count genes (i.e. [CPM < 0.5] >= X samples ) prior to differential expression analysis. The filtered raw gene count matrix is normalized, and differential expression analysis is performed between user-defined groups of samples (i.e. contrasts) using three different methods: DESeq2, limma, and edgeR. Enriched pathways are identified via l2p over-representation test using gene sets from the Molecular Signatures Database. Please note: As input, this sub-workflow will accept the raw counts matrix generated in the first step (i.e. RNA-seq quantification and quality-control pipeline), or it will accept a user-provided raw counts matrix. Fig 2. An overview of the Differential Expression Pipeline. Three different methods (Deseq2, limma, and edgeR) are employed to find differentially expressed genes for each user-defined contrast. EBSeq is used to find differentially expressed isoforms. A PCA report containing before and after normalization plots (using DESeq2, limma, and edgeR) is generated for each contrast.","title":"Overview"},{"location":"RNA-seq/Gene-and-isoform-expression-overview/#gene-and-isoform-expression-pipelines","text":"","title":"Gene and isoform expression pipelines"},{"location":"RNA-seq/Gene-and-isoform-expression-overview/#overview","text":"This page is the main source of documentation for users that are getting started with the RNA-seq expression pipeline. If you are not familiar with RNA-seq, please checkout our theory and practical guide . That section provides a conceptual overview to RNA-seq analysis and as well as a set of generalized guidelines for different quality-control metrics. Our resources page contains more information about the pipeline's supported reference genomes along with every tool the pipeline employs. If you are a new user , we recommend following our guided tutorial with the provided test data set on Biowulf. If you are a new user and you would like to skip our guided tutorial, please see our quick start section . The RNA-seq expression workflow is composed of two phases (or pipelines). In the first pipeline, gene and isoform expression are quantified and pre- and post- alignment QC is performed. In the second pipeline, differential expression analysis is performed. In both pipelines, a series of interactive reports are generated to allow a user to explore their results. Both pipelines support the following reference genomes: Human hg19 hg38 hg38_30 hs37d5 hs38d1 hg38_30 Human + Integrated Virus hg38_30_KSHV hg38_HPV16 Mouse mm10 mm9 mm10_M21 Canine canFam3 Rhesus macaque Mmul_8.0.1","title":"Overview"},{"location":"RNA-seq/Gene-and-isoform-expression-overview/#quantification-and-quality-control-pipeline","text":"In the first pipeline, the sequencing quality of each sample is independently assessed using FastQC, Preseq, Picard tools, RSeQC, SAMtools, and QualiMap. FastQ Screen and Kraken + Krona are used to screen for various sources of contamination. Adapter sequences are removed using Cutadapt prior to mapping to the user-selected reference genome. STAR is run in a two-pass mode where splice-junctions are collected and aggregated across all samples and provided to the second-pass of STAR. Gene and isoform expression levels are quantified using RSEM and subread. The expected counts from RSEM are merged across samples to create a two counts matrices for genes and isoforms. Fig 1. An Overview of the Quantification and Quality-control Pipeline. Gene and isoform counts are quantified and a series of QC-checks are performed to assess the quality of the data. This pipeline stops at the generation of a raw counts matrix, which is input to the next sub-workflow. To run the pipeline, a user must select their raw data directory (i.e. the location to their FastQ files), a reference genome, and output directory (i.e. the location where the pipeline performs the analysis). Quality-control information is summarized across all samples in the MultiQC report.","title":"Quantification and quality-control pipeline"},{"location":"RNA-seq/Gene-and-isoform-expression-overview/#differential-expression-pipeline","text":"In the second step, the count matrices from RSEM are filtered to remove low count genes (i.e. [CPM < 0.5] >= X samples ) prior to differential expression analysis. The filtered raw gene count matrix is normalized, and differential expression analysis is performed between user-defined groups of samples (i.e. contrasts) using three different methods: DESeq2, limma, and edgeR. Enriched pathways are identified via l2p over-representation test using gene sets from the Molecular Signatures Database. Please note: As input, this sub-workflow will accept the raw counts matrix generated in the first step (i.e. RNA-seq quantification and quality-control pipeline), or it will accept a user-provided raw counts matrix. Fig 2. An overview of the Differential Expression Pipeline. Three different methods (Deseq2, limma, and edgeR) are employed to find differentially expressed genes for each user-defined contrast. EBSeq is used to find differentially expressed isoforms. A PCA report containing before and after normalization plots (using DESeq2, limma, and edgeR) is generated for each contrast.","title":"Differential Expression pipeline"},{"location":"RNA-seq/TLDR-RNA-seq/","text":"TLDR RNA-seq \u00b6 Throughout the data analysis process, there are many steps that we must repeat. These are often steps like removing adapter sequences, aligning reads, running QC, quantifying gene counts, and much more. Pipeliner is a pipeline runner . This means that those repetitive steps we needed to run before are now automated . With Pipeliner, you can run the same best-practices NGS pipelines developed, tested, and benchmarked by experts at CCBR and NCBR . Quick Start \u00b6 This section contains information for launching and setting up Pipeliner, and it also contains detailed steps for running the following Quantification and Quality-control pipeline. Launch Pipeliner \u00b6 To get started with the tutorial please, login into Biowulf with X11 forwarding enabled: # Step 0. Login ssh -Y $USER @biowulf.nih.gov X11 is needed to instantiate Pipeliner's Tkinter-based graphical user interface. Although it is not required, we recommend running Pipeliner from an interactive node. This will speed up certain steps that require some overhead later like dry-running the pipeline. You can get an interactive node on Biowulf by running the following command. # Recommended Step sinteractive --mem = 16g --cpus-per-task = 4 To see a complete listing of available Pipeliner modules on Biowulf, please run the following command: # Optional Step module avail ccbrpipeliner We recommend running the latest version of Pipeliner. In this tutorial, we will be using ccbrpipeliner/4.0.2 . Please note that we use semantic versioning for each of our releases so version major versions will not be compatible with each other (i.e. 3.0 is not compatible with 4.0 ). Please keep a note of the Pipeliner version that you are using for all of your analysis needs. As previously mentioned, we will be using 4.0.2 . Please load that module into your environment: # Step 1.) Load Pipeliner module load ccbrpipeliner/4.0.2 Loading Pipeliner will add all of its dependencies and executables into your $PATH . Please note: If you do not give an exact version, the default version will be loaded into your environment. The default version is not guaranteed to stay the same so it is generally better to explicitly provide an exact version to load. You are now ready to start Pipeliner's graphical user interface. To start the GUI, please run the following command: # Step 2.) Launch Pipeliner ccbrpipe.sh After running ccbrpipe.sh , you should now see Pipeliner's user interface: Please note: If you receive a message stating _tkinter.TclError: no display name and no $DISPLAY environment variable , this may be due to logging into Biowulf without enabling X11 forwarding. Please see our FAQ for more information. Setup Pipeliner \u00b6 In this section we assume, you have successfully Launched Pipeliner . Step 0.) Enter required fields in Project Information Please fill out the following required fields: Project Id and Email Address . Step 1.) Select Pipeline Family and Genome in Global Settings From the Pipeline Family drop-down, please select rnaseq . From the Genome drop-down, please select a reference genome. You can find more information about each available reference genome on our resources page . Once selected, a new RNAseq tab will appear. Step 1.) Provide PATHS To run the pipeline, you will need to provide two PATHS: 1. Data Directory : an existing PATH on the filesystem to your raw data (i.e. FASTQ files) - Files must adhere to our naming convention. Please see the rules below for naming your files. 2. Working Directory : PATH to the analysis output - If this is your first time running the pipeline for a given set of samples, this should be a new PATH on the filesystem (i.e. Pipeliner will create this folder when selecting Initialize Directory and copy over its required resources into this PATH). If you are carrying on your analysis, this will be the same directory you initialized in a previous run of Pipeliner. Please note: Pipeliner expects input files to follow a specific naming convention: basename .R1.fastq.gz, basename .R2.fastq.gz. FastQ files should end with the following extensions: .R1.fastq.gz and .R2.fastq.gz . Within basename , there are additional conventions you must follow. Please carefully read through all the rules for creating filenames. Rules for naming raw data files \u00b6 Rule Description Good Name Bad Name 1 Filenames CANNOT contain spaces Tumor_SC Tumor SC 2 Filenames CANNOT contain hyphens: - WT_rep1 WT-rep1 3 Filenames CANNOT start with a number t_ea 1_t_ea 4 Filenames CANNOT contain the strings sample , R1 or R2 Tumor_SC sample_SC 5 Filenames can contain underscores: _ T_S26_WT T_S26-SC Run Quantification and Quality-control pipeline \u00b6 In this section we assume, you have successfully Launched Pipeliner and Setup Pipeliner . Step 0.) Select pipeline To run this pipeline, select Quality Control Analysis from the Pipeline field in the Options section. Optional If this the first time running the pipeline for a given set of samples, you will need to initialize your working directory. Please click the Initialize Directory button. Please note: This will create the directory you defined in the Working Directory field. You only need to do this one time for any user-defined Working Directory . Please do not click this button again after the directory has been initialized or when you run the second half of the RNA-seq pipeline (Differential Expression pipeline). Step 1.) Understanding required sample metadata Next, you will need to provide groups.tab file. The groups.tab is a tab-delimited sample sheet file with three required columns. This file contains metadata for each sample. Here is an example: Wildtype_S1 WT WT_1 Wildtype_S2 WT WT_2 Knockout_S1 KO KO_1 Knockout_S2 KO KO_2 Description of each groups.tab column Column 1: Basenames Contains the basename for each sample. A basename is the raw data's filename without the following extensions: .R1.fastq.gz , .R2.fastq.gz . If you have paired-end data, you should only have one line in the groups.tab file for each sample. Pattern : basename .R{1,2}.fastq.gz Example : Input: A paired-end sample has the following raw data filenames: $ ls > WT_rep_1.R1.fastq.gz WT_rep_1.R2.fastq.gz Output: Given the following raw data filenames, the basename would be: WT_rep_1 Column 2: Groups Contains group information for each sample. This information is used for coloring plots and for defining groups of samples in differential expression analysis. Example : Input: A group of samples have the following raw data filenames: $ ls > WT_rep_1.R1.fastq.gz WT_rep_1.R2.fastq.gz WT_rep_2.R1.fastq.gz WT_rep_2.R2.fastq.gz Output: Given the following raw data filenames, the group name might be: Wildtype Column 3: Labels Contains label information for each sample. This field is used for creating an alias for each sample. The information in this column is used to create abbreviated sample names (or labels) when figures are generated. Example : Input: A group of samples have the following raw data filenames: $ ls > WT_rep_1.R1.fastq.gz WT_rep_1.R2.fastq.gz WT_rep_2.R1.fastq.gz WT_rep_2.R2.fastq.gz Output: Given the following raw data filenames, the labels might be: WT_1 WT_2 Creating a groups.tab file is easy! You can use your text editor of choice to create the file. Please note: If you use excel to create your groups file, you could run into some unexpected problems. Even after saving a file as TSV in excel, Microsoft products tend to add a new-line character that is not posix-compliant. You may need to run a tool like dos2unix on your file to fix this problem. As so, it is best to use a real text editor when creating this file. There are many free, open-source options: emacs, nano, neovim, vim, doom, evil, spacemacs, VS Code, Sublime Text, Atom, Text Wrangler, TextMate, Notepad++, etc. It is also worth noting that you can have more than two groups in your groups.tab ; however, the relationship between sample and group must be 1:1 . This means that you cannot have a sample belonging to more than one group. Again, the first column represents the sample's basename (filename without the .R?.fastq.gz extension); the second represents the sample's group; and, the third column represents an alias/label (an abbreviation) used for plotting figures. Step 2.) Providing sample metadata There are two ways to provide Pipeliner with group information: 1. Select Set Groups from the Sample Information section. Paste the group information from your text editor into the pop-up box and click save . 2. Create or copy a file called groups.tab in your working directory, then select Set Groups from the Sample Information section and click load + save . Step 3.) Dry-run the pipeline Please select the Dry-run button. This will generate the pipeline's Snakefile , run.json , and it will dry run the pipeline. Step 4.) Run the pipeline You are now ready to run the pipeline. Please select the Run button. In a few moments, a pop-up box will appear stating that the job is starting. Please select OK .","title":"Quick Start"},{"location":"RNA-seq/TLDR-RNA-seq/#tldr-rna-seq","text":"Throughout the data analysis process, there are many steps that we must repeat. These are often steps like removing adapter sequences, aligning reads, running QC, quantifying gene counts, and much more. Pipeliner is a pipeline runner . This means that those repetitive steps we needed to run before are now automated . With Pipeliner, you can run the same best-practices NGS pipelines developed, tested, and benchmarked by experts at CCBR and NCBR .","title":"TLDR RNA-seq"},{"location":"RNA-seq/TLDR-RNA-seq/#quick-start","text":"This section contains information for launching and setting up Pipeliner, and it also contains detailed steps for running the following Quantification and Quality-control pipeline.","title":"Quick Start"},{"location":"RNA-seq/TLDR-RNA-seq/#launch-pipeliner","text":"To get started with the tutorial please, login into Biowulf with X11 forwarding enabled: # Step 0. Login ssh -Y $USER @biowulf.nih.gov X11 is needed to instantiate Pipeliner's Tkinter-based graphical user interface. Although it is not required, we recommend running Pipeliner from an interactive node. This will speed up certain steps that require some overhead later like dry-running the pipeline. You can get an interactive node on Biowulf by running the following command. # Recommended Step sinteractive --mem = 16g --cpus-per-task = 4 To see a complete listing of available Pipeliner modules on Biowulf, please run the following command: # Optional Step module avail ccbrpipeliner We recommend running the latest version of Pipeliner. In this tutorial, we will be using ccbrpipeliner/4.0.2 . Please note that we use semantic versioning for each of our releases so version major versions will not be compatible with each other (i.e. 3.0 is not compatible with 4.0 ). Please keep a note of the Pipeliner version that you are using for all of your analysis needs. As previously mentioned, we will be using 4.0.2 . Please load that module into your environment: # Step 1.) Load Pipeliner module load ccbrpipeliner/4.0.2 Loading Pipeliner will add all of its dependencies and executables into your $PATH . Please note: If you do not give an exact version, the default version will be loaded into your environment. The default version is not guaranteed to stay the same so it is generally better to explicitly provide an exact version to load. You are now ready to start Pipeliner's graphical user interface. To start the GUI, please run the following command: # Step 2.) Launch Pipeliner ccbrpipe.sh After running ccbrpipe.sh , you should now see Pipeliner's user interface: Please note: If you receive a message stating _tkinter.TclError: no display name and no $DISPLAY environment variable , this may be due to logging into Biowulf without enabling X11 forwarding. Please see our FAQ for more information.","title":"Launch Pipeliner"},{"location":"RNA-seq/TLDR-RNA-seq/#setup-pipeliner","text":"In this section we assume, you have successfully Launched Pipeliner . Step 0.) Enter required fields in Project Information Please fill out the following required fields: Project Id and Email Address . Step 1.) Select Pipeline Family and Genome in Global Settings From the Pipeline Family drop-down, please select rnaseq . From the Genome drop-down, please select a reference genome. You can find more information about each available reference genome on our resources page . Once selected, a new RNAseq tab will appear. Step 1.) Provide PATHS To run the pipeline, you will need to provide two PATHS: 1. Data Directory : an existing PATH on the filesystem to your raw data (i.e. FASTQ files) - Files must adhere to our naming convention. Please see the rules below for naming your files. 2. Working Directory : PATH to the analysis output - If this is your first time running the pipeline for a given set of samples, this should be a new PATH on the filesystem (i.e. Pipeliner will create this folder when selecting Initialize Directory and copy over its required resources into this PATH). If you are carrying on your analysis, this will be the same directory you initialized in a previous run of Pipeliner. Please note: Pipeliner expects input files to follow a specific naming convention: basename .R1.fastq.gz, basename .R2.fastq.gz. FastQ files should end with the following extensions: .R1.fastq.gz and .R2.fastq.gz . Within basename , there are additional conventions you must follow. Please carefully read through all the rules for creating filenames.","title":"Setup Pipeliner"},{"location":"RNA-seq/TLDR-RNA-seq/#rules-for-naming-raw-data-files","text":"Rule Description Good Name Bad Name 1 Filenames CANNOT contain spaces Tumor_SC Tumor SC 2 Filenames CANNOT contain hyphens: - WT_rep1 WT-rep1 3 Filenames CANNOT start with a number t_ea 1_t_ea 4 Filenames CANNOT contain the strings sample , R1 or R2 Tumor_SC sample_SC 5 Filenames can contain underscores: _ T_S26_WT T_S26-SC","title":"Rules for naming raw data files"},{"location":"RNA-seq/TLDR-RNA-seq/#run-quantification-and-quality-control-pipeline","text":"In this section we assume, you have successfully Launched Pipeliner and Setup Pipeliner . Step 0.) Select pipeline To run this pipeline, select Quality Control Analysis from the Pipeline field in the Options section. Optional If this the first time running the pipeline for a given set of samples, you will need to initialize your working directory. Please click the Initialize Directory button. Please note: This will create the directory you defined in the Working Directory field. You only need to do this one time for any user-defined Working Directory . Please do not click this button again after the directory has been initialized or when you run the second half of the RNA-seq pipeline (Differential Expression pipeline). Step 1.) Understanding required sample metadata Next, you will need to provide groups.tab file. The groups.tab is a tab-delimited sample sheet file with three required columns. This file contains metadata for each sample. Here is an example: Wildtype_S1 WT WT_1 Wildtype_S2 WT WT_2 Knockout_S1 KO KO_1 Knockout_S2 KO KO_2 Description of each groups.tab column Column 1: Basenames Contains the basename for each sample. A basename is the raw data's filename without the following extensions: .R1.fastq.gz , .R2.fastq.gz . If you have paired-end data, you should only have one line in the groups.tab file for each sample. Pattern : basename .R{1,2}.fastq.gz Example : Input: A paired-end sample has the following raw data filenames: $ ls > WT_rep_1.R1.fastq.gz WT_rep_1.R2.fastq.gz Output: Given the following raw data filenames, the basename would be: WT_rep_1 Column 2: Groups Contains group information for each sample. This information is used for coloring plots and for defining groups of samples in differential expression analysis. Example : Input: A group of samples have the following raw data filenames: $ ls > WT_rep_1.R1.fastq.gz WT_rep_1.R2.fastq.gz WT_rep_2.R1.fastq.gz WT_rep_2.R2.fastq.gz Output: Given the following raw data filenames, the group name might be: Wildtype Column 3: Labels Contains label information for each sample. This field is used for creating an alias for each sample. The information in this column is used to create abbreviated sample names (or labels) when figures are generated. Example : Input: A group of samples have the following raw data filenames: $ ls > WT_rep_1.R1.fastq.gz WT_rep_1.R2.fastq.gz WT_rep_2.R1.fastq.gz WT_rep_2.R2.fastq.gz Output: Given the following raw data filenames, the labels might be: WT_1 WT_2 Creating a groups.tab file is easy! You can use your text editor of choice to create the file. Please note: If you use excel to create your groups file, you could run into some unexpected problems. Even after saving a file as TSV in excel, Microsoft products tend to add a new-line character that is not posix-compliant. You may need to run a tool like dos2unix on your file to fix this problem. As so, it is best to use a real text editor when creating this file. There are many free, open-source options: emacs, nano, neovim, vim, doom, evil, spacemacs, VS Code, Sublime Text, Atom, Text Wrangler, TextMate, Notepad++, etc. It is also worth noting that you can have more than two groups in your groups.tab ; however, the relationship between sample and group must be 1:1 . This means that you cannot have a sample belonging to more than one group. Again, the first column represents the sample's basename (filename without the .R?.fastq.gz extension); the second represents the sample's group; and, the third column represents an alias/label (an abbreviation) used for plotting figures. Step 2.) Providing sample metadata There are two ways to provide Pipeliner with group information: 1. Select Set Groups from the Sample Information section. Paste the group information from your text editor into the pop-up box and click save . 2. Create or copy a file called groups.tab in your working directory, then select Set Groups from the Sample Information section and click load + save . Step 3.) Dry-run the pipeline Please select the Dry-run button. This will generate the pipeline's Snakefile , run.json , and it will dry run the pipeline. Step 4.) Run the pipeline You are now ready to run the pipeline. Please select the Run button. In a few moments, a pop-up box will appear stating that the job is starting. Please select OK .","title":"Run Quantification and Quality-control pipeline"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/","text":"Introduction \u00b6 RNA-sequencing ( RNA-seq ) has a wide variety of applications; this transcriptome profiling method can be used to quantify gene and isoform expression, find changes in alternative splicing, detect gene-fusion events, call variants and much more. It is also worth noting that RNA-seq can be coupled with other biochemical assays to analyze many other aspects of RNA biology, such as RNA\u2013protein binding (CLIP-seq, RIP-seq), RNA structure (SHAPE-seq), or RNA\u2013RNA interactions (CLASH-seq). These applications are, however, beyond the scope of this documentation as we focus on typical RNA-seq project (i.e. quantifying expression). Our focus is to outline current standards and resources for the bioinformatics analysis of RNA-seq data. We do not aim to provide an exhaustive compilation of resources or software tools. Rather, we aim to provide a guideline and conceptual overview for RNA-seq data analysis based on our best-practices RNA-seq pipeline. Here we review all of the typical major steps in RNA-seq data analysis, starting from experimental design, quality control, read alignment, quantification of gene and transcript levels, and visualization. Experimental Design \u00b6 Just like any other scientific experiment, a good RNA-seq experiment is hypothesis-driven. If you cannot describe the problem you are trying to address, throwing NGS at the problem is not a cure-all solution. Fishing for results is a waste of your time and is bad science. As so, designing a well-thought-out experiment around a testable question will maximize the likelihood of generating high-impact results. The data that is generated will determine whether you have the potential to answer your biological question of interest. As a prerequisite, you need to think about how you will construct your libraries; the correct sequencing depth to address your question of interest; the number of replicates, and strategies to reduce/mitigate batch effects. Library construction \u00b6 rRNA can comprise up to 80% of the RNA in a cell. An important consideration is the RNA extraction protocol that will be used to remove the highly abundant ribosomal RNA (rRNA). For eukaryotic cells, there are two major considerations: choosing whether to enrich for mRNA or whether to deplete rRNA. mRNA: Poly-(A) selection is a common method used to enrich for mRNA. This method generates the highest percentage of reads which will ultimately map to protein-coding genes-- making it a common choice for most applications. That being said, poly(A)-selection requires your RNA to be of high quality with minimal degradation. Degraded samples that are followed with ploy(A)-selection may result in a 3\u2019 bias, which in effect, may introduce downstream biases into your results. total RNA: The second method captures total RNA through the depletion of rRNA. This method allows you to examine both mRNA and other non-coding RNA species such as lncRNAs. Again, depending on the question you are trying to answer this may be the right method for you. Although, it should be noted that both methods, mRNA and total RNA, require RINs (>8). But if you samples do contain slightly degraded RNA, you might be able to use the total RNA method over poly(A)-selection. Sequencing Depth \u00b6 Sequencing depth or library size is another important design factor. As sequencing depth is increased, more transcript will be detected (up until a saturation point), and their relative abundance will be quantified more accurately. mRNA ~ poly(A)-selection: For mRNA libraries, we recommend a minimum sequencing depth of 10-20M paired-end reads (or 20-40M reads). RNA must be of high quality. total RNA ~ rRNA depletion: For total RNA libraries, we recommend a sequencing depth of 25-60M paired-end reads (or 50-120M reads). RNA must be of high quality. Note: In the sections below, when I say paired-end reads I am referring to read pairs generated from paired-end sequencing of a given cDNA fragment. You will sometimes see reads reported as pairs of reads or total reads. Sequencing depth again depends on the aims of the experiment. Are you trying to quantify differences in gene expression, are you trying to quantify differential isoform usage or alternative splicing events? The numbers quoted above are more or less tailored to quantify differences in gene expression. If you are trying to quantify changes in alternative splicing or isoform regulation, you are going to much higher coverage (~ 100M paired-end reads). Replicates \u00b6 Another important design factor is the number of replicates. That being said, biological replicates are always preferred over technical replicates. Recommended: We recommend 4 biological replicates per experimental condition or group. Having more replicates is good for several reasons because in the real world problems arise. If you have a bad sample that cannot be used due to severe QC issues, you are still left with 3 biological replicates. This allows you to drop a bad sample without comprising statistical power downstream. Bare Minimum: If cost is a factor, at a minimum, 3 biological replicates will ensure good statistical power for downstream analysis. Reducing Batch Effects \u00b6 Batch effects represent unwanted sources of technical variation. Batch effects introduce non-biological variation into your data, which if not accounted for can influence the results. Through the process of library preparation to sequencing, there are a number of steps (such as RNA extraction to adapter ligation to lane loading, etc.) that might introduce biases into the resulting data. As a general rule of thumb, the best way to reduce the introduction of batch effects is through uniform processing-- meaning you need to ensure that differences in sample handling are minimal. This means that samples should be processed by the same lab technician and everything should be done in a uniform manner. That being said, do not extract your RNA at different times, do not use different lots of reagents! If a large number of samples are being processed and everything cannot be done at the same time, process representative samples from each biological group at the same time. This will ensure that batches and your variable of interest do not become confounded. Also, keep note of which samples belong to each batch. This information will be needed for batch correction. To reduce the possibility of introducing batch effects from sequencing, all samples should be multiplexed together on the same lane(s). Sample Group Batch Batch* Treatment_rep_1 KO 1 1 Treatment_rep_2 KO 2 1 Treatment_rep_3 KO 1 1 Treatment_rep_4 KO 2 1 Control_rep_1 WT 1 2 Control_rep_2 WT 2 2 Control_rep_3 WT 1 2 Control_rep_4 WT 2 2 Batch = properly balanced batches, easily corrected Batch* = Totally confounded Groups and Batches, cannot be corrected That being said, some problems cannot be bioinformatically corrected. If your variable of interest is totally confounded with your batches, applying batch correction to fix the problem is not going to work, and will lead to undesired results (i.e. Batch* column). If batches must be introduced due to other constraining factors, please keep note which samples belong to each batch, and please put some thought into how to properly balance samples across your batches. Quality Control \u00b6 Quality-control ( QC ) is extremely important! As the old adage goes: Garbage in, Garbage out! If there is one thing that to take away from this document, let it be that. Performing QC checks will help ensure that your results are reliable and reproducible. It is worth noting that there is a large variety of open-source tools that can be used to assess the quality of your data so there is no reason to re-invent the wheel. Please keep this in mind but also be aware that there are many wheels per se , and you will need to know which to use and when. In this next section, we will cover different quality-control checks that can be applied at different stages of your RNA-seq analysis. These recommendations are based on a few tools our best-practices RNA-seq pipeline employs. Pre-aligment \u00b6 Before drawing biological conclusions, it is important to perform quality control checks to ensure that there are no signs of sequencing error, biases in your data, or other sources of contamination. Modern high-throughput sequencers generate millions of reads per run, and in the real world, problems can arise. The general idea is to assess the quality of your reads before and after adapter removal and to check for different sources of contamination before proceeding to alignment. Here are a few of the tools that we use and recommend. FastQC: To assess the sequencing quality of your data, we recommend running FastQC before and after adapter trimming. FastQC generates a set of basic statistics to identify problems that can arise during sequencing or library preparation. FastQC will summarize per base and per read QC metrics such as quality scores and GC content (ideally, this plot should have a normal distribution with no forms of bimodality). It will also summarize the distribution of sequence lengths and will report the presence of adapter sequences, which is one reason we run it after removing adapters. FastQ Screen and Kraken: During the process of sample collection to library preparation, there is a risk for introducing wanted sources of DNA. FastQ Screen compares your sequencing data to a set of different reference genomes to determine if there is contamination. It allows a user to see if the composition of your library matches what you expect. If your data has high levels of human, mouse, fungi, or bacterial contamination, FastQ Screen will tell you. FastQ Screen will tell you what percentage of your library aligns against different reference genomes. If there are high levels of microbial contamination, Kraken will provide an estimation of the taxonomic composition. Kraken can be used in conjunction with Krona to produce interactive reports. Note: Due to high levels of homology between organisms there may be a small portion of your reads that align to an unexpected reference genome. Again, this should be a minimal percentage of your reads. Post-alignment \u00b6 Again, there are many tools available to assess the quality of your data post-alignment, and as stated before, there is no need to re-invent the wheel. Please see the table below for a generalized set of guidelines for different pre/post QC metrics. Preseq: Preseq can be used to estimate the complexity of a library for each of your samples. If the duplication rate is very high, the overall library complexity will be low. Low library complexity could signal an issue with library preparation or sample preparation (FFPE samples) where very little input RNA was over-amplified or the sample may be degraded. Picard CollectRNAseqMetrics: Picard has a particularly useful sub-command called CollectRNAseqMetrics which reports the number and percentage of reads that align to various regions: such as coding, intronic, UTR, intergenic and ribosomal regions. This is particularly useful as you would expect a library constructed with ploy(A)-selection to have a high percentage of reads that map to coding regions. Picard CollectRNAseqMetrics will also report the uniformity of coverage across all genes, which is useful for determining whether a sample has a 3' bias (observed in libraries containing degraded RNA). RSeQC: This is another particularity useful package that is tailored for RNA-seq data. The package is made up of over 20 sub-module that can be used to do things like calculate the average insert size between paired-end reads (which is useful for GEO upload), annotate the percentage of reads spanning known or novel splice junctions, and convert a BAM file into a normalized BigWig file. General QC Guidelines \u00b6 Here is a set of generalized guidelines for different QC metrics. Some of these metrics will vary genome-to-genome depending on the quality of the assembly and annotation but that has been taken into consideration for our set of supported reference genomes. QC Metric Guidelines mRNA total RNA RNA Type(s) Coding Coding + non-coding RIN >= 8 [low RIN ~ 3' bias] >= 8 Single-end vs Paired-end Paired-end Paired-end Sequencing Depth 10-20M PE reads 25-60M PE reads FastQC Q30 > 70% Q30 > 70% Percent Aligned to Reference > 70% > 65% Million Reads Aligned Reference > 7M PE reads > 16.5M PE reads Percent Aligned to rRNA < 5% < 15% Picard RNAseqMetrics Coding > 50% Coding > 35% Picard RNAseqMetrics Intronic + Intergenic < 25% Intronic + Intergenic < 40% Processing Pipeline \u00b6 Starting from raw data (FastQ files), how do we get a raw counts matrix, or how do we get a list of differential expressed genes? Before feeding your data into an R package for differential expression analysis, it needs to be processed to add biological context to it. In this section, we will talk about the data processing pipeline in more detail-- more specifically focusing on primary and secondary analysis. Primary Analysis \u00b6 Raw data > Adapter Trimming > Alignment > Quantification Adapter Trimming: One of the first steps in this process is to remove any unwanted adapters sequences from your reads in before alignment. Adapters are composed of synthetic sequences and should be removed prior to alignment. Adapter removal is especially important in certain protocols, such as miRNA-seq. When smaller fragments are sequenced it is almost certain there will be some form of adapter contamination. Alignment: In the alignment step, we add biological context to the raw data. In this step, we align reads to the reference genome to find where the sequenced fragments originate. Accurate alignment of the cDNA fragments (which are derived from RNA) is difficult. Alternative splicing introduces the problem of aligning to non-contiguous regions, and using traditional genomic alignment algorithms can produce inaccurate or low-quality alignments due to the combination of alternative splicing and genomic variation (substitutions, insertions, and deletions). This has lead to the development of splice-aware aligners like STAR, which are designed to overcome these issues. STAR can also be run in a two-pass mode for enhanced detection of reads mapping to novel splice junctions. Quantification: In the quantification step, the number of reads that mapped to a particular genomic feature (such as a gene or isoform) is counted. It is important to keep in mind that raw counts are biased by a number of factors such as library size, feature-length, and other compositional biases. As so, it is important to normalize your data to remove these biases before summarizing differences between groups of samples.","title":"Theory"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/#introduction","text":"RNA-sequencing ( RNA-seq ) has a wide variety of applications; this transcriptome profiling method can be used to quantify gene and isoform expression, find changes in alternative splicing, detect gene-fusion events, call variants and much more. It is also worth noting that RNA-seq can be coupled with other biochemical assays to analyze many other aspects of RNA biology, such as RNA\u2013protein binding (CLIP-seq, RIP-seq), RNA structure (SHAPE-seq), or RNA\u2013RNA interactions (CLASH-seq). These applications are, however, beyond the scope of this documentation as we focus on typical RNA-seq project (i.e. quantifying expression). Our focus is to outline current standards and resources for the bioinformatics analysis of RNA-seq data. We do not aim to provide an exhaustive compilation of resources or software tools. Rather, we aim to provide a guideline and conceptual overview for RNA-seq data analysis based on our best-practices RNA-seq pipeline. Here we review all of the typical major steps in RNA-seq data analysis, starting from experimental design, quality control, read alignment, quantification of gene and transcript levels, and visualization.","title":"Introduction"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/#experimental-design","text":"Just like any other scientific experiment, a good RNA-seq experiment is hypothesis-driven. If you cannot describe the problem you are trying to address, throwing NGS at the problem is not a cure-all solution. Fishing for results is a waste of your time and is bad science. As so, designing a well-thought-out experiment around a testable question will maximize the likelihood of generating high-impact results. The data that is generated will determine whether you have the potential to answer your biological question of interest. As a prerequisite, you need to think about how you will construct your libraries; the correct sequencing depth to address your question of interest; the number of replicates, and strategies to reduce/mitigate batch effects.","title":"Experimental Design"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/#library-construction","text":"rRNA can comprise up to 80% of the RNA in a cell. An important consideration is the RNA extraction protocol that will be used to remove the highly abundant ribosomal RNA (rRNA). For eukaryotic cells, there are two major considerations: choosing whether to enrich for mRNA or whether to deplete rRNA. mRNA: Poly-(A) selection is a common method used to enrich for mRNA. This method generates the highest percentage of reads which will ultimately map to protein-coding genes-- making it a common choice for most applications. That being said, poly(A)-selection requires your RNA to be of high quality with minimal degradation. Degraded samples that are followed with ploy(A)-selection may result in a 3\u2019 bias, which in effect, may introduce downstream biases into your results. total RNA: The second method captures total RNA through the depletion of rRNA. This method allows you to examine both mRNA and other non-coding RNA species such as lncRNAs. Again, depending on the question you are trying to answer this may be the right method for you. Although, it should be noted that both methods, mRNA and total RNA, require RINs (>8). But if you samples do contain slightly degraded RNA, you might be able to use the total RNA method over poly(A)-selection.","title":"Library construction"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/#sequencing-depth","text":"Sequencing depth or library size is another important design factor. As sequencing depth is increased, more transcript will be detected (up until a saturation point), and their relative abundance will be quantified more accurately. mRNA ~ poly(A)-selection: For mRNA libraries, we recommend a minimum sequencing depth of 10-20M paired-end reads (or 20-40M reads). RNA must be of high quality. total RNA ~ rRNA depletion: For total RNA libraries, we recommend a sequencing depth of 25-60M paired-end reads (or 50-120M reads). RNA must be of high quality. Note: In the sections below, when I say paired-end reads I am referring to read pairs generated from paired-end sequencing of a given cDNA fragment. You will sometimes see reads reported as pairs of reads or total reads. Sequencing depth again depends on the aims of the experiment. Are you trying to quantify differences in gene expression, are you trying to quantify differential isoform usage or alternative splicing events? The numbers quoted above are more or less tailored to quantify differences in gene expression. If you are trying to quantify changes in alternative splicing or isoform regulation, you are going to much higher coverage (~ 100M paired-end reads).","title":"Sequencing Depth"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/#replicates","text":"Another important design factor is the number of replicates. That being said, biological replicates are always preferred over technical replicates. Recommended: We recommend 4 biological replicates per experimental condition or group. Having more replicates is good for several reasons because in the real world problems arise. If you have a bad sample that cannot be used due to severe QC issues, you are still left with 3 biological replicates. This allows you to drop a bad sample without comprising statistical power downstream. Bare Minimum: If cost is a factor, at a minimum, 3 biological replicates will ensure good statistical power for downstream analysis.","title":"Replicates"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/#reducing-batch-effects","text":"Batch effects represent unwanted sources of technical variation. Batch effects introduce non-biological variation into your data, which if not accounted for can influence the results. Through the process of library preparation to sequencing, there are a number of steps (such as RNA extraction to adapter ligation to lane loading, etc.) that might introduce biases into the resulting data. As a general rule of thumb, the best way to reduce the introduction of batch effects is through uniform processing-- meaning you need to ensure that differences in sample handling are minimal. This means that samples should be processed by the same lab technician and everything should be done in a uniform manner. That being said, do not extract your RNA at different times, do not use different lots of reagents! If a large number of samples are being processed and everything cannot be done at the same time, process representative samples from each biological group at the same time. This will ensure that batches and your variable of interest do not become confounded. Also, keep note of which samples belong to each batch. This information will be needed for batch correction. To reduce the possibility of introducing batch effects from sequencing, all samples should be multiplexed together on the same lane(s). Sample Group Batch Batch* Treatment_rep_1 KO 1 1 Treatment_rep_2 KO 2 1 Treatment_rep_3 KO 1 1 Treatment_rep_4 KO 2 1 Control_rep_1 WT 1 2 Control_rep_2 WT 2 2 Control_rep_3 WT 1 2 Control_rep_4 WT 2 2 Batch = properly balanced batches, easily corrected Batch* = Totally confounded Groups and Batches, cannot be corrected That being said, some problems cannot be bioinformatically corrected. If your variable of interest is totally confounded with your batches, applying batch correction to fix the problem is not going to work, and will lead to undesired results (i.e. Batch* column). If batches must be introduced due to other constraining factors, please keep note which samples belong to each batch, and please put some thought into how to properly balance samples across your batches.","title":"Reducing Batch Effects"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/#quality-control","text":"Quality-control ( QC ) is extremely important! As the old adage goes: Garbage in, Garbage out! If there is one thing that to take away from this document, let it be that. Performing QC checks will help ensure that your results are reliable and reproducible. It is worth noting that there is a large variety of open-source tools that can be used to assess the quality of your data so there is no reason to re-invent the wheel. Please keep this in mind but also be aware that there are many wheels per se , and you will need to know which to use and when. In this next section, we will cover different quality-control checks that can be applied at different stages of your RNA-seq analysis. These recommendations are based on a few tools our best-practices RNA-seq pipeline employs.","title":"Quality Control"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/#pre-aligment","text":"Before drawing biological conclusions, it is important to perform quality control checks to ensure that there are no signs of sequencing error, biases in your data, or other sources of contamination. Modern high-throughput sequencers generate millions of reads per run, and in the real world, problems can arise. The general idea is to assess the quality of your reads before and after adapter removal and to check for different sources of contamination before proceeding to alignment. Here are a few of the tools that we use and recommend. FastQC: To assess the sequencing quality of your data, we recommend running FastQC before and after adapter trimming. FastQC generates a set of basic statistics to identify problems that can arise during sequencing or library preparation. FastQC will summarize per base and per read QC metrics such as quality scores and GC content (ideally, this plot should have a normal distribution with no forms of bimodality). It will also summarize the distribution of sequence lengths and will report the presence of adapter sequences, which is one reason we run it after removing adapters. FastQ Screen and Kraken: During the process of sample collection to library preparation, there is a risk for introducing wanted sources of DNA. FastQ Screen compares your sequencing data to a set of different reference genomes to determine if there is contamination. It allows a user to see if the composition of your library matches what you expect. If your data has high levels of human, mouse, fungi, or bacterial contamination, FastQ Screen will tell you. FastQ Screen will tell you what percentage of your library aligns against different reference genomes. If there are high levels of microbial contamination, Kraken will provide an estimation of the taxonomic composition. Kraken can be used in conjunction with Krona to produce interactive reports. Note: Due to high levels of homology between organisms there may be a small portion of your reads that align to an unexpected reference genome. Again, this should be a minimal percentage of your reads.","title":"Pre-aligment"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/#post-alignment","text":"Again, there are many tools available to assess the quality of your data post-alignment, and as stated before, there is no need to re-invent the wheel. Please see the table below for a generalized set of guidelines for different pre/post QC metrics. Preseq: Preseq can be used to estimate the complexity of a library for each of your samples. If the duplication rate is very high, the overall library complexity will be low. Low library complexity could signal an issue with library preparation or sample preparation (FFPE samples) where very little input RNA was over-amplified or the sample may be degraded. Picard CollectRNAseqMetrics: Picard has a particularly useful sub-command called CollectRNAseqMetrics which reports the number and percentage of reads that align to various regions: such as coding, intronic, UTR, intergenic and ribosomal regions. This is particularly useful as you would expect a library constructed with ploy(A)-selection to have a high percentage of reads that map to coding regions. Picard CollectRNAseqMetrics will also report the uniformity of coverage across all genes, which is useful for determining whether a sample has a 3' bias (observed in libraries containing degraded RNA). RSeQC: This is another particularity useful package that is tailored for RNA-seq data. The package is made up of over 20 sub-module that can be used to do things like calculate the average insert size between paired-end reads (which is useful for GEO upload), annotate the percentage of reads spanning known or novel splice junctions, and convert a BAM file into a normalized BigWig file.","title":"Post-alignment"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/#general-qc-guidelines","text":"Here is a set of generalized guidelines for different QC metrics. Some of these metrics will vary genome-to-genome depending on the quality of the assembly and annotation but that has been taken into consideration for our set of supported reference genomes. QC Metric Guidelines mRNA total RNA RNA Type(s) Coding Coding + non-coding RIN >= 8 [low RIN ~ 3' bias] >= 8 Single-end vs Paired-end Paired-end Paired-end Sequencing Depth 10-20M PE reads 25-60M PE reads FastQC Q30 > 70% Q30 > 70% Percent Aligned to Reference > 70% > 65% Million Reads Aligned Reference > 7M PE reads > 16.5M PE reads Percent Aligned to rRNA < 5% < 15% Picard RNAseqMetrics Coding > 50% Coding > 35% Picard RNAseqMetrics Intronic + Intergenic < 25% Intronic + Intergenic < 40%","title":"General QC Guidelines"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/#processing-pipeline","text":"Starting from raw data (FastQ files), how do we get a raw counts matrix, or how do we get a list of differential expressed genes? Before feeding your data into an R package for differential expression analysis, it needs to be processed to add biological context to it. In this section, we will talk about the data processing pipeline in more detail-- more specifically focusing on primary and secondary analysis.","title":"Processing Pipeline"},{"location":"RNA-seq/Theory-and-practical-guide-for-RNA-seq/#primary-analysis","text":"Raw data > Adapter Trimming > Alignment > Quantification Adapter Trimming: One of the first steps in this process is to remove any unwanted adapters sequences from your reads in before alignment. Adapters are composed of synthetic sequences and should be removed prior to alignment. Adapter removal is especially important in certain protocols, such as miRNA-seq. When smaller fragments are sequenced it is almost certain there will be some form of adapter contamination. Alignment: In the alignment step, we add biological context to the raw data. In this step, we align reads to the reference genome to find where the sequenced fragments originate. Accurate alignment of the cDNA fragments (which are derived from RNA) is difficult. Alternative splicing introduces the problem of aligning to non-contiguous regions, and using traditional genomic alignment algorithms can produce inaccurate or low-quality alignments due to the combination of alternative splicing and genomic variation (substitutions, insertions, and deletions). This has lead to the development of splice-aware aligners like STAR, which are designed to overcome these issues. STAR can also be run in a two-pass mode for enhanced detection of reads mapping to novel splice junctions. Quantification: In the quantification step, the number of reads that mapped to a particular genomic feature (such as a gene or isoform) is counted. It is important to keep in mind that raw counts are biased by a number of factors such as library size, feature-length, and other compositional biases. As so, it is important to normalize your data to remove these biases before summarizing differences between groups of samples.","title":"Primary Analysis"},{"location":"WEG-seq/TLDR-WEG-seq/","text":"WES/WGS Quick Start \u00b6 Launch Pipeliner \u00b6 The RNA-Seq documentation contains a good guide on starting the Pipeliner GUI Select Pipeline \u00b6 From the \" Pipeline Family \" dropdown menu, select exomeseq or genomeseq , depending on the type of sequencing, and then select the genome. Currently only hg19 , hg38 , and mm10 are supported. Provide Data Paths \u00b6 The RNA-Seq documentation has a handy table of rules for naming raw data files and a more detailed guide for setting up the raw data In the \" Data Directory \" input box, enter the full path of the folder that contains your raw, gzipped, paired-end FASTQ files. You can use the \" Open Directory \" button to browse through the filesystem to locate the directory, or type in the path manually. The CCBR Tools repo also contains a bash script to automatically create a labels.txt file. In the \" Working Directory \" input box, enter the full path of the folder to which the output will be stored. You can use the \" Open Directory \" button to browse through the filesystem to locate the directory, or type in the path manually. Here's an example of what the GUI should look like when filled out: Run Intial QC \u00b6 For all exome and genome pipelines, workflows consist of 2 stages: Initial QC and variant calling. The initialQC portion of the workflow MUST ALWAYS BE EXECUTED TO COMPLETION BEFORE VARIANT CALLING. When first running the Initial QC pipeline, click on the \" Initialize Directory \" button. For EXOME analysis, you must provide the full path to the exome targets bed file in the area highlighted below. Please check with the sequencing facility or the manufacturer of the exome capture kit for this file. If there are no errors, click on the \" Dry Run \" button. This may take several minutes if you have a large number of input files. Inspect the Dry Run output. It should show a tally of the rules that will be executed and details of each step for each file, like this: Run variant calling \u00b6 Pipeliner supports three types of variant calling: Germline , Somatic Tumor-Normal , or Somatic Tumor-only . Once Initial QC is completed, setup the Pipeliner options exactly as before, and in the Pipeline dropdown, select one of the variant calling pipelines. For the tumor-normal pipeline, the sample pairing must be specified for each pair in the area highlighted below. When you specify 'Somatic Tumor-Normal' in the Pipeline dropdown menu of the Options box, a 'Pairs' text input area will appear (marked in red above). Inside that window, you can write in the pairs, with each pair on a separate line, the normal sample in the first column, the tumor sample in the second column, and with a tab separating the columns. For example, if the fastq files for the tumor sample are named Sample_1_tumor.R[1,2].fastq.gz and the matched normal is Sample_1_normal.R[1,2].fastq.gz , the pairs file would look like this: Sample_1_normal Sample_1_tumor Track Progress \u00b6 Within the GUI, set up the fields exactly as you did above when you started the pipeline, but instead of initializing, select 'Progress' from the 'View' menu at the top of the GUI. This will generate a workflow, with the the completed steps in colored circles, and the incomplete steps in gray. Alternatively, you can simply read the last line of the 'snakemake.log' file in the 'Reports' directory within the working directory. This file is written to every time a job is submitted or completed, giving you information concerning the % jobs completed, as well as any error messages describing failed jobs. The CCBR Tools repo also contains a bash script to parse the snakemake.log file and determine the slurm job IDs and logs that likely contain the error(s). Finally, we also provide a bash script to cancel slurm jobs listed in a snakemake log file. This is helpful when you have multiple Pipeliner runs going on, and you want to selectively cancel one of them (at a time).","title":"User Tutorial"},{"location":"WEG-seq/TLDR-WEG-seq/#weswgs-quick-start","text":"","title":"WES/WGS Quick Start"},{"location":"WEG-seq/TLDR-WEG-seq/#launch-pipeliner","text":"The RNA-Seq documentation contains a good guide on starting the Pipeliner GUI","title":"Launch Pipeliner"},{"location":"WEG-seq/TLDR-WEG-seq/#select-pipeline","text":"From the \" Pipeline Family \" dropdown menu, select exomeseq or genomeseq , depending on the type of sequencing, and then select the genome. Currently only hg19 , hg38 , and mm10 are supported.","title":"Select Pipeline"},{"location":"WEG-seq/TLDR-WEG-seq/#provide-data-paths","text":"The RNA-Seq documentation has a handy table of rules for naming raw data files and a more detailed guide for setting up the raw data In the \" Data Directory \" input box, enter the full path of the folder that contains your raw, gzipped, paired-end FASTQ files. You can use the \" Open Directory \" button to browse through the filesystem to locate the directory, or type in the path manually. The CCBR Tools repo also contains a bash script to automatically create a labels.txt file. In the \" Working Directory \" input box, enter the full path of the folder to which the output will be stored. You can use the \" Open Directory \" button to browse through the filesystem to locate the directory, or type in the path manually. Here's an example of what the GUI should look like when filled out:","title":"Provide Data Paths"},{"location":"WEG-seq/TLDR-WEG-seq/#run-intial-qc","text":"For all exome and genome pipelines, workflows consist of 2 stages: Initial QC and variant calling. The initialQC portion of the workflow MUST ALWAYS BE EXECUTED TO COMPLETION BEFORE VARIANT CALLING. When first running the Initial QC pipeline, click on the \" Initialize Directory \" button. For EXOME analysis, you must provide the full path to the exome targets bed file in the area highlighted below. Please check with the sequencing facility or the manufacturer of the exome capture kit for this file. If there are no errors, click on the \" Dry Run \" button. This may take several minutes if you have a large number of input files. Inspect the Dry Run output. It should show a tally of the rules that will be executed and details of each step for each file, like this:","title":"Run Intial QC"},{"location":"WEG-seq/TLDR-WEG-seq/#run-variant-calling","text":"Pipeliner supports three types of variant calling: Germline , Somatic Tumor-Normal , or Somatic Tumor-only . Once Initial QC is completed, setup the Pipeliner options exactly as before, and in the Pipeline dropdown, select one of the variant calling pipelines. For the tumor-normal pipeline, the sample pairing must be specified for each pair in the area highlighted below. When you specify 'Somatic Tumor-Normal' in the Pipeline dropdown menu of the Options box, a 'Pairs' text input area will appear (marked in red above). Inside that window, you can write in the pairs, with each pair on a separate line, the normal sample in the first column, the tumor sample in the second column, and with a tab separating the columns. For example, if the fastq files for the tumor sample are named Sample_1_tumor.R[1,2].fastq.gz and the matched normal is Sample_1_normal.R[1,2].fastq.gz , the pairs file would look like this: Sample_1_normal Sample_1_tumor","title":"Run variant calling"},{"location":"WEG-seq/TLDR-WEG-seq/#track-progress","text":"Within the GUI, set up the fields exactly as you did above when you started the pipeline, but instead of initializing, select 'Progress' from the 'View' menu at the top of the GUI. This will generate a workflow, with the the completed steps in colored circles, and the incomplete steps in gray. Alternatively, you can simply read the last line of the 'snakemake.log' file in the 'Reports' directory within the working directory. This file is written to every time a job is submitted or completed, giving you information concerning the % jobs completed, as well as any error messages describing failed jobs. The CCBR Tools repo also contains a bash script to parse the snakemake.log file and determine the slurm job IDs and logs that likely contain the error(s). Finally, we also provide a bash script to cancel slurm jobs listed in a snakemake log file. This is helpful when you have multiple Pipeliner runs going on, and you want to selectively cancel one of them (at a time).","title":"Track Progress"},{"location":"WEG-seq/Whole-exome-genome-output/","text":"Output from the whole genome and exome pipelines \u00b6 The output files and their locations are broken down here per pipeline type. All file locations are relative to the working directory specified for the Pipeliner run. Initial QC \u00b6 The Intial QC pipeline is the first step for both exome and genome workflows. It implements alignment and pre-processing according to best practices for GATK 3.6. Here's a table of the most important output files from this pipeline. Pipeline Output Type Tool(s) File Location Initial QC Original fastqs (symlinked) -- [sample].R[1,2].fastq.gz Recalibrated (BQSR) BAMs GATK 3.6 [sample].recal.bam QC Report multiqc, qualimap, fastqc, fastq_screen multiqc_report.html Germline \u00b6 This pipeline is essentially the GATK Best Practices with a few alterations detailed below. Briefly, joint SNP and INDEL variant detection is conducted across all samples included in a pipeline run using the GATK Haplotypcaller under default settings. This produces the 'combined.vcf' call file. This file is subsequently filtered at two levels of stringency based on several GATK annotations: A strict set of criteria (QD < 2.0, FS > 60.0, MQ < 40.0, MQRankSum < -12.5, ReadPosRankSum < -8.0 for SNPs; QD < 2.0, FS > 200.0, ReadPosRankSum < -20.0 for INDELs) generates the 'combined.strictFilter.vcf'. This call set is highly stringent, maximizing the true positive rate at the expense of an elevated false negative rate. This call set is really only intended for more general population genetic scale analyses (e.g., burden tests, admixture, linkage/pedigree based analysis, etc.) where false positives can be significantly confounding. A relaxed set of criteria (QD < 2.0, FS > 60.0 for SNPs; QD < 2.0, FS > 200.0 for INDELs) generates the 'combined.relaxedFilter.vcf' file. This call set is an attempt to optimize the balance between false positive and false negative, and is generally suitable for all discovery applications. Unless you have strong justification otherwise, the 'combined.relaxedFilter.vcf' file should be used for all downstream analyses. In addition, we provide structural variants called using Manta v1.2.0 and Svaba. We also provide copy number calling using Freec and Sequenza, as well as Canvas for WGS data. Finally, a basic analyses of sample relatedness and ancestry (e.g., % European, African, etc.) is also performed and displayed as a network tree. Pipeline Output Type Tool(s) File Location Germline SNVs Strict Filter exome.strictFilter.vcf Relaxed Filter exome.relaxedFilter.vcf Admixture and PLINK admixture_out/admixture_mqc.png admixture_out/admixture_table.tsv admixture_out/samples_and_knowns_filtered_recode* Structural Variants Manta manta_out/[pair]/results/variants/diploidSV.vcf.gz SvABA svaba_out/* Copy Number Variants Canvas (WGS only) canvas_out/* Tumor-Normal \u00b6 This workflow calls somatic SNPs and INDELs using three variant detection algorithms. For each of these tools, variants are called in a paired tumor-normal fashion, with default settings. For each sample, the resulting VCF is fully annotated using VEP v92 and converted to a MAF file using the vcf2maf tool. Resulting MAF files are found in the onctotator_out directory within each caller's results directory (e.g., mutect2_out/oncotator_out/NORMAL+TUMOR.maf). Individual sample MAF files are then merged within the oncotator_out directory for each caller (e.g., mutect2_out/oncotator_out/mutect2_merged.maf), and MutSigCV is run for each caller separately (e.g., mutect2_out/mutsigCV_out/). In addition, within each caller's output directory, an oncoplot for the top 30 non-silent mutated genes and a general MAF summary are generated. For Copy Number Variants (CNVs), two tools are employed in tandem. First, Control-FREEC is run with default parameters. This generates pileup files that can be used by Sequenza, primarily for jointly estimating contamination and ploidy. These value are used to run Freec a second time for improved performance. Sample pairing must be provided as shown in the Quick Start guide. Individual germline samples samples can be used multiple times (e.g., for multiple tumors from the same patient), as long as one of the two samples in the pair is unique. You cannot run the exact pair in duplicate in the same run. For Mutect2, we use a panel of normals (PON) developed from the ExAC (excluding TCGA) dataset, filtered for variants <0.001 in the general population, and also including and in-house set of blacklisted recurrent germline variants that are not found in any population databases. Finally, germline analysis is also performed (see above for output details) with the Tumor-Normal pipeline. Pipeline Output Type Tool(s) File Location Somatic Tumor-Normal SNVs mutect VCF mutect_out/[pair].FINAL.vcf Mutect MAF and Summaries mutect_out/oncotator_out/final_filtered.maf mutect_out/oncotator_out/variants_fixed.maf mutect_out/oncotator_out/tcga_comparison.pdf mutect_out/oncotator_out/genes_by_VAF.pdf Mutect2 MAF and Summaries mutect2_out/oncotator_out/final_filtered.maf mutect2_out/oncotator_out/variants_fixed.maf mutect2_out/oncotator_out/tcga_comparison.pdf mutect2_out/oncotator_out/genes_by_VAF.pdf VarDict MAF and Summaries vardict_out/oncotator_out/final_filtered.maf vardict_out/oncotator_out/variants_fixed.maf vardict_out/oncotator_out/tcga_comparison.pdf vardict_out/oncotator_out/genes_by_VAF.pdf Strelka MAF and Summaries strelka_out/oncotator_out/final_filtered.maf strelka_out/oncotator_out/variants_fixed.maf strelka_out/oncotator_out/tcga_comparison.pdf strelka_out/oncotator_out/genes_by_VAF.pdf Merged Somatic Variants merged_somatic_variants/oncotator_out/final_filtered.maf merged_somatic_variants/oncotator_out/variants_fixed.maf merged_somatic_variants/oncotator_out/tcga_comparison.pdf merged_somatic_variants/oncotator_out/genes_by_VAF.pdf Structural Variants Manta manta_out/[pair]/results/variants/diploidSV.vcf.gz Copy Number Variants Control-FREEC (Pass 1) freec_out/pass1/[pair].recal.bam_CNVs.p.value.txt Control-FREEC (Pass 2) freec_out/pass2/[pair].recal.bam_CNVs.p.value.txt Sequenza sequenza_out/[tumor-sample]/* Tumor-Only \u00b6 In general, the tumor-only pipeline is a stripped down version of the tumor-normal pipeline. We only run MuTect2, Mutect, and VarDict for somatic variant detection, with the same PON and filtering as described above for the tumor-normal pipeline.","title":"Output Files"},{"location":"WEG-seq/Whole-exome-genome-output/#output-from-the-whole-genome-and-exome-pipelines","text":"The output files and their locations are broken down here per pipeline type. All file locations are relative to the working directory specified for the Pipeliner run.","title":"Output from the whole genome and exome pipelines"},{"location":"WEG-seq/Whole-exome-genome-output/#initial-qc","text":"The Intial QC pipeline is the first step for both exome and genome workflows. It implements alignment and pre-processing according to best practices for GATK 3.6. Here's a table of the most important output files from this pipeline. Pipeline Output Type Tool(s) File Location Initial QC Original fastqs (symlinked) -- [sample].R[1,2].fastq.gz Recalibrated (BQSR) BAMs GATK 3.6 [sample].recal.bam QC Report multiqc, qualimap, fastqc, fastq_screen multiqc_report.html","title":"Initial QC"},{"location":"WEG-seq/Whole-exome-genome-output/#germline","text":"This pipeline is essentially the GATK Best Practices with a few alterations detailed below. Briefly, joint SNP and INDEL variant detection is conducted across all samples included in a pipeline run using the GATK Haplotypcaller under default settings. This produces the 'combined.vcf' call file. This file is subsequently filtered at two levels of stringency based on several GATK annotations: A strict set of criteria (QD < 2.0, FS > 60.0, MQ < 40.0, MQRankSum < -12.5, ReadPosRankSum < -8.0 for SNPs; QD < 2.0, FS > 200.0, ReadPosRankSum < -20.0 for INDELs) generates the 'combined.strictFilter.vcf'. This call set is highly stringent, maximizing the true positive rate at the expense of an elevated false negative rate. This call set is really only intended for more general population genetic scale analyses (e.g., burden tests, admixture, linkage/pedigree based analysis, etc.) where false positives can be significantly confounding. A relaxed set of criteria (QD < 2.0, FS > 60.0 for SNPs; QD < 2.0, FS > 200.0 for INDELs) generates the 'combined.relaxedFilter.vcf' file. This call set is an attempt to optimize the balance between false positive and false negative, and is generally suitable for all discovery applications. Unless you have strong justification otherwise, the 'combined.relaxedFilter.vcf' file should be used for all downstream analyses. In addition, we provide structural variants called using Manta v1.2.0 and Svaba. We also provide copy number calling using Freec and Sequenza, as well as Canvas for WGS data. Finally, a basic analyses of sample relatedness and ancestry (e.g., % European, African, etc.) is also performed and displayed as a network tree. Pipeline Output Type Tool(s) File Location Germline SNVs Strict Filter exome.strictFilter.vcf Relaxed Filter exome.relaxedFilter.vcf Admixture and PLINK admixture_out/admixture_mqc.png admixture_out/admixture_table.tsv admixture_out/samples_and_knowns_filtered_recode* Structural Variants Manta manta_out/[pair]/results/variants/diploidSV.vcf.gz SvABA svaba_out/* Copy Number Variants Canvas (WGS only) canvas_out/*","title":"Germline"},{"location":"WEG-seq/Whole-exome-genome-output/#tumor-normal","text":"This workflow calls somatic SNPs and INDELs using three variant detection algorithms. For each of these tools, variants are called in a paired tumor-normal fashion, with default settings. For each sample, the resulting VCF is fully annotated using VEP v92 and converted to a MAF file using the vcf2maf tool. Resulting MAF files are found in the onctotator_out directory within each caller's results directory (e.g., mutect2_out/oncotator_out/NORMAL+TUMOR.maf). Individual sample MAF files are then merged within the oncotator_out directory for each caller (e.g., mutect2_out/oncotator_out/mutect2_merged.maf), and MutSigCV is run for each caller separately (e.g., mutect2_out/mutsigCV_out/). In addition, within each caller's output directory, an oncoplot for the top 30 non-silent mutated genes and a general MAF summary are generated. For Copy Number Variants (CNVs), two tools are employed in tandem. First, Control-FREEC is run with default parameters. This generates pileup files that can be used by Sequenza, primarily for jointly estimating contamination and ploidy. These value are used to run Freec a second time for improved performance. Sample pairing must be provided as shown in the Quick Start guide. Individual germline samples samples can be used multiple times (e.g., for multiple tumors from the same patient), as long as one of the two samples in the pair is unique. You cannot run the exact pair in duplicate in the same run. For Mutect2, we use a panel of normals (PON) developed from the ExAC (excluding TCGA) dataset, filtered for variants <0.001 in the general population, and also including and in-house set of blacklisted recurrent germline variants that are not found in any population databases. Finally, germline analysis is also performed (see above for output details) with the Tumor-Normal pipeline. Pipeline Output Type Tool(s) File Location Somatic Tumor-Normal SNVs mutect VCF mutect_out/[pair].FINAL.vcf Mutect MAF and Summaries mutect_out/oncotator_out/final_filtered.maf mutect_out/oncotator_out/variants_fixed.maf mutect_out/oncotator_out/tcga_comparison.pdf mutect_out/oncotator_out/genes_by_VAF.pdf Mutect2 MAF and Summaries mutect2_out/oncotator_out/final_filtered.maf mutect2_out/oncotator_out/variants_fixed.maf mutect2_out/oncotator_out/tcga_comparison.pdf mutect2_out/oncotator_out/genes_by_VAF.pdf VarDict MAF and Summaries vardict_out/oncotator_out/final_filtered.maf vardict_out/oncotator_out/variants_fixed.maf vardict_out/oncotator_out/tcga_comparison.pdf vardict_out/oncotator_out/genes_by_VAF.pdf Strelka MAF and Summaries strelka_out/oncotator_out/final_filtered.maf strelka_out/oncotator_out/variants_fixed.maf strelka_out/oncotator_out/tcga_comparison.pdf strelka_out/oncotator_out/genes_by_VAF.pdf Merged Somatic Variants merged_somatic_variants/oncotator_out/final_filtered.maf merged_somatic_variants/oncotator_out/variants_fixed.maf merged_somatic_variants/oncotator_out/tcga_comparison.pdf merged_somatic_variants/oncotator_out/genes_by_VAF.pdf Structural Variants Manta manta_out/[pair]/results/variants/diploidSV.vcf.gz Copy Number Variants Control-FREEC (Pass 1) freec_out/pass1/[pair].recal.bam_CNVs.p.value.txt Control-FREEC (Pass 2) freec_out/pass2/[pair].recal.bam_CNVs.p.value.txt Sequenza sequenza_out/[tumor-sample]/*","title":"Tumor-Normal"},{"location":"WEG-seq/Whole-exome-genome-output/#tumor-only","text":"In general, the tumor-only pipeline is a stripped down version of the tumor-normal pipeline. We only run MuTect2, Mutect, and VarDict for somatic variant detection, with the same PON and filtering as described above for the tumor-normal pipeline.","title":"Tumor-Only"},{"location":"WEG-seq/Whole-exome-genome-overview/","text":"Whole genome and exome pipelines \u00b6 Overview \u00b6 This section offers an introduction to the Whole Exome Sequencing (WES) and Whole Genome Sequencing (WGS) pipelines available in CCBR Pipeliner, an overview of the workflows, and details of the QC and variant calling outputs. WES and WGS require different considerations and implementations, but they are conceptually similar. Figure 1 below describes the workflow, highlighting differences between WGS and WES, as well as tumor-normal or tumor only. Both the WES and WGS pipelines can be run in germline , tumor only , or tumor-normal modes. Workflow Summary \u00b6 Fig 1. An Overview of the Whole Genome/Exome Pipelines. For detailed descriptions of the individual tools outlined in the WES workflows, refer to the specific tool's documentation and web sites (tools are listed here ).","title":"Overview"},{"location":"WEG-seq/Whole-exome-genome-overview/#whole-genome-and-exome-pipelines","text":"","title":"Whole genome and exome pipelines"},{"location":"WEG-seq/Whole-exome-genome-overview/#overview","text":"This section offers an introduction to the Whole Exome Sequencing (WES) and Whole Genome Sequencing (WGS) pipelines available in CCBR Pipeliner, an overview of the workflows, and details of the QC and variant calling outputs. WES and WGS require different considerations and implementations, but they are conceptually similar. Figure 1 below describes the workflow, highlighting differences between WGS and WES, as well as tumor-normal or tumor only. Both the WES and WGS pipelines can be run in germline , tumor only , or tumor-normal modes.","title":"Overview"},{"location":"WEG-seq/Whole-exome-genome-overview/#workflow-summary","text":"Fig 1. An Overview of the Whole Genome/Exome Pipelines. For detailed descriptions of the individual tools outlined in the WES workflows, refer to the specific tool's documentation and web sites (tools are listed here ).","title":"Workflow Summary"},{"location":"WEG-seq/Whole-exome-genome-tools-and-versions/","text":"Reference genomes \u00b6 The Initial QC and variant calling pipelines support the following genomes: Human hg19 hg38 Mouse mm10 Tools and versions \u00b6 Analysis Category Software Version Notes Preprocessing Trimmomatic 0.33 bwa aligner 0.7.15 Picard 2.1.1 Genome Analysis Toolkit (GATK) 3.8-0 Somatic Variant Calling Mutect2 GATK 3.8-0 Mutect 1.1.7 VarDict 1.4 Strelka 2.9.0 Tumor-Normal only vcf2maf 1.6.16 MutSigCV 1.41 Run only if >10 tumor samples Germline Variant Calling HaplotypeCaller GATK 3.8-0 Admixture 1.3.0 PLINK 1.9.0 Copy Number Variants (CNV) Control-FREEC 11.9 Tumor-Normal only Sequenza-utils 2.2.0 Tumor-Normal only Sequenza R package 3.0 Tumor-Normal only Canvas 1.3.8 WGS only Structural Variants (SV) Manta 1.3.0 SvABA WGS only Quality Control and Reporting qualimap 2.2.1 multiqc 1.4 FastQC 0.11.5 Fastq Screen 0.9.3 General scripting R 3.5 perl 5.18.4 Python 3.6","title":"Resources"},{"location":"WEG-seq/Whole-exome-genome-tools-and-versions/#reference-genomes","text":"The Initial QC and variant calling pipelines support the following genomes: Human hg19 hg38 Mouse mm10","title":"Reference genomes"},{"location":"WEG-seq/Whole-exome-genome-tools-and-versions/#tools-and-versions","text":"Analysis Category Software Version Notes Preprocessing Trimmomatic 0.33 bwa aligner 0.7.15 Picard 2.1.1 Genome Analysis Toolkit (GATK) 3.8-0 Somatic Variant Calling Mutect2 GATK 3.8-0 Mutect 1.1.7 VarDict 1.4 Strelka 2.9.0 Tumor-Normal only vcf2maf 1.6.16 MutSigCV 1.41 Run only if >10 tumor samples Germline Variant Calling HaplotypeCaller GATK 3.8-0 Admixture 1.3.0 PLINK 1.9.0 Copy Number Variants (CNV) Control-FREEC 11.9 Tumor-Normal only Sequenza-utils 2.2.0 Tumor-Normal only Sequenza R package 3.0 Tumor-Normal only Canvas 1.3.8 WGS only Structural Variants (SV) Manta 1.3.0 SvABA WGS only Quality Control and Reporting qualimap 2.2.1 multiqc 1.4 FastQC 0.11.5 Fastq Screen 0.9.3 General scripting R 3.5 perl 5.18.4 Python 3.6","title":"Tools and versions"},{"location":"dev/coming-soon/","text":"Coming Soon \u00b6 This page is under construction, and our team is actively working on bringing you the most up-to-date documentation. If you need this information ASAP, please feel free to contact us directly. Thank you for your patience!","title":"Data Privacy"},{"location":"dev/coming-soon/#coming-soon","text":"This page is under construction, and our team is actively working on bringing you the most up-to-date documentation. If you need this information ASAP, please feel free to contact us directly. Thank you for your patience!","title":"Coming Soon"},{"location":"dev/lorem_ipsum/","text":"Lorem ipsum \u00b6 Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum. h2 Heading \u00b6 h3 Heading \u00b6 h4 Heading \u00b6 h5 Heading \u00b6 h6 Heading \u00b6 Horizontal Rules \u00b6 Emphasis \u00b6 This is bold text This is bold text This is italic text This is italic text Strikethrough Blockquotes \u00b6 Blockquotes can also be nested... ...by using additional greater-than signs right next to each other... ...or with spaces between arrows. Lists \u00b6 Unordered Create a list by starting a line with + , - , or * Sub-lists are made by indenting 2 spaces: Marker character change forces new list start: Ac tristique libero volutpat at Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Very easy! Ordered Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa You can use sequential numbers... ...or keep all the numbers as 1. Start numbering with offset: foo bar Code \u00b6 Inline code Indented code // Some comments line 1 of code line 2 of code line 3 of code Block code \"fences\" Sample text here... Syntax highlighting var foo = function ( bar ) { return bar ++ ; }; console . log ( foo ( 5 )); Tables \u00b6 Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Right-aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Links \u00b6 link text link with title Images \u00b6 Like links, Images also have a footnote style syntax With a reference later in the document defining the URL location: Plugins \u00b6 The killer feature of markdown-it is very effective support of syntax plugins . Footnotes \u00b6 Footnote 1 link 1 . Footnote 2 link 2 . Inline footnote^[Text of inline footnote] definition. Duplicated footnote reference 2 . Definition lists \u00b6 Term 1 Definition 1 with lazy continuation. Term 2 with inline markup Definition 2 { some code, part of Definition 2 } Third paragraph of definition 2. Compact style: Term 1 ~ Definition 1 Term 2 ~ Definition 2a ~ Definition 2b Footnote can have markup and multiple paragraphs. \u21a9 Footnote text. \u21a9 \u21a9","title":"Lorem ipsum"},{"location":"dev/lorem_ipsum/#lorem-ipsum","text":"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.","title":"Lorem ipsum"},{"location":"dev/lorem_ipsum/#h2-heading","text":"","title":"h2 Heading"},{"location":"dev/lorem_ipsum/#h3-heading","text":"","title":"h3 Heading"},{"location":"dev/lorem_ipsum/#h4-heading","text":"","title":"h4 Heading"},{"location":"dev/lorem_ipsum/#h5-heading","text":"","title":"h5 Heading"},{"location":"dev/lorem_ipsum/#h6-heading","text":"","title":"h6 Heading"},{"location":"dev/lorem_ipsum/#horizontal-rules","text":"","title":"Horizontal Rules"},{"location":"dev/lorem_ipsum/#emphasis","text":"This is bold text This is bold text This is italic text This is italic text Strikethrough","title":"Emphasis"},{"location":"dev/lorem_ipsum/#blockquotes","text":"Blockquotes can also be nested... ...by using additional greater-than signs right next to each other... ...or with spaces between arrows.","title":"Blockquotes"},{"location":"dev/lorem_ipsum/#lists","text":"Unordered Create a list by starting a line with + , - , or * Sub-lists are made by indenting 2 spaces: Marker character change forces new list start: Ac tristique libero volutpat at Facilisis in pretium nisl aliquet Nulla volutpat aliquam velit Very easy! Ordered Lorem ipsum dolor sit amet Consectetur adipiscing elit Integer molestie lorem at massa You can use sequential numbers... ...or keep all the numbers as 1. Start numbering with offset: foo bar","title":"Lists"},{"location":"dev/lorem_ipsum/#code","text":"Inline code Indented code // Some comments line 1 of code line 2 of code line 3 of code Block code \"fences\" Sample text here... Syntax highlighting var foo = function ( bar ) { return bar ++ ; }; console . log ( foo ( 5 ));","title":"Code"},{"location":"dev/lorem_ipsum/#tables","text":"Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files. Right-aligned columns Option Description data path to data files to supply the data that will be passed into templates. engine engine to be used for processing templates. Handlebars is the default. ext extension to be used for dest files.","title":"Tables"},{"location":"dev/lorem_ipsum/#links","text":"link text link with title","title":"Links"},{"location":"dev/lorem_ipsum/#images","text":"Like links, Images also have a footnote style syntax With a reference later in the document defining the URL location:","title":"Images"},{"location":"dev/lorem_ipsum/#plugins","text":"The killer feature of markdown-it is very effective support of syntax plugins .","title":"Plugins"},{"location":"dev/lorem_ipsum/#footnotes","text":"Footnote 1 link 1 . Footnote 2 link 2 . Inline footnote^[Text of inline footnote] definition. Duplicated footnote reference 2 .","title":"Footnotes"},{"location":"dev/lorem_ipsum/#definition-lists","text":"Term 1 Definition 1 with lazy continuation. Term 2 with inline markup Definition 2 { some code, part of Definition 2 } Third paragraph of definition 2. Compact style: Term 1 ~ Definition 1 Term 2 ~ Definition 2a ~ Definition 2b Footnote can have markup and multiple paragraphs. \u21a9 Footnote text. \u21a9 \u21a9","title":"Definition lists"},{"location":"miRNA-seq/TLDR-miRNASeq/","text":"Setup \u00b6 In the rawData directory, create a directory to contain all the FASTQ files. Navigate to the directory and create softlinks or hardlinks for the fastq.gz files (absolute file path is recommended) . Follow the naming conventions as described in the RNA-Seq documentation . In short: Use the format: <sampleName>.R1.fastq.gz Do not use spaces in the sample name. Do not use hyphens or minus signs in the sample name (i.e. - ) Do not start sample names with a number Do not use the terms sample , R1 , or R2 in the sample name itself. You may use underscores in the filename (i.e. _ ) In the GUI, follow standard usage to select the miRSeq pipeline and the organism genome of interest. Current supported genomes are hg38 (human) and mm10 (mouse). Create the working directory as normal and \"Initialize Directory.\" If set up properly, symlinks to the fastq.gz files should be created in the working directory. Initial Quality Control \u00b6 The most up-to-date version of the miRSeq pipeline is labeled miRSeq_v2. Do not use the CAPmirseq-plus pipeline, as it is no longer maintained. Novel miRNA identification \u00b6 By default, miRDeep2 initially performs alignment of reads to a known microRNA sequence reference, such as those available at miRBase.org . In addition, miRDeeps offers the option to perform identification of novel microRNAs by mapping reads to the reference genome and determining the likelihood of genuine precursor and mature miRNA sequences through folding energy. These calculations can be time- and memory-intensive, but should the user be interested in novel miRNA discovery, we have maintained the ability to perform this function. Setting up sample sheets \u00b6 groups.tab As before, the groups.tab file lists the sample file headers, indicates the group to which each sample belongs, and allows the user to create an alias for the sample. For examples, if there are four samples in two groups, with the file names Sample1.R1.fastq.gz , Sample2.R1.fastq.gz ,etc. groups.tab` would contain the following: Sample1 Group1 S1 Sample2 Group2 S2 Sample3 Group1 S3 Sample4 Group2 S4 contrasts.tab The contrasts.tab file contains the comparisons to be made by differential expression, along with information associated with normalizing across samples. The file consists of four columns, with the first two columns indicating groups to be compared, followed by the minimum read count and the minimum number of samples for a miRNA to be accepted (i.e. not filtered for low expression). To continue the previous example, to compare Group2-Group1, with a minimum read count of 0.5 in at least 2 samples, contrasts.tab would contain the following: Group2 Group1 0.5 2 Dry-running the Pipeline \u00b6 After setting up the data directory, the working directory, the groups.tab file, and the contrasts.tab file, click the Dry Run button. This will launch a preliminary pipeline check to ensure that all necessary files are present and accessible. A new window will open showing the steps that will be run in the pipeline. Scroll to the end of the dry run to confirm that the process names and number of processes run are identical at the beginning and end. Top of Dry Run End of Dry Run Run the miRSeq Pipeline \u00b6 If the dry run checks out, click the Run button. This produces the following popup: Click OK to launch the pipeline. Users will be notified by email when the run is completed.","title":"User Tutorial"},{"location":"miRNA-seq/TLDR-miRNASeq/#setup","text":"In the rawData directory, create a directory to contain all the FASTQ files. Navigate to the directory and create softlinks or hardlinks for the fastq.gz files (absolute file path is recommended) . Follow the naming conventions as described in the RNA-Seq documentation . In short: Use the format: <sampleName>.R1.fastq.gz Do not use spaces in the sample name. Do not use hyphens or minus signs in the sample name (i.e. - ) Do not start sample names with a number Do not use the terms sample , R1 , or R2 in the sample name itself. You may use underscores in the filename (i.e. _ ) In the GUI, follow standard usage to select the miRSeq pipeline and the organism genome of interest. Current supported genomes are hg38 (human) and mm10 (mouse). Create the working directory as normal and \"Initialize Directory.\" If set up properly, symlinks to the fastq.gz files should be created in the working directory.","title":"Setup"},{"location":"miRNA-seq/TLDR-miRNASeq/#initial-quality-control","text":"The most up-to-date version of the miRSeq pipeline is labeled miRSeq_v2. Do not use the CAPmirseq-plus pipeline, as it is no longer maintained.","title":"Initial Quality Control"},{"location":"miRNA-seq/TLDR-miRNASeq/#novel-mirna-identification","text":"By default, miRDeep2 initially performs alignment of reads to a known microRNA sequence reference, such as those available at miRBase.org . In addition, miRDeeps offers the option to perform identification of novel microRNAs by mapping reads to the reference genome and determining the likelihood of genuine precursor and mature miRNA sequences through folding energy. These calculations can be time- and memory-intensive, but should the user be interested in novel miRNA discovery, we have maintained the ability to perform this function.","title":"Novel miRNA identification"},{"location":"miRNA-seq/TLDR-miRNASeq/#setting-up-sample-sheets","text":"groups.tab As before, the groups.tab file lists the sample file headers, indicates the group to which each sample belongs, and allows the user to create an alias for the sample. For examples, if there are four samples in two groups, with the file names Sample1.R1.fastq.gz , Sample2.R1.fastq.gz ,etc. groups.tab` would contain the following: Sample1 Group1 S1 Sample2 Group2 S2 Sample3 Group1 S3 Sample4 Group2 S4 contrasts.tab The contrasts.tab file contains the comparisons to be made by differential expression, along with information associated with normalizing across samples. The file consists of four columns, with the first two columns indicating groups to be compared, followed by the minimum read count and the minimum number of samples for a miRNA to be accepted (i.e. not filtered for low expression). To continue the previous example, to compare Group2-Group1, with a minimum read count of 0.5 in at least 2 samples, contrasts.tab would contain the following: Group2 Group1 0.5 2","title":"Setting up sample sheets"},{"location":"miRNA-seq/TLDR-miRNASeq/#dry-running-the-pipeline","text":"After setting up the data directory, the working directory, the groups.tab file, and the contrasts.tab file, click the Dry Run button. This will launch a preliminary pipeline check to ensure that all necessary files are present and accessible. A new window will open showing the steps that will be run in the pipeline. Scroll to the end of the dry run to confirm that the process names and number of processes run are identical at the beginning and end. Top of Dry Run End of Dry Run","title":"Dry-running the Pipeline"},{"location":"miRNA-seq/TLDR-miRNASeq/#run-the-mirseq-pipeline","text":"If the dry run checks out, click the Run button. This produces the following popup: Click OK to launch the pipeline. Users will be notified by email when the run is completed.","title":"Run the miRSeq Pipeline"},{"location":"miRNA-seq/miRSeq-Output-Files/","text":"Inputs \u00b6 Initial input files \u00b6 These files are generated during the Initialize Directory and are linked from the rawdata directory. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.fastq.gz -> /data/CCBR_Pipeliner/testdata/mirseq/fastq/Control_1_miRNA_S1.R1.fastq.gz \u251c\u2500\u2500 Control_2_miRNA_S2.R1.fastq.gz -> /data/CCBR_Pipeliner/testdata/mirseq/fastq/Control_2_miRNA_S2.R1.fastq.gz \u251c\u2500\u2500 ... \u251c\u2500\u2500 ... \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.R1.fastq.gz -> /data/CCBR_Pipeliner/testdata/mirseq/fastq/TreatmentB_3_miRNA_S11.R1.fastq.gz \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1.fastq.gz -> /data/CCBR_Pipeliner/testdata/mirseq/fastq/TreatmentB_4_miRNA_S12.R1.fastq.gz Input tab files \u00b6 These are the tab-delimited files created by the user to indicate groups and contrasts <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 groups.tab \u251c\u2500\u2500 contrasts.tab Quality Control \u00b6 Pre-trim FastQC \u00b6 These files are available in the rawQC directory and are produced by the first round of FastQC, performed on the reads before adapter trimming. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 rawQC \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1_fastqc.html \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1_fastqc.zip \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1_fastqc.html \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1_fastqc.zip \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.R1_fastqc.html \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.R1_fastqc.zip \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1_fastqc.html \u2502 \u2514\u2500\u2500 TreatmentB_4_miRNA_S12.R1_fastqc.zip \u251c\u2500\u2500 ... Adapter trimmed reads \u00b6 These files are produced by Cutadapt by trimming the adapter sequences from the read sequences. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 trim \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim.fastq.gz \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1.trim.fastq.gz \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.R1.trim.fastq.gz \u2502 \u2514\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim.fastq.gz \u251c\u2500\u2500 ... Kraken \u00b6 Kraken is a tool for evaluating the degree of contamination in the individual samples and produces html reports for each sample. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 kraken \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.trim.fastq.kraken_bacteria.krona.html \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.trim.fastq.kraken_bacteria.taxa.txt \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.trim.fastq.kraken_bacteria.krona.html \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.trim.fastq.kraken_bacteria.taxa.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.trim.fastq.kraken_bacteria.krona.html \u2502 \u2514\u2500\u2500 TreatmentB_4_miRNA_S12.trim.fastq.kraken_bacteria.taxa.txt \u251c\u2500\u2500 ... Post-trim FastQC \u00b6 FastQC is also performed after adapter trimming to evaluate the quality of the reads without appended adapter sequences. It also includes two files containing the read length statistics. These results are available in the QC directory. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 QC \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_fastqc.html \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_fastqc.zip \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1.trim_fastqc.html \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 readlength.err \u2502 \u251c\u2500\u2500 readlength.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.R1.trim_fastqc.html \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.R1.trim_fastqc.zip \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_fastqc.html \u2502 \u2514\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_fastqc.zip \u251c\u2500\u2500 ... FastQ Screen \u00b6 FastQ Screen is run twice, with different configuration files. The results for the first run are stored in the FQscreen directory and perform a preliminary mapping to identify likely species from which the reads were obtained. The second run is stored in the FQscreen2 directory and aligns the reads to ribosomal and UniVec sequences. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 FQscreen \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_screen.html \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_screen.png \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_screen.txt \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1.trim_screen.html \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1.trim_screen.png \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1.trim_screen.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_screen.html \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_screen.png \u2502 \u2514\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_screen.txt \u251c\u2500\u2500 FQscreen2 \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_screen.html \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_screen.png \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_screen.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_screen.html \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_screen.png \u2502 \u2514\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_screen.txt \u251c\u2500\u2500 ... MultiQC Report \u00b6 The MultiQC report, which compiles all the results of the different QC programs into a single html report, is in the Reports directory. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 Reports \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 multiqc_data \u2502 \u2502 \u251c\u2500\u2500 multiqc_data.json \u2502 \u2502 \u251c\u2500\u2500 multiqc_fastqc.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_fastq_screen.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_general_stats.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc.log \u2502 \u2502 \u2514\u2500\u2500 multiqc_sources.txt \u2502 \u251c\u2500\u2500 multiqc_report.html \u2502 \u251c\u2500\u2500 ... \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 ... miRDeep2 Outputs \u00b6 Preliminary FASTA conversion \u00b6 miRDeep2 operates on FASTA files, while the trimmed data is in FASTQ format. The files are converted to FASTA format using the FASTX-toolkit and compressed for storage after they are utilized . The conversion is logged for the Snakemake program using file flags. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 fasta \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.trimfasta.done \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.trimfasta.done \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.trimfasta.done \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.trimfasta.done \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 ... miRDeep2 Mapper \u00b6 miRDeep2 performs a preliminary mapping prior to alignment to create a single collapsed FASTA file containing all the reads. This requires the creation of said FASTA file and a mapping config file containing sample abbreviations. It then performs alignment with Bowtie 1 to the reference genome and the output is stored as trimmed.arf in the working directory. Since the raw FASTA files are no longer necessary, they are compressed into a .tar.gz file. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 fasta \u2502 \u251c\u2500\u2500 collapsed_trim.fa \u2502 \u251c\u2500\u2500 ... \u2502 \u2514\u2500\u2500 trim.tar.gz \u251c\u2500\u2500 ... \u251c\u2500\u2500 mirdeep_config.txt \u251c\u2500\u2500 ... \u2514\u2500\u2500 trimmed.arf miRDeep2: Annotated Reads Only \u00b6 If the user has opted to not identify novel microRNAs, the collapsed FASTA file is aligned with Bowtie against the annotated precursor and mature microRNA sequences from miRBase, and the results are stored in a counts file in the directory mirdeep2_out . The final results, with the assigned sample names, are stored in mirdeep2_results/annotated_counts.txt . <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 mirdeep2_out \u2502 \u251c\u2500\u2500 expression_<stamp>.html \u2502 \u251c\u2500\u2500 expression_analyses \u2502 \u2502 \u2514\u2500\u2500 expression_analyses_<stamp> \u2502 \u2502 \u251c\u2500\u2500 bowtie_mature.out \u2502 \u2502 \u251c\u2500\u2500 bowtie_reads.out \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa.converted \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa_mapped.arf \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa_mapped.bwt \u2502 \u2502 \u251c\u2500\u2500 expression_1594075822.html \u2502 \u2502 \u251c\u2500\u2500 mature2hairpin \u2502 \u2502 \u251c\u2500\u2500 mature.converted \u2502 \u2502 \u251c\u2500\u2500 mature.fa_mapped.arf \u2502 \u2502 \u251c\u2500\u2500 mature.fa_mapped.bwt \u2502 \u2502 \u251c\u2500\u2500 miRBase.mrd \u2502 \u2502 \u251c\u2500\u2500 miRNA_expressed.csv \u2502 \u2502 \u251c\u2500\u2500 miRNA_not_expressed.csv \u2502 \u2502 \u251c\u2500\u2500 miRNA_precursor.1.ebwt \u2502 \u2502 \u251c\u2500\u2500 miRNA_precursor.2.ebwt \u2502 \u2502 \u251c\u2500\u2500 miRNA_precursor.3.ebwt \u2502 \u2502 \u251c\u2500\u2500 miRNA_precursor.4.ebwt \u2502 \u2502 \u251c\u2500\u2500 miRNA_precursor.rev.1.ebwt \u2502 \u2502 \u251c\u2500\u2500 miRNA_precursor.rev.2.ebwt \u2502 \u2502 \u251c\u2500\u2500 precursor.converted \u2502 \u2502 \u251c\u2500\u2500 read_occ \u2502 \u2502 \u2514\u2500\u2500 rna.ps \u2502 \u2514\u2500\u2500 miRNAs_expressed_all_samples.txt \u251c\u2500\u2500 mirdeep2_results \u2502 \u2514\u2500\u2500 annotated_counts.txt \u251c\u2500\u2500 ... miRDeep2: Novel miRNA Alignment \u00b6 If the user has opted to have miRDeep2 identify novel miRNAs, several additional outputs are generated, including * Novel hairpin and mature FASTA references, which are stored in the fasta directory * Alignments to the annotated miRBase reference in mirdeep2_1p * Alignments to the novel reference sequences in mirdeep2_2p * Counts for annotated and novel reference sequences in mirdeep2_results <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 fasta \u2502 \u251c\u2500\u2500 collapsed_trim.fa \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 novel_hairpin.fa \u2502 \u251c\u2500\u2500 novel_mature.fa \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.trimfasta.done \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.trimfasta.done \u2502 \u2514\u2500\u2500 trim.tar.gz \u251c\u2500\u2500 mirdeep2_1p \u2502 \u251c\u2500\u2500 dir_prepare_signature1594151705 \u2502 \u2502 \u251c\u2500\u2500 mature_vs_precursors.arf \u2502 \u2502 \u251c\u2500\u2500 mature_vs_precursors.bwt \u2502 \u2502 \u251c\u2500\u2500 precursors.ebwt.1.ebwt \u2502 \u2502 \u251c\u2500\u2500 precursors.ebwt.2.ebwt \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 signature_unsorted.arf.tmp \u2502 \u2502 \u2514\u2500\u2500 signature_unsorted.arf.tmp2 \u2502 \u251c\u2500\u2500 error_07_07_2020_t_15_43_26.log \u2502 \u251c\u2500\u2500 expression_07_07_2020_t_15_43_26.html \u2502 \u251c\u2500\u2500 expression_analyses \u2502 \u2502 \u2514\u2500\u2500 expression_analyses_07_07_2020_t_15_43_26 \u2502 \u2502 \u251c\u2500\u2500 bowtie_mature.out \u2502 \u2502 \u251c\u2500\u2500 bowtie_reads.out \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa.converted \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa_mapped.arf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2514\u2500\u2500 rna.ps \u2502 \u251c\u2500\u2500 mirna_results_07_07_2020_t_15_43_26 \u2502 \u2502 \u251c\u2500\u2500 known_mature_07_07_2020_t_15_43_26_score-50_to_na.bed \u2502 \u2502 \u251c\u2500\u2500 known_mature_07_07_2020_t_15_43_26_score-50_to_na.fa \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 novel_star_07_07_2020_t_15_43_26_score-50_to_na.bed \u2502 \u2502 \u2514\u2500\u2500 novel_star_07_07_2020_t_15_43_26_score-50_to_na.fa \u2502 \u251c\u2500\u2500 miRNAs_expressed_all_samples_1p.txt \u2502 \u251c\u2500\u2500 pdfs_07_07_2020_t_15_43_26 \u2502 \u2502 \u251c\u2500\u2500 chr10_23178.pdf \u2502 \u2502 \u251c\u2500\u2500 chr10_23253.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2514\u2500\u2500 chrY_45431.pdf \u2502 \u251c\u2500\u2500 result_07_07_2020_t_15_43_26.bed \u2502 \u251c\u2500\u2500 result_07_07_2020_t_15_43_26.csv \u2502 \u2514\u2500\u2500 result_07_07_2020_t_15_43_26.html \u251c\u2500\u2500 mirdeep2_2p \u2502 \u251c\u2500\u2500 expression_1594185150.html \u2502 \u251c\u2500\u2500 expression_analyses \u2502 \u2502 \u2514\u2500\u2500 expression_analyses_1594185150 \u2502 \u2502 \u251c\u2500\u2500 bowtie_mature.out \u2502 \u2502 \u251c\u2500\u2500 bowtie_reads.out \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa.converted \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa_mapped.arf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 novel_mature.fa_mapped.bwt \u2502 \u2502 \u251c\u2500\u2500 precursor.converted \u2502 \u2502 \u251c\u2500\u2500 read_occ \u2502 \u2502 \u2514\u2500\u2500 rna.ps \u2502 \u251c\u2500\u2500 novel_miRNAs_expressed_all_samples_2p.txt \u2502 \u2514\u2500\u2500 pdfs_1594185150 \u2502 \u251c\u2500\u2500 chr10_23178.pdf \u2502 \u251c\u2500\u2500 chr10_23253.pdf \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 ... \u251c\u2500\u2500 mirdeep2_results \u2502 \u251c\u2500\u2500 annotatedCounts.txt \u2502 \u2514\u2500\u2500 novelCounts.txt Differential expression \u00b6 Coming soon! Miscellaneous outputs from the Pipeliner Snakemake \u00b6 Many of these files are produced by Pipeliner in order to run the pipeline to completion or as background outputs. <WorkingDirectory> | | \u251c\u2500\u2500 cluster.json \u251c\u2500\u2500 HPC_usage_table.txt \u251c\u2500\u2500 pairs \u251c\u2500\u2500 pipeline_ctrl.sh \u251c\u2500\u2500 Reports \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 run.json \u251c\u2500\u2500 samples \u251c\u2500\u2500 Scripts \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 slurmfiles \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 Snakefile \u2514\u2500\u2500 submit_slurm.sh","title":"Output Files"},{"location":"miRNA-seq/miRSeq-Output-Files/#inputs","text":"","title":"Inputs"},{"location":"miRNA-seq/miRSeq-Output-Files/#initial-input-files","text":"These files are generated during the Initialize Directory and are linked from the rawdata directory. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.fastq.gz -> /data/CCBR_Pipeliner/testdata/mirseq/fastq/Control_1_miRNA_S1.R1.fastq.gz \u251c\u2500\u2500 Control_2_miRNA_S2.R1.fastq.gz -> /data/CCBR_Pipeliner/testdata/mirseq/fastq/Control_2_miRNA_S2.R1.fastq.gz \u251c\u2500\u2500 ... \u251c\u2500\u2500 ... \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.R1.fastq.gz -> /data/CCBR_Pipeliner/testdata/mirseq/fastq/TreatmentB_3_miRNA_S11.R1.fastq.gz \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1.fastq.gz -> /data/CCBR_Pipeliner/testdata/mirseq/fastq/TreatmentB_4_miRNA_S12.R1.fastq.gz","title":"Initial input files"},{"location":"miRNA-seq/miRSeq-Output-Files/#input-tab-files","text":"These are the tab-delimited files created by the user to indicate groups and contrasts <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 groups.tab \u251c\u2500\u2500 contrasts.tab","title":"Input tab files"},{"location":"miRNA-seq/miRSeq-Output-Files/#quality-control","text":"","title":"Quality Control"},{"location":"miRNA-seq/miRSeq-Output-Files/#pre-trim-fastqc","text":"These files are available in the rawQC directory and are produced by the first round of FastQC, performed on the reads before adapter trimming. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 rawQC \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1_fastqc.html \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1_fastqc.zip \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1_fastqc.html \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1_fastqc.zip \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.R1_fastqc.html \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.R1_fastqc.zip \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1_fastqc.html \u2502 \u2514\u2500\u2500 TreatmentB_4_miRNA_S12.R1_fastqc.zip \u251c\u2500\u2500 ...","title":"Pre-trim FastQC"},{"location":"miRNA-seq/miRSeq-Output-Files/#adapter-trimmed-reads","text":"These files are produced by Cutadapt by trimming the adapter sequences from the read sequences. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 trim \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim.fastq.gz \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1.trim.fastq.gz \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.R1.trim.fastq.gz \u2502 \u2514\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim.fastq.gz \u251c\u2500\u2500 ...","title":"Adapter trimmed reads"},{"location":"miRNA-seq/miRSeq-Output-Files/#kraken","text":"Kraken is a tool for evaluating the degree of contamination in the individual samples and produces html reports for each sample. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 kraken \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.trim.fastq.kraken_bacteria.krona.html \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.trim.fastq.kraken_bacteria.taxa.txt \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.trim.fastq.kraken_bacteria.krona.html \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.trim.fastq.kraken_bacteria.taxa.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.trim.fastq.kraken_bacteria.krona.html \u2502 \u2514\u2500\u2500 TreatmentB_4_miRNA_S12.trim.fastq.kraken_bacteria.taxa.txt \u251c\u2500\u2500 ...","title":"Kraken"},{"location":"miRNA-seq/miRSeq-Output-Files/#post-trim-fastqc","text":"FastQC is also performed after adapter trimming to evaluate the quality of the reads without appended adapter sequences. It also includes two files containing the read length statistics. These results are available in the QC directory. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 QC \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_fastqc.html \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_fastqc.zip \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1.trim_fastqc.html \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 readlength.err \u2502 \u251c\u2500\u2500 readlength.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.R1.trim_fastqc.html \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.R1.trim_fastqc.zip \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_fastqc.html \u2502 \u2514\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_fastqc.zip \u251c\u2500\u2500 ...","title":"Post-trim FastQC"},{"location":"miRNA-seq/miRSeq-Output-Files/#fastq-screen","text":"FastQ Screen is run twice, with different configuration files. The results for the first run are stored in the FQscreen directory and perform a preliminary mapping to identify likely species from which the reads were obtained. The second run is stored in the FQscreen2 directory and aligns the reads to ribosomal and UniVec sequences. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 FQscreen \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_screen.html \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_screen.png \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_screen.txt \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1.trim_screen.html \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1.trim_screen.png \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.R1.trim_screen.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_screen.html \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_screen.png \u2502 \u2514\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_screen.txt \u251c\u2500\u2500 FQscreen2 \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_screen.html \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_screen.png \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.R1.trim_screen.txt \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_screen.html \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_screen.png \u2502 \u2514\u2500\u2500 TreatmentB_4_miRNA_S12.R1.trim_screen.txt \u251c\u2500\u2500 ...","title":"FastQ Screen"},{"location":"miRNA-seq/miRSeq-Output-Files/#multiqc-report","text":"The MultiQC report, which compiles all the results of the different QC programs into a single html report, is in the Reports directory. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 Reports \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 multiqc_data \u2502 \u2502 \u251c\u2500\u2500 multiqc_data.json \u2502 \u2502 \u251c\u2500\u2500 multiqc_fastqc.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_fastq_screen.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc_general_stats.txt \u2502 \u2502 \u251c\u2500\u2500 multiqc.log \u2502 \u2502 \u2514\u2500\u2500 multiqc_sources.txt \u2502 \u251c\u2500\u2500 multiqc_report.html \u2502 \u251c\u2500\u2500 ... \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 ...","title":"MultiQC Report"},{"location":"miRNA-seq/miRSeq-Output-Files/#mirdeep2-outputs","text":"","title":"miRDeep2 Outputs"},{"location":"miRNA-seq/miRSeq-Output-Files/#preliminary-fasta-conversion","text":"miRDeep2 operates on FASTA files, while the trimmed data is in FASTQ format. The files are converted to FASTA format using the FASTX-toolkit and compressed for storage after they are utilized . The conversion is logged for the Snakemake program using file flags. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 fasta \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 Control_1_miRNA_S1.trimfasta.done \u2502 \u251c\u2500\u2500 Control_2_miRNA_S2.trimfasta.done \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.trimfasta.done \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.trimfasta.done \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 ...","title":"Preliminary FASTA conversion"},{"location":"miRNA-seq/miRSeq-Output-Files/#mirdeep2-mapper","text":"miRDeep2 performs a preliminary mapping prior to alignment to create a single collapsed FASTA file containing all the reads. This requires the creation of said FASTA file and a mapping config file containing sample abbreviations. It then performs alignment with Bowtie 1 to the reference genome and the output is stored as trimmed.arf in the working directory. Since the raw FASTA files are no longer necessary, they are compressed into a .tar.gz file. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 fasta \u2502 \u251c\u2500\u2500 collapsed_trim.fa \u2502 \u251c\u2500\u2500 ... \u2502 \u2514\u2500\u2500 trim.tar.gz \u251c\u2500\u2500 ... \u251c\u2500\u2500 mirdeep_config.txt \u251c\u2500\u2500 ... \u2514\u2500\u2500 trimmed.arf","title":"miRDeep2 Mapper"},{"location":"miRNA-seq/miRSeq-Output-Files/#mirdeep2-annotated-reads-only","text":"If the user has opted to not identify novel microRNAs, the collapsed FASTA file is aligned with Bowtie against the annotated precursor and mature microRNA sequences from miRBase, and the results are stored in a counts file in the directory mirdeep2_out . The final results, with the assigned sample names, are stored in mirdeep2_results/annotated_counts.txt . <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 mirdeep2_out \u2502 \u251c\u2500\u2500 expression_<stamp>.html \u2502 \u251c\u2500\u2500 expression_analyses \u2502 \u2502 \u2514\u2500\u2500 expression_analyses_<stamp> \u2502 \u2502 \u251c\u2500\u2500 bowtie_mature.out \u2502 \u2502 \u251c\u2500\u2500 bowtie_reads.out \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa.converted \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa_mapped.arf \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa_mapped.bwt \u2502 \u2502 \u251c\u2500\u2500 expression_1594075822.html \u2502 \u2502 \u251c\u2500\u2500 mature2hairpin \u2502 \u2502 \u251c\u2500\u2500 mature.converted \u2502 \u2502 \u251c\u2500\u2500 mature.fa_mapped.arf \u2502 \u2502 \u251c\u2500\u2500 mature.fa_mapped.bwt \u2502 \u2502 \u251c\u2500\u2500 miRBase.mrd \u2502 \u2502 \u251c\u2500\u2500 miRNA_expressed.csv \u2502 \u2502 \u251c\u2500\u2500 miRNA_not_expressed.csv \u2502 \u2502 \u251c\u2500\u2500 miRNA_precursor.1.ebwt \u2502 \u2502 \u251c\u2500\u2500 miRNA_precursor.2.ebwt \u2502 \u2502 \u251c\u2500\u2500 miRNA_precursor.3.ebwt \u2502 \u2502 \u251c\u2500\u2500 miRNA_precursor.4.ebwt \u2502 \u2502 \u251c\u2500\u2500 miRNA_precursor.rev.1.ebwt \u2502 \u2502 \u251c\u2500\u2500 miRNA_precursor.rev.2.ebwt \u2502 \u2502 \u251c\u2500\u2500 precursor.converted \u2502 \u2502 \u251c\u2500\u2500 read_occ \u2502 \u2502 \u2514\u2500\u2500 rna.ps \u2502 \u2514\u2500\u2500 miRNAs_expressed_all_samples.txt \u251c\u2500\u2500 mirdeep2_results \u2502 \u2514\u2500\u2500 annotated_counts.txt \u251c\u2500\u2500 ...","title":"miRDeep2: Annotated Reads Only"},{"location":"miRNA-seq/miRSeq-Output-Files/#mirdeep2-novel-mirna-alignment","text":"If the user has opted to have miRDeep2 identify novel miRNAs, several additional outputs are generated, including * Novel hairpin and mature FASTA references, which are stored in the fasta directory * Alignments to the annotated miRBase reference in mirdeep2_1p * Alignments to the novel reference sequences in mirdeep2_2p * Counts for annotated and novel reference sequences in mirdeep2_results <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 fasta \u2502 \u251c\u2500\u2500 collapsed_trim.fa \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 novel_hairpin.fa \u2502 \u251c\u2500\u2500 novel_mature.fa \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 TreatmentB_3_miRNA_S11.trimfasta.done \u2502 \u251c\u2500\u2500 TreatmentB_4_miRNA_S12.trimfasta.done \u2502 \u2514\u2500\u2500 trim.tar.gz \u251c\u2500\u2500 mirdeep2_1p \u2502 \u251c\u2500\u2500 dir_prepare_signature1594151705 \u2502 \u2502 \u251c\u2500\u2500 mature_vs_precursors.arf \u2502 \u2502 \u251c\u2500\u2500 mature_vs_precursors.bwt \u2502 \u2502 \u251c\u2500\u2500 precursors.ebwt.1.ebwt \u2502 \u2502 \u251c\u2500\u2500 precursors.ebwt.2.ebwt \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 signature_unsorted.arf.tmp \u2502 \u2502 \u2514\u2500\u2500 signature_unsorted.arf.tmp2 \u2502 \u251c\u2500\u2500 error_07_07_2020_t_15_43_26.log \u2502 \u251c\u2500\u2500 expression_07_07_2020_t_15_43_26.html \u2502 \u251c\u2500\u2500 expression_analyses \u2502 \u2502 \u2514\u2500\u2500 expression_analyses_07_07_2020_t_15_43_26 \u2502 \u2502 \u251c\u2500\u2500 bowtie_mature.out \u2502 \u2502 \u251c\u2500\u2500 bowtie_reads.out \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa.converted \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa_mapped.arf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2514\u2500\u2500 rna.ps \u2502 \u251c\u2500\u2500 mirna_results_07_07_2020_t_15_43_26 \u2502 \u2502 \u251c\u2500\u2500 known_mature_07_07_2020_t_15_43_26_score-50_to_na.bed \u2502 \u2502 \u251c\u2500\u2500 known_mature_07_07_2020_t_15_43_26_score-50_to_na.fa \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 novel_star_07_07_2020_t_15_43_26_score-50_to_na.bed \u2502 \u2502 \u2514\u2500\u2500 novel_star_07_07_2020_t_15_43_26_score-50_to_na.fa \u2502 \u251c\u2500\u2500 miRNAs_expressed_all_samples_1p.txt \u2502 \u251c\u2500\u2500 pdfs_07_07_2020_t_15_43_26 \u2502 \u2502 \u251c\u2500\u2500 chr10_23178.pdf \u2502 \u2502 \u251c\u2500\u2500 chr10_23253.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2514\u2500\u2500 chrY_45431.pdf \u2502 \u251c\u2500\u2500 result_07_07_2020_t_15_43_26.bed \u2502 \u251c\u2500\u2500 result_07_07_2020_t_15_43_26.csv \u2502 \u2514\u2500\u2500 result_07_07_2020_t_15_43_26.html \u251c\u2500\u2500 mirdeep2_2p \u2502 \u251c\u2500\u2500 expression_1594185150.html \u2502 \u251c\u2500\u2500 expression_analyses \u2502 \u2502 \u2514\u2500\u2500 expression_analyses_1594185150 \u2502 \u2502 \u251c\u2500\u2500 bowtie_mature.out \u2502 \u2502 \u251c\u2500\u2500 bowtie_reads.out \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa.converted \u2502 \u2502 \u251c\u2500\u2500 collapsed_trim.fa_mapped.arf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 novel_mature.fa_mapped.bwt \u2502 \u2502 \u251c\u2500\u2500 precursor.converted \u2502 \u2502 \u251c\u2500\u2500 read_occ \u2502 \u2502 \u2514\u2500\u2500 rna.ps \u2502 \u251c\u2500\u2500 novel_miRNAs_expressed_all_samples_2p.txt \u2502 \u2514\u2500\u2500 pdfs_1594185150 \u2502 \u251c\u2500\u2500 chr10_23178.pdf \u2502 \u251c\u2500\u2500 chr10_23253.pdf \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 ... \u251c\u2500\u2500 mirdeep2_results \u2502 \u251c\u2500\u2500 annotatedCounts.txt \u2502 \u2514\u2500\u2500 novelCounts.txt","title":"miRDeep2: Novel miRNA Alignment"},{"location":"miRNA-seq/miRSeq-Output-Files/#differential-expression","text":"Coming soon!","title":"Differential expression"},{"location":"miRNA-seq/miRSeq-Output-Files/#miscellaneous-outputs-from-the-pipeliner-snakemake","text":"Many of these files are produced by Pipeliner in order to run the pipeline to completion or as background outputs. <WorkingDirectory> | | \u251c\u2500\u2500 cluster.json \u251c\u2500\u2500 HPC_usage_table.txt \u251c\u2500\u2500 pairs \u251c\u2500\u2500 pipeline_ctrl.sh \u251c\u2500\u2500 Reports \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 run.json \u251c\u2500\u2500 samples \u251c\u2500\u2500 Scripts \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 slurmfiles \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 Snakefile \u2514\u2500\u2500 submit_slurm.sh","title":"Miscellaneous outputs from the Pipeliner Snakemake"},{"location":"miRNA-seq/miRSeq-Tools-and-Versions/","text":"Reference Genomes \u00b6 Name Species Common name Annotation Version hg38 Homo sapiens Human Genome Reference Consortium Human Build 38 mm10 Mus musculus House mouse Genome Reference Consortium Mouse Build 38 Software \u00b6 Quality control and pre-processing \u00b6 Package/Tool Version Usage Reference FastQC 0.11.5 Preliminary quality control on FASTQ reads before and after adapter trimming 1 Cutadapt 1.18 Adapter sequence trimming 2 Kraken 1.1 Assesses microbial contamination 3 KronaTools 2.7 Visualizes results from Kraken 4 FastQ Screen 0.9.3 Assesses sequence contamination 5 MultiQC 1.4 QC report aggregation and generation 6 FASTX-Toolkit 0.0.14 FASTA and FASTQ conversion kit 7 Alignment and differential expression \u00b6 Package/Tool Version Usage Reference miRDeep2 2.0.0.8 Backbone for miRSeq alignment and quantification. Dependencies include Bowtie1 , ViennaRNA , RandFold , and Perl 8 , 9 , 10 , 11 , 12 edgeR 3.28.1 Normalization and differential miR expression analysis 13 , 14 R 3.6.1 Programming language used to run edgeR 15 References \u00b6 1 Andrews, S. 2018. \"FastQC: A quality control tool for high throughput sequence data.\" http://www.bioinformatics.babraham.ac.uk/projects/fastqc/ . Version 0.11.5 2 Martin, M. 2011. \"Cutadapt removes adapter sequences from high-throughput sequencing reads.\" EMBnet.journal 17(1): 10-12. doi: 10.14806/ej.17.1.200 3 Wood and Salzberg. 2014. \"Kraken: ultrafast metagenomic sequence classification using exact alignments.\" Genome Biol. 15: R46. doi: 10.1186/gb-2014-15-3-r46 4 Ondov, Bergman, and Phillippy. 2011. \"Interactive metagenomic visualization in a Web browser.\" BMC Bioinformatics 12: 385. doi: 10.1186/1471-2105-12-385 5 Wingett and Andrews. 2018. \"FastQ Screen: A tool for multi-genome mapping and quality control.\" F1000Res. 7: 1338. doi: 10.12688/f1000research.15931.2 6 Ewels, Magnusson, et al. 2016. \"MultiQC: Summarize analysis results for multiple tools and samples in a single report.\" Bioinformatics 32(19): 3047-3048. doi: 10.1093/bioinformatics/btw354 7 Gordon, A. 2010. \"FASTX-Toolkit: FASTQ/A short-reads pre-processing tools.\" http://hannonlab.cshl.edu/fastx_toolkit/index.html 8 Friedlander, Mackowiak, et al. 2012. \"miRDeep2 accurately identifies known and hundreds of novel microRNA genes in seven animal clades.\" Nucleic Acids Res. 40(1): 37-52. doi: 10.1093/nar/gkr688 9 Langmead, Trapnell, et al. 2009. \"Ultrafast and memory-efficient alignment of short DNA sequences to the human genome.\" Genome Biol. 10: R25. doi: 10.1186/gb-2009-10-3-r25 10 Lorenz, Bernhart, et al. 2011. \"ViennaRNA Package 2.0.\" Algorithms Mol Biol. 6: 26. doi: 10.1186/1748-7188-6-26 11 Bonnet, Wuyts, et al. 2004. \"Evidence that microRNA precursors, unlike other non-coding RNAs, have lower folding free energies than random sequences.\" Bioinformatics 20(17): 2911-2917. doi: 10.1093/bioinformatics/bth374 12 \"perl - The Perl 5 language interpreter.\" 2017. https://www.perl.org . Version 5.24.3. 13 Robinson, McCarthy, and Smyth. 2010. \"edgeR: a Bioconductor package for differential expression analysis of digital gene expression data. Bioinformatics 26: 139-140. doi: 10.1093/bioinformatics/btp616 14 McCarthy, Chen, and Smyth. 2012. \"Differential expression analysis of multifactor RNA-Seq experiments with respect to biological variation.\" Nucleic Acids Res. 40(10): 4288-4297. doi: 10.1093/nar/gks042 15 \"The R Project for Statistical Computing.\" https://www.r-project.org/ . Version 3.6.1 , released 2019-07-05.","title":"Resources"},{"location":"miRNA-seq/miRSeq-Tools-and-Versions/#reference-genomes","text":"Name Species Common name Annotation Version hg38 Homo sapiens Human Genome Reference Consortium Human Build 38 mm10 Mus musculus House mouse Genome Reference Consortium Mouse Build 38","title":"Reference Genomes"},{"location":"miRNA-seq/miRSeq-Tools-and-Versions/#software","text":"","title":"Software"},{"location":"miRNA-seq/miRSeq-Tools-and-Versions/#quality-control-and-pre-processing","text":"Package/Tool Version Usage Reference FastQC 0.11.5 Preliminary quality control on FASTQ reads before and after adapter trimming 1 Cutadapt 1.18 Adapter sequence trimming 2 Kraken 1.1 Assesses microbial contamination 3 KronaTools 2.7 Visualizes results from Kraken 4 FastQ Screen 0.9.3 Assesses sequence contamination 5 MultiQC 1.4 QC report aggregation and generation 6 FASTX-Toolkit 0.0.14 FASTA and FASTQ conversion kit 7","title":"Quality control and pre-processing"},{"location":"miRNA-seq/miRSeq-Tools-and-Versions/#alignment-and-differential-expression","text":"Package/Tool Version Usage Reference miRDeep2 2.0.0.8 Backbone for miRSeq alignment and quantification. Dependencies include Bowtie1 , ViennaRNA , RandFold , and Perl 8 , 9 , 10 , 11 , 12 edgeR 3.28.1 Normalization and differential miR expression analysis 13 , 14 R 3.6.1 Programming language used to run edgeR 15","title":"Alignment and differential expression"},{"location":"miRNA-seq/miRSeq-Tools-and-Versions/#references","text":"1 Andrews, S. 2018. \"FastQC: A quality control tool for high throughput sequence data.\" http://www.bioinformatics.babraham.ac.uk/projects/fastqc/ . Version 0.11.5 2 Martin, M. 2011. \"Cutadapt removes adapter sequences from high-throughput sequencing reads.\" EMBnet.journal 17(1): 10-12. doi: 10.14806/ej.17.1.200 3 Wood and Salzberg. 2014. \"Kraken: ultrafast metagenomic sequence classification using exact alignments.\" Genome Biol. 15: R46. doi: 10.1186/gb-2014-15-3-r46 4 Ondov, Bergman, and Phillippy. 2011. \"Interactive metagenomic visualization in a Web browser.\" BMC Bioinformatics 12: 385. doi: 10.1186/1471-2105-12-385 5 Wingett and Andrews. 2018. \"FastQ Screen: A tool for multi-genome mapping and quality control.\" F1000Res. 7: 1338. doi: 10.12688/f1000research.15931.2 6 Ewels, Magnusson, et al. 2016. \"MultiQC: Summarize analysis results for multiple tools and samples in a single report.\" Bioinformatics 32(19): 3047-3048. doi: 10.1093/bioinformatics/btw354 7 Gordon, A. 2010. \"FASTX-Toolkit: FASTQ/A short-reads pre-processing tools.\" http://hannonlab.cshl.edu/fastx_toolkit/index.html 8 Friedlander, Mackowiak, et al. 2012. \"miRDeep2 accurately identifies known and hundreds of novel microRNA genes in seven animal clades.\" Nucleic Acids Res. 40(1): 37-52. doi: 10.1093/nar/gkr688 9 Langmead, Trapnell, et al. 2009. \"Ultrafast and memory-efficient alignment of short DNA sequences to the human genome.\" Genome Biol. 10: R25. doi: 10.1186/gb-2009-10-3-r25 10 Lorenz, Bernhart, et al. 2011. \"ViennaRNA Package 2.0.\" Algorithms Mol Biol. 6: 26. doi: 10.1186/1748-7188-6-26 11 Bonnet, Wuyts, et al. 2004. \"Evidence that microRNA precursors, unlike other non-coding RNAs, have lower folding free energies than random sequences.\" Bioinformatics 20(17): 2911-2917. doi: 10.1093/bioinformatics/bth374 12 \"perl - The Perl 5 language interpreter.\" 2017. https://www.perl.org . Version 5.24.3. 13 Robinson, McCarthy, and Smyth. 2010. \"edgeR: a Bioconductor package for differential expression analysis of digital gene expression data. Bioinformatics 26: 139-140. doi: 10.1093/bioinformatics/btp616 14 McCarthy, Chen, and Smyth. 2012. \"Differential expression analysis of multifactor RNA-Seq experiments with respect to biological variation.\" Nucleic Acids Res. 40(10): 4288-4297. doi: 10.1093/nar/gks042 15 \"The R Project for Statistical Computing.\" https://www.r-project.org/ . Version 3.6.1 , released 2019-07-05.","title":"References"},{"location":"miRNA-seq/overview-miRNA-seq/","text":"miRNA-seq Pipeline \u00b6 Overview \u00b6 An end-to-end pipeline for miRSeq, beginning from raw single-end FASTQ files and ending with differential expression. The alignment is performed using miRDeep2 and differential expression with EdgeR, first by creating a generalized linear model (GLM) and performing a likelihood ratio test (LRT).","title":"Overview"},{"location":"miRNA-seq/overview-miRNA-seq/#mirna-seq-pipeline","text":"","title":"miRNA-seq Pipeline"},{"location":"miRNA-seq/overview-miRNA-seq/#overview","text":"An end-to-end pipeline for miRSeq, beginning from raw single-end FASTQ files and ending with differential expression. The alignment is performed using miRDeep2 and differential expression with EdgeR, first by creating a generalized linear model (GLM) and performing a likelihood ratio test (LRT).","title":"Overview"},{"location":"scRNA-seq/TLDR-Single-Cell-RNASeq/","text":"Setup \u00b6 In the rawData directory for the project, create a directory titled \u201ch5\u201d. Navigate to the directory and create softlinks for the h5 files (absolute file path is generally helpful). From inside the directory, this can be done for each file with the command: ln -s absolute/path/to/sample/outs/filtered_feature_bc_matrix.h5 renamed_sample.h5 If there are too many samples to repeatedly type this command, a bash script can be generated and run to create the softlinked files (assuming that these paths are generated from CellRanger outputs): echo '#!/bin/bash' > make_softlinks.bash; for file in /path/to/experiment/*/outs/filtered_feature_bc_matrix.h5; do sample=$(echo $file|sed \"s~.*experiment/~~g\"|sed \"s~/outs.*~~g\"); echo ln -s $file \"$sample\".h5; done >> make_softlinks.bash Run the bash script with: bash make_softlinks.bash The h5 directory should now contain softlinks for all the h5 files, pointing to their \"true\" location. This can be checked with the ls -lh command from inside the h5 directory. lrwxrwxrwx. 1 user Group 16 Jul 2 2020 sample1_NR.h5 -> /path/to/sample1_NR/outs/filtered_feature_bc_matrix.h5 lrwxrwxrwx. 1 user Group 15 Jul 2 2020 sample1_R.h5 -> /path/to/sample1_R/outs/filtered_feature_bc_matrix.h5 lrwxrwxrwx. 1 user Group 16 Jul 2 2020 sample2_NR.h5 -> /path/to/sample2_NR/outs/filtered_feature_bc_matrix.h5 lrwxrwxrwx. 1 user Group 15 Jul 2 2020 sample2_R.h5 -> /path/to/sample2_R/outs/filtered_feature_bc_matrix.h5 In the GUI, follow the standard usage to select the scRNASeq pipeline and an organism genome of interest. Current supported genomes are GRCh38 (human) and mm10 (mouse). Set the data directory the parent directory containing the h5 directory, not the h5 directory directly. You should see the h5 directory in the selection window: Create the working directory as normal and \u201cInitialize Directory\u201d. If set up properly, symlinks to the h5 files should be created within the working directory. Initial Quality Control \u00b6 Clustering \u00b6 The clustering algorithm can be chosen from one of three options: 1. Smart Local Moving Algorithm (default) 2. Original Louvain algorithm 3. Louvain algorithm with multilevel refinement Multiple clustering resolutions can be used, ranging from 0 to 2, where lower resolution values will result in larger and fewer clusters. The default values of 0.4, 0.6, 0.8, 1.0, and 1.2 should cover the majority of clustering resolutions necessary. Cell Type Annotation \u00b6 The annotation databases provided by SingleR are species dependent and are populated in response to the species selected. Five human databases are included by default : * Human Primary Cell Atlas (non-specific) * Blueprint and ENCODE (non-specific) * Database for Immune Cell Expression (DICE) (immune) * Monaco Immune Cell Data (immune) * Novershtern Hematopoietic Cell Data (hematopoietic & immune) Two mouse databases are also provided: * ImmGen (immune) * mouseRNASeq \u2013 A collection of mouse data (non-specific) All relevant databases are used for cell type identification; the choice of database selects the default reference used in the preliminary QC plots. Sample Tab Files \u00b6 As before, groups.tab contains three columns for each sample: FileNameHeader(noExtension) GroupID SampleAlias contrasts.tab contains two columns: Group1 Group2 Contrasts are calculated as Group1-Group2 . For example, if there are 4 samples in 2 groups, with file names Sample1.h5 , Sample2.h5 , etc., groups.tab would contain the following: Sample1 Group1 S1 Sample2 Group2 S2 Sample3 Group1 S3 Sample4 Group2 S4 and to determine Group2-Group1 , contrasts.tab would contain: Group2 Group1 CITESeq \u00b6 CITESeq is a recent addition to single-cell technologies where antibody capture is used in conjunction with scRNASeq. This allows for more direct correlation to traditional cell sorting techniques, where surface markers are used to identify cells. By selecting this option, it retrieves the CITESeq data from the h5 object and performs relevant scaling and normalization, per Seurat recommendations . Dry run the Pipeline \u00b6 After setting up the data directory, the working directory, the groups.tab file, the contrasts.tab file, and all necessary options, click the Dry Run button. This will launch a preliminary pipeline check to ensure that all necessary files are present and accessible. A new window will open showing the steps that will be run in the pipeline. Scroll to the end of the dry run to confirm that the process names and number of processes run are identical at the beginning and end. Top of Dry Run End of Dry Run Run the scRNASeq Pipeline \u00b6 If the dry run checks out, click the Run button. This produces the following popup: Click OK to launch the pipeline. Users will be notified by email when the run is completed.","title":"User Tutorial"},{"location":"scRNA-seq/TLDR-Single-Cell-RNASeq/#setup","text":"In the rawData directory for the project, create a directory titled \u201ch5\u201d. Navigate to the directory and create softlinks for the h5 files (absolute file path is generally helpful). From inside the directory, this can be done for each file with the command: ln -s absolute/path/to/sample/outs/filtered_feature_bc_matrix.h5 renamed_sample.h5 If there are too many samples to repeatedly type this command, a bash script can be generated and run to create the softlinked files (assuming that these paths are generated from CellRanger outputs): echo '#!/bin/bash' > make_softlinks.bash; for file in /path/to/experiment/*/outs/filtered_feature_bc_matrix.h5; do sample=$(echo $file|sed \"s~.*experiment/~~g\"|sed \"s~/outs.*~~g\"); echo ln -s $file \"$sample\".h5; done >> make_softlinks.bash Run the bash script with: bash make_softlinks.bash The h5 directory should now contain softlinks for all the h5 files, pointing to their \"true\" location. This can be checked with the ls -lh command from inside the h5 directory. lrwxrwxrwx. 1 user Group 16 Jul 2 2020 sample1_NR.h5 -> /path/to/sample1_NR/outs/filtered_feature_bc_matrix.h5 lrwxrwxrwx. 1 user Group 15 Jul 2 2020 sample1_R.h5 -> /path/to/sample1_R/outs/filtered_feature_bc_matrix.h5 lrwxrwxrwx. 1 user Group 16 Jul 2 2020 sample2_NR.h5 -> /path/to/sample2_NR/outs/filtered_feature_bc_matrix.h5 lrwxrwxrwx. 1 user Group 15 Jul 2 2020 sample2_R.h5 -> /path/to/sample2_R/outs/filtered_feature_bc_matrix.h5 In the GUI, follow the standard usage to select the scRNASeq pipeline and an organism genome of interest. Current supported genomes are GRCh38 (human) and mm10 (mouse). Set the data directory the parent directory containing the h5 directory, not the h5 directory directly. You should see the h5 directory in the selection window: Create the working directory as normal and \u201cInitialize Directory\u201d. If set up properly, symlinks to the h5 files should be created within the working directory.","title":"Setup"},{"location":"scRNA-seq/TLDR-Single-Cell-RNASeq/#initial-quality-control","text":"","title":"Initial Quality Control"},{"location":"scRNA-seq/TLDR-Single-Cell-RNASeq/#clustering","text":"The clustering algorithm can be chosen from one of three options: 1. Smart Local Moving Algorithm (default) 2. Original Louvain algorithm 3. Louvain algorithm with multilevel refinement Multiple clustering resolutions can be used, ranging from 0 to 2, where lower resolution values will result in larger and fewer clusters. The default values of 0.4, 0.6, 0.8, 1.0, and 1.2 should cover the majority of clustering resolutions necessary.","title":"Clustering"},{"location":"scRNA-seq/TLDR-Single-Cell-RNASeq/#cell-type-annotation","text":"The annotation databases provided by SingleR are species dependent and are populated in response to the species selected. Five human databases are included by default : * Human Primary Cell Atlas (non-specific) * Blueprint and ENCODE (non-specific) * Database for Immune Cell Expression (DICE) (immune) * Monaco Immune Cell Data (immune) * Novershtern Hematopoietic Cell Data (hematopoietic & immune) Two mouse databases are also provided: * ImmGen (immune) * mouseRNASeq \u2013 A collection of mouse data (non-specific) All relevant databases are used for cell type identification; the choice of database selects the default reference used in the preliminary QC plots.","title":"Cell Type Annotation"},{"location":"scRNA-seq/TLDR-Single-Cell-RNASeq/#sample-tab-files","text":"As before, groups.tab contains three columns for each sample: FileNameHeader(noExtension) GroupID SampleAlias contrasts.tab contains two columns: Group1 Group2 Contrasts are calculated as Group1-Group2 . For example, if there are 4 samples in 2 groups, with file names Sample1.h5 , Sample2.h5 , etc., groups.tab would contain the following: Sample1 Group1 S1 Sample2 Group2 S2 Sample3 Group1 S3 Sample4 Group2 S4 and to determine Group2-Group1 , contrasts.tab would contain: Group2 Group1","title":"Sample Tab Files"},{"location":"scRNA-seq/TLDR-Single-Cell-RNASeq/#citeseq","text":"CITESeq is a recent addition to single-cell technologies where antibody capture is used in conjunction with scRNASeq. This allows for more direct correlation to traditional cell sorting techniques, where surface markers are used to identify cells. By selecting this option, it retrieves the CITESeq data from the h5 object and performs relevant scaling and normalization, per Seurat recommendations .","title":"CITESeq"},{"location":"scRNA-seq/TLDR-Single-Cell-RNASeq/#dry-run-the-pipeline","text":"After setting up the data directory, the working directory, the groups.tab file, the contrasts.tab file, and all necessary options, click the Dry Run button. This will launch a preliminary pipeline check to ensure that all necessary files are present and accessible. A new window will open showing the steps that will be run in the pipeline. Scroll to the end of the dry run to confirm that the process names and number of processes run are identical at the beginning and end. Top of Dry Run End of Dry Run","title":"Dry run the Pipeline"},{"location":"scRNA-seq/TLDR-Single-Cell-RNASeq/#run-the-scrnaseq-pipeline","text":"If the dry run checks out, click the Run button. This produces the following popup: Click OK to launch the pipeline. Users will be notified by email when the run is completed.","title":"Run the scRNASeq Pipeline"},{"location":"scRNA-seq/overview-scRNA-seq/","text":"scRNA-seq Pipeline \u00b6 Overview \u00b6 An end-to-end pipeline for scRNASeq, beginning from .h5 outputs generated by 10x Genomics Chromium device to Seurat objects of combined samples, and finally differential gene expression (in development). The backbone of the pipeline is Seurat, with additional tools included as needed.","title":"Overview"},{"location":"scRNA-seq/overview-scRNA-seq/#scrna-seq-pipeline","text":"","title":"scRNA-seq Pipeline"},{"location":"scRNA-seq/overview-scRNA-seq/#overview","text":"An end-to-end pipeline for scRNASeq, beginning from .h5 outputs generated by 10x Genomics Chromium device to Seurat objects of combined samples, and finally differential gene expression (in development). The backbone of the pipeline is Seurat, with additional tools included as needed.","title":"Overview"},{"location":"scRNA-seq/scRNASeq-Output-Files/","text":"Input Files \u00b6 Initial input files \u00b6 The initial input files are obtained from the raw data directory during the Initialize Directory step. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 sample1_NR.h5 -> /data/CCBR_Pipeliner/testdata/scrnaseq/h5/sample1_NR.h5 \u251c\u2500\u2500 sample1_R.h5 -> /data/CCBR_Pipeliner/testdata/scrnaseq/h5/sample1_R.h5 \u251c\u2500\u2500 sample2_NR.h5 -> /data/CCBR_Pipeliner/testdata/scrnaseq/h5/sample2_NR.h5 \u251c\u2500\u2500 sample2_R.h5 -> /data/CCBR_Pipeliner/testdata/scrnaseq/h5/sample2_R.h5 \u251c\u2500\u2500 ... Input tab files \u00b6 These are the tab-delimited files created by the user to indicate groups and contrasts. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 contrasts.tab \u251c\u2500\u2500 ... \u251c\u2500\u2500 groups.tab \u251c\u2500\u2500 ... Single Sample Quality Control \u00b6 Filtered Sample Outputs \u00b6 For each sample, an RDS file containing a Seurat object is exported for both pre- and post-doublet removal. Flag files are also exported to indicate progress to the Snakemake pipeline. \u251c\u2500\u2500 filtered \u2502 \u251c\u2500\u2500 sample1_NR_doublets.rds \u2502 \u251c\u2500\u2500 sample1_NR.rds \u2502 \u251c\u2500\u2500 sample1_R_doublets.rds \u2502 \u251c\u2500\u2500 sample1_R.rds \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 flags \u2502 \u251c\u2500\u2500 sample1_NR.txt \u2502 \u251c\u2500\u2500 ... Quality control reports \u00b6 The QC run for each sample produces a number of image outputs that indicate the quality of the sample and show how many cells were removed for each justification (e.g. low number of unique genes). These images and statistics are compiled into a single html report for each sample. \u251c\u2500\u2500 QC \u2502 \u251c\u2500\u2500 QC_Report_sample1_NR.html \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 sample1_NR \u2502 \u2502 \u2514\u2500\u2500 images \u2502 \u2502 \u251c\u2500\u2500 cellAnnotUMAP_BP_encode_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 cellAnnotVln_BP_encode_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 cellCycle_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 cellsRemovedVenn_sample1_NR.png \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 clusterResolution_0.4_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 clusterResolution_0.6_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 doublets_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 filterStats_sample1_NR.png \u2502 \u2502 \u251c\u2500\u2500 mitoPct_postFilter_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 mitoPct_preFilter_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 silhouetteResolution_0.4_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 sample1_R \u2502 \u2502 \u2514\u2500\u2500 images \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ... Multisample Outputs \u00b6 After QC is performed on the individual samples, the samples are combined both with and without batch correction. Seurat has named the process of combining samples as \"merging\" and the process of batch correction as integration. For each contrast, a merged and integrated object is created. \u251c\u2500\u2500 integration \u2502 \u251c\u2500\u2500 merged \u2502 \u2502 \u2514\u2500\u2500 R-NR \u2502 \u2502 \u2514\u2500\u2500 R-NR.rds \u2502 \u2514\u2500\u2500 seurat_batch_corrected \u2502 \u2514\u2500\u2500 R-NR \u2502 \u2514\u2500\u2500 R-NR.rds Differential Expression \u00b6 Coming soon Miscellaneous Pipeliner Outputs \u00b6 <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 cluster.json \u251c\u2500\u2500 ... \u251c\u2500\u2500 HPC_usage_table.txt \u251c\u2500\u2500 ... \u251c\u2500\u2500 logfiles \u2502 \u2514\u2500\u2500 blank \u251c\u2500\u2500 pairs \u251c\u2500\u2500 pipeline_ctrl.sh \u251c\u2500\u2500 ... \u251c\u2500\u2500 Reports \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 Rplots.pdf \u251c\u2500\u2500 run.json \u251c\u2500\u2500 samples \u251c\u2500\u2500 Scripts \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 slurmfiles \u2502 \u251c\u2500\u2500 blank \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 Snakefile \u2514\u2500\u2500 submit_slurm.sh","title":"Output Files"},{"location":"scRNA-seq/scRNASeq-Output-Files/#input-files","text":"","title":"Input Files"},{"location":"scRNA-seq/scRNASeq-Output-Files/#initial-input-files","text":"The initial input files are obtained from the raw data directory during the Initialize Directory step. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 sample1_NR.h5 -> /data/CCBR_Pipeliner/testdata/scrnaseq/h5/sample1_NR.h5 \u251c\u2500\u2500 sample1_R.h5 -> /data/CCBR_Pipeliner/testdata/scrnaseq/h5/sample1_R.h5 \u251c\u2500\u2500 sample2_NR.h5 -> /data/CCBR_Pipeliner/testdata/scrnaseq/h5/sample2_NR.h5 \u251c\u2500\u2500 sample2_R.h5 -> /data/CCBR_Pipeliner/testdata/scrnaseq/h5/sample2_R.h5 \u251c\u2500\u2500 ...","title":"Initial input files"},{"location":"scRNA-seq/scRNASeq-Output-Files/#input-tab-files","text":"These are the tab-delimited files created by the user to indicate groups and contrasts. <WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 contrasts.tab \u251c\u2500\u2500 ... \u251c\u2500\u2500 groups.tab \u251c\u2500\u2500 ...","title":"Input tab files"},{"location":"scRNA-seq/scRNASeq-Output-Files/#single-sample-quality-control","text":"","title":"Single Sample Quality Control"},{"location":"scRNA-seq/scRNASeq-Output-Files/#filtered-sample-outputs","text":"For each sample, an RDS file containing a Seurat object is exported for both pre- and post-doublet removal. Flag files are also exported to indicate progress to the Snakemake pipeline. \u251c\u2500\u2500 filtered \u2502 \u251c\u2500\u2500 sample1_NR_doublets.rds \u2502 \u251c\u2500\u2500 sample1_NR.rds \u2502 \u251c\u2500\u2500 sample1_R_doublets.rds \u2502 \u251c\u2500\u2500 sample1_R.rds \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 flags \u2502 \u251c\u2500\u2500 sample1_NR.txt \u2502 \u251c\u2500\u2500 ...","title":"Filtered Sample Outputs"},{"location":"scRNA-seq/scRNASeq-Output-Files/#quality-control-reports","text":"The QC run for each sample produces a number of image outputs that indicate the quality of the sample and show how many cells were removed for each justification (e.g. low number of unique genes). These images and statistics are compiled into a single html report for each sample. \u251c\u2500\u2500 QC \u2502 \u251c\u2500\u2500 QC_Report_sample1_NR.html \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 sample1_NR \u2502 \u2502 \u2514\u2500\u2500 images \u2502 \u2502 \u251c\u2500\u2500 cellAnnotUMAP_BP_encode_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 cellAnnotVln_BP_encode_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 cellCycle_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 cellsRemovedVenn_sample1_NR.png \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 clusterResolution_0.4_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 clusterResolution_0.6_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 doublets_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 filterStats_sample1_NR.png \u2502 \u2502 \u251c\u2500\u2500 mitoPct_postFilter_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 mitoPct_preFilter_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u251c\u2500\u2500 silhouetteResolution_0.4_sample1_NR.pdf \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 sample1_R \u2502 \u2502 \u2514\u2500\u2500 images \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u251c\u2500\u2500 ...","title":"Quality control reports"},{"location":"scRNA-seq/scRNASeq-Output-Files/#multisample-outputs","text":"After QC is performed on the individual samples, the samples are combined both with and without batch correction. Seurat has named the process of combining samples as \"merging\" and the process of batch correction as integration. For each contrast, a merged and integrated object is created. \u251c\u2500\u2500 integration \u2502 \u251c\u2500\u2500 merged \u2502 \u2502 \u2514\u2500\u2500 R-NR \u2502 \u2502 \u2514\u2500\u2500 R-NR.rds \u2502 \u2514\u2500\u2500 seurat_batch_corrected \u2502 \u2514\u2500\u2500 R-NR \u2502 \u2514\u2500\u2500 R-NR.rds","title":"Multisample Outputs"},{"location":"scRNA-seq/scRNASeq-Output-Files/#differential-expression","text":"Coming soon","title":"Differential Expression"},{"location":"scRNA-seq/scRNASeq-Output-Files/#miscellaneous-pipeliner-outputs","text":"<WorkingDirectory> \u2502 \u2502 \u251c\u2500\u2500 cluster.json \u251c\u2500\u2500 ... \u251c\u2500\u2500 HPC_usage_table.txt \u251c\u2500\u2500 ... \u251c\u2500\u2500 logfiles \u2502 \u2514\u2500\u2500 blank \u251c\u2500\u2500 pairs \u251c\u2500\u2500 pipeline_ctrl.sh \u251c\u2500\u2500 ... \u251c\u2500\u2500 Reports \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 Rplots.pdf \u251c\u2500\u2500 run.json \u251c\u2500\u2500 samples \u251c\u2500\u2500 Scripts \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 slurmfiles \u2502 \u251c\u2500\u2500 blank \u2502 \u251c\u2500\u2500 ... \u251c\u2500\u2500 Snakefile \u2514\u2500\u2500 submit_slurm.sh","title":"Miscellaneous Pipeliner Outputs"},{"location":"scRNA-seq/scRNASeq-Tools-and-Versions/","text":"Reference Genomes \u00b6 Name Species Common name Annotation Version GRCh38 Homo sapiens Human Genome Reference Consortium Human Build 38 mm10 Mus musculus House mouse Genome Reference Consortium Mouse Build 38 Software \u00b6 Data processing \u00b6 Package name Version Usage Reference R 3.6.1 Primary framework and programming language for data processing 1 Seurat 3.1.4 Primary program for processing single cell data 2 , 3 Routliers 0.0.0.3 R package for identifying outliers via median absolute deviation 4 , 5 , 6 SCTransform Included in Seurat v3.1.4 Used for normalization. This replaces the ScaleData/Normalization from previous versions of Seurat 7 URD 1.1.0 Used to calculate optimal number of principal components through the Marchenko-Pastur law 8 UMAP 0.4.6 2D and 3D dimensionality reduction projection for visualizing cells and relative similarity 9 , 10 SingleR 1.0.5 Cell type annotation based on correlation to cell types within curated databases 11 , 12 DoubletFinder 2.0.2 Algorithm to determine likely doublets based on cell distribution and cell type similarity 13 , 14 Visualization \u00b6 Package name Version Usage Reference ggplot2 3.3.0 Basis for a majority of the visualization, including violin distribution plots and UMAP plots 15 Rmarkdown 2.1 Report writing in html and pdf formats 16 , 17 VennDiagram 1.6.20 Generate Venn diagrams 18 cluster 2.1.0 Analyze clustering similarity for optimization via silhouette plots 19 References \u00b6 1 \"The R Project for Statistical Computing.\" https://www.r-project.org/ . Version 3.6.1 , released 2019-07-05. 2 Stuart, Butler, et al. , 2019. \"Comprehensive Integration of Single-Cell Data.\" Cell 177 (7): 1888-1902.e21. doi: 10.1016/j.cell.2019.05.031 3 Butler, Hoffman, et al. , 2018. \"Integrating single-cell transcriptomic data across different conditions, technologies, and species.\" Nat. Biotechnol. 36: 411-420. doi: 10.1038/nbt.4096 4 Leys, Ley, et al. , 2013. \"Detecting outliers: Do not use standard deviation around the mean, use absolute deviation around the median.\" J. Exp. Soc. Psychol. 49(4): 764-766. doi: 10.1016/j.jesp.2013.03.013 5 Leys, Klein, et al. , 2018. \"Detecting multivariate outliers: Use a robust variant of the Mahalanobis distance.\" J. Exp. Soc. Psychol. 74: 150-156. doi: 10.1016/j.jesp.2017.09.011 6 Delecre and Klein. 2019. \"Routliers: Robust Outliers Detection.\" https://CRAN.R-project.org/package=Routliers . 7 Hafemeister and Satija. 2019. \"Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression.\" Genome Biol. 20: 296. doi: 10.1186/s13059-019-1874-1 8 Farrell, Wang, et al. 2018. \"Single-cell reconstruction of developmental trajectories during zebrafish embryogenesis.\" Science 360: 979. doi: 10.1126/science.aar3131 9 McInnes, L. \"UMAP.\" https://github.com/lmcinnes/umap . 10 McInnes and Healy. 2018. \"UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction.\" ArXiv e-prints . 1802.03426 . 11 Aran, Looney, et al. 2019. \"Reference-based analysis of lung single-cell sequencing reveals a transitional profibrotic macrophage.\" Nat. Immunol. 20: 163-172. doi: 10.1038/s41590-018-0276-y . 12 Aran, Lun, et al. \"Reference-Based Single-Cell RNA-Seq Annotation.\" https://bioconductor.org/packages/release/bioc/html/SingleR.html . doi: 10.18129/B9.bioc.SingleR 13 McGinnis, Murrow, and Gartner. 2019. \"DoubletFinder: Doublet Detection in Single-Cell RNA Sequencing Data Using Artificial Nearest Neighbors.\" Cell Systems 8(4): 329-337.e4. doi: 10.1016/j.cels.2019.03.003 14 McGinnis, C. \"DoubletFinder.\" https://github.com/chris-mcginnis-ucsf/DoubletFinder . 15 Wickham, H. 2016. ggplot2: Elegant graphics for data analysis . Springer-Verlag New York. ISBN 978-3-319-24277-4, https://ggplot2.tidyverse.org . 16 Allaire, Xie, et al. 2019. rmarkdown: Dynamic documents for R. R package version 2.1, https://github.com/rstudio/rmarkdown . 17 Xie, Allaire, and Grolemund. 2018. R Markdown: The Definitive Guide. Chapman and Hall/CRC, Boca Raton, FL, USA. ISBN 9781138359338, https://bookdown.org/yihui/rmarkdown . 18 Chen and Boutros. 2018. VennDiagram: Generate high-resolution Venn and Euler plots. R package version 1.6.20, https://cran.r-project.org/web/packages/VennDiagram 19 Maechler, Rouseeuw, et al. 2019. cluster: Cluster Analysis Basics and Extensions. R package version 2.1.0, https://cran.r-project.org/web/packages/cluster/","title":"Resources"},{"location":"scRNA-seq/scRNASeq-Tools-and-Versions/#reference-genomes","text":"Name Species Common name Annotation Version GRCh38 Homo sapiens Human Genome Reference Consortium Human Build 38 mm10 Mus musculus House mouse Genome Reference Consortium Mouse Build 38","title":"Reference Genomes"},{"location":"scRNA-seq/scRNASeq-Tools-and-Versions/#software","text":"","title":"Software"},{"location":"scRNA-seq/scRNASeq-Tools-and-Versions/#data-processing","text":"Package name Version Usage Reference R 3.6.1 Primary framework and programming language for data processing 1 Seurat 3.1.4 Primary program for processing single cell data 2 , 3 Routliers 0.0.0.3 R package for identifying outliers via median absolute deviation 4 , 5 , 6 SCTransform Included in Seurat v3.1.4 Used for normalization. This replaces the ScaleData/Normalization from previous versions of Seurat 7 URD 1.1.0 Used to calculate optimal number of principal components through the Marchenko-Pastur law 8 UMAP 0.4.6 2D and 3D dimensionality reduction projection for visualizing cells and relative similarity 9 , 10 SingleR 1.0.5 Cell type annotation based on correlation to cell types within curated databases 11 , 12 DoubletFinder 2.0.2 Algorithm to determine likely doublets based on cell distribution and cell type similarity 13 , 14","title":"Data processing"},{"location":"scRNA-seq/scRNASeq-Tools-and-Versions/#visualization","text":"Package name Version Usage Reference ggplot2 3.3.0 Basis for a majority of the visualization, including violin distribution plots and UMAP plots 15 Rmarkdown 2.1 Report writing in html and pdf formats 16 , 17 VennDiagram 1.6.20 Generate Venn diagrams 18 cluster 2.1.0 Analyze clustering similarity for optimization via silhouette plots 19","title":"Visualization"},{"location":"scRNA-seq/scRNASeq-Tools-and-Versions/#references","text":"1 \"The R Project for Statistical Computing.\" https://www.r-project.org/ . Version 3.6.1 , released 2019-07-05. 2 Stuart, Butler, et al. , 2019. \"Comprehensive Integration of Single-Cell Data.\" Cell 177 (7): 1888-1902.e21. doi: 10.1016/j.cell.2019.05.031 3 Butler, Hoffman, et al. , 2018. \"Integrating single-cell transcriptomic data across different conditions, technologies, and species.\" Nat. Biotechnol. 36: 411-420. doi: 10.1038/nbt.4096 4 Leys, Ley, et al. , 2013. \"Detecting outliers: Do not use standard deviation around the mean, use absolute deviation around the median.\" J. Exp. Soc. Psychol. 49(4): 764-766. doi: 10.1016/j.jesp.2013.03.013 5 Leys, Klein, et al. , 2018. \"Detecting multivariate outliers: Use a robust variant of the Mahalanobis distance.\" J. Exp. Soc. Psychol. 74: 150-156. doi: 10.1016/j.jesp.2017.09.011 6 Delecre and Klein. 2019. \"Routliers: Robust Outliers Detection.\" https://CRAN.R-project.org/package=Routliers . 7 Hafemeister and Satija. 2019. \"Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression.\" Genome Biol. 20: 296. doi: 10.1186/s13059-019-1874-1 8 Farrell, Wang, et al. 2018. \"Single-cell reconstruction of developmental trajectories during zebrafish embryogenesis.\" Science 360: 979. doi: 10.1126/science.aar3131 9 McInnes, L. \"UMAP.\" https://github.com/lmcinnes/umap . 10 McInnes and Healy. 2018. \"UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction.\" ArXiv e-prints . 1802.03426 . 11 Aran, Looney, et al. 2019. \"Reference-based analysis of lung single-cell sequencing reveals a transitional profibrotic macrophage.\" Nat. Immunol. 20: 163-172. doi: 10.1038/s41590-018-0276-y . 12 Aran, Lun, et al. \"Reference-Based Single-Cell RNA-Seq Annotation.\" https://bioconductor.org/packages/release/bioc/html/SingleR.html . doi: 10.18129/B9.bioc.SingleR 13 McGinnis, Murrow, and Gartner. 2019. \"DoubletFinder: Doublet Detection in Single-Cell RNA Sequencing Data Using Artificial Nearest Neighbors.\" Cell Systems 8(4): 329-337.e4. doi: 10.1016/j.cels.2019.03.003 14 McGinnis, C. \"DoubletFinder.\" https://github.com/chris-mcginnis-ucsf/DoubletFinder . 15 Wickham, H. 2016. ggplot2: Elegant graphics for data analysis . Springer-Verlag New York. ISBN 978-3-319-24277-4, https://ggplot2.tidyverse.org . 16 Allaire, Xie, et al. 2019. rmarkdown: Dynamic documents for R. R package version 2.1, https://github.com/rstudio/rmarkdown . 17 Xie, Allaire, and Grolemund. 2018. R Markdown: The Definitive Guide. Chapman and Hall/CRC, Boca Raton, FL, USA. ISBN 9781138359338, https://bookdown.org/yihui/rmarkdown . 18 Chen and Boutros. 2018. VennDiagram: Generate high-resolution Venn and Euler plots. R package version 1.6.20, https://cran.r-project.org/web/packages/VennDiagram 19 Maechler, Rouseeuw, et al. 2019. cluster: Cluster Analysis Basics and Extensions. R package version 2.1.0, https://cran.r-project.org/web/packages/cluster/","title":"References"}]}